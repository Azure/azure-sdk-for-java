// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) AutoRest Code Generator.

package com.azure.resourcemanager.machinelearning.models;

import com.azure.core.annotation.Fluent;
import com.azure.core.util.logging.ClientLogger;
import com.azure.json.JsonReader;
import com.azure.json.JsonToken;
import com.azure.json.JsonWriter;
import java.io.IOException;

/**
 * The SparkJobPythonEntry model.
 */
@Fluent
public final class SparkJobPythonEntry extends SparkJobEntry {
    /*
     * [Required] Type of the job's entry point.
     */
    private SparkJobEntryType sparkJobEntryType = SparkJobEntryType.SPARK_JOB_PYTHON_ENTRY;

    /*
     * [Required] Relative python file path for job entry point.
     */
    private String file;

    /**
     * Creates an instance of SparkJobPythonEntry class.
     */
    public SparkJobPythonEntry() {
    }

    /**
     * Get the sparkJobEntryType property: [Required] Type of the job's entry point.
     * 
     * @return the sparkJobEntryType value.
     */
    @Override
    public SparkJobEntryType sparkJobEntryType() {
        return this.sparkJobEntryType;
    }

    /**
     * Get the file property: [Required] Relative python file path for job entry point.
     * 
     * @return the file value.
     */
    public String file() {
        return this.file;
    }

    /**
     * Set the file property: [Required] Relative python file path for job entry point.
     * 
     * @param file the file value to set.
     * @return the SparkJobPythonEntry object itself.
     */
    public SparkJobPythonEntry withFile(String file) {
        this.file = file;
        return this;
    }

    /**
     * Validates the instance.
     * 
     * @throws IllegalArgumentException thrown if the instance is not valid.
     */
    @Override
    public void validate() {
        super.validate();
        if (file() == null) {
            throw LOGGER.atError()
                .log(new IllegalArgumentException("Missing required property file in model SparkJobPythonEntry"));
        }
    }

    private static final ClientLogger LOGGER = new ClientLogger(SparkJobPythonEntry.class);

    /**
     * {@inheritDoc}
     */
    @Override
    public JsonWriter toJson(JsonWriter jsonWriter) throws IOException {
        jsonWriter.writeStartObject();
        jsonWriter.writeStringField("file", this.file);
        jsonWriter.writeStringField("sparkJobEntryType",
            this.sparkJobEntryType == null ? null : this.sparkJobEntryType.toString());
        return jsonWriter.writeEndObject();
    }

    /**
     * Reads an instance of SparkJobPythonEntry from the JsonReader.
     * 
     * @param jsonReader The JsonReader being read.
     * @return An instance of SparkJobPythonEntry if the JsonReader was pointing to an instance of it, or null if it was
     * pointing to JSON null.
     * @throws IllegalStateException If the deserialized JSON object was missing any required properties.
     * @throws IOException If an error occurs while reading the SparkJobPythonEntry.
     */
    public static SparkJobPythonEntry fromJson(JsonReader jsonReader) throws IOException {
        return jsonReader.readObject(reader -> {
            SparkJobPythonEntry deserializedSparkJobPythonEntry = new SparkJobPythonEntry();
            while (reader.nextToken() != JsonToken.END_OBJECT) {
                String fieldName = reader.getFieldName();
                reader.nextToken();

                if ("file".equals(fieldName)) {
                    deserializedSparkJobPythonEntry.file = reader.getString();
                } else if ("sparkJobEntryType".equals(fieldName)) {
                    deserializedSparkJobPythonEntry.sparkJobEntryType
                        = SparkJobEntryType.fromString(reader.getString());
                } else {
                    reader.skipChildren();
                }
            }

            return deserializedSparkJobPythonEntry;
        });
    }
}
