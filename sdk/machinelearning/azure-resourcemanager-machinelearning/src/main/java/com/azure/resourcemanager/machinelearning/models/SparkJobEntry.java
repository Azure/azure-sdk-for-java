// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) AutoRest Code Generator.

package com.azure.resourcemanager.machinelearning.models;

import com.azure.core.annotation.Immutable;
import com.azure.json.JsonReader;
import com.azure.json.JsonSerializable;
import com.azure.json.JsonToken;
import com.azure.json.JsonWriter;
import java.io.IOException;

/**
 * Spark job entry point definition.
 */
@Immutable
public class SparkJobEntry implements JsonSerializable<SparkJobEntry> {
    /*
     * [Required] Type of the job's entry point.
     */
    private SparkJobEntryType sparkJobEntryType = SparkJobEntryType.fromString("SparkJobEntry");

    /**
     * Creates an instance of SparkJobEntry class.
     */
    public SparkJobEntry() {
    }

    /**
     * Get the sparkJobEntryType property: [Required] Type of the job's entry point.
     * 
     * @return the sparkJobEntryType value.
     */
    public SparkJobEntryType sparkJobEntryType() {
        return this.sparkJobEntryType;
    }

    /**
     * Validates the instance.
     * 
     * @throws IllegalArgumentException thrown if the instance is not valid.
     */
    public void validate() {
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public JsonWriter toJson(JsonWriter jsonWriter) throws IOException {
        jsonWriter.writeStartObject();
        jsonWriter.writeStringField("sparkJobEntryType",
            this.sparkJobEntryType == null ? null : this.sparkJobEntryType.toString());
        return jsonWriter.writeEndObject();
    }

    /**
     * Reads an instance of SparkJobEntry from the JsonReader.
     * 
     * @param jsonReader The JsonReader being read.
     * @return An instance of SparkJobEntry if the JsonReader was pointing to an instance of it, or null if it was
     * pointing to JSON null.
     * @throws IOException If an error occurs while reading the SparkJobEntry.
     */
    public static SparkJobEntry fromJson(JsonReader jsonReader) throws IOException {
        return jsonReader.readObject(reader -> {
            String discriminatorValue = null;
            try (JsonReader readerToUse = reader.bufferObject()) {
                readerToUse.nextToken(); // Prepare for reading
                while (readerToUse.nextToken() != JsonToken.END_OBJECT) {
                    String fieldName = readerToUse.getFieldName();
                    readerToUse.nextToken();
                    if ("sparkJobEntryType".equals(fieldName)) {
                        discriminatorValue = readerToUse.getString();
                        break;
                    } else {
                        readerToUse.skipChildren();
                    }
                }
                // Use the discriminator value to determine which subtype should be deserialized.
                if ("SparkJobPythonEntry".equals(discriminatorValue)) {
                    return SparkJobPythonEntry.fromJson(readerToUse.reset());
                } else if ("SparkJobScalaEntry".equals(discriminatorValue)) {
                    return SparkJobScalaEntry.fromJson(readerToUse.reset());
                } else {
                    return fromJsonKnownDiscriminator(readerToUse.reset());
                }
            }
        });
    }

    static SparkJobEntry fromJsonKnownDiscriminator(JsonReader jsonReader) throws IOException {
        return jsonReader.readObject(reader -> {
            SparkJobEntry deserializedSparkJobEntry = new SparkJobEntry();
            while (reader.nextToken() != JsonToken.END_OBJECT) {
                String fieldName = reader.getFieldName();
                reader.nextToken();

                if ("sparkJobEntryType".equals(fieldName)) {
                    deserializedSparkJobEntry.sparkJobEntryType = SparkJobEntryType.fromString(reader.getString());
                } else {
                    reader.skipChildren();
                }
            }

            return deserializedSparkJobEntry;
        });
    }
}
