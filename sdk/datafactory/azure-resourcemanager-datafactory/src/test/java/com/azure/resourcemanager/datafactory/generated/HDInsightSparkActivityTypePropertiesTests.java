// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) AutoRest Code Generator.

package com.azure.resourcemanager.datafactory.generated;

import com.azure.core.util.BinaryData;
import com.azure.resourcemanager.datafactory.fluent.models.HDInsightSparkActivityTypeProperties;
import com.azure.resourcemanager.datafactory.models.HDInsightActivityDebugInfoOption;
import com.azure.resourcemanager.datafactory.models.LinkedServiceReference;
import java.util.Arrays;
import java.util.HashMap;
import java.util.Map;
import org.junit.jupiter.api.Assertions;

public final class HDInsightSparkActivityTypePropertiesTests {
    @org.junit.jupiter.api.Test
    public void testDeserialize() throws Exception {
        HDInsightSparkActivityTypeProperties model = BinaryData.fromString(
            "{\"rootPath\":\"datahowxcptx\",\"entryFilePath\":\"dataxfwwvmygcfaztoi\",\"arguments\":[\"datajri\",\"datacamgjyt\",\"datakttit\"],\"getDebugInfo\":\"None\",\"sparkJobLinkedService\":{\"referenceName\":\"xpmoadjooernzl\",\"parameters\":{\"awptxqxpuf\":\"dataygoutqebpuoy\",\"j\":\"dataxp\",\"cecukzt\":\"dataajvskpbu\",\"wwfgjjca\":\"datau\"}},\"className\":\"cepp\",\"proxyUser\":\"datailyxpqxnlifhjym\",\"sparkConfig\":{\"jphozymcypdbuoqn\":\"dataliivyatyzwybgay\",\"gidgwscosmhgza\":\"datatlz\",\"yavfc\":\"datacgdk\"}}")
            .toObject(HDInsightSparkActivityTypeProperties.class);
        Assertions.assertEquals(HDInsightActivityDebugInfoOption.NONE, model.getDebugInfo());
        Assertions.assertEquals("xpmoadjooernzl", model.sparkJobLinkedService().referenceName());
        Assertions.assertEquals("cepp", model.className());
    }

    @org.junit.jupiter.api.Test
    public void testSerialize() throws Exception {
        HDInsightSparkActivityTypeProperties model
            = new HDInsightSparkActivityTypeProperties().withRootPath("datahowxcptx")
                .withEntryFilePath("dataxfwwvmygcfaztoi")
                .withArguments(Arrays.asList("datajri", "datacamgjyt", "datakttit"))
                .withGetDebugInfo(HDInsightActivityDebugInfoOption.NONE)
                .withSparkJobLinkedService(new LinkedServiceReference().withReferenceName("xpmoadjooernzl")
                    .withParameters(mapOf("awptxqxpuf", "dataygoutqebpuoy", "j", "dataxp", "cecukzt", "dataajvskpbu",
                        "wwfgjjca", "datau")))
                .withClassName("cepp")
                .withProxyUser("datailyxpqxnlifhjym")
                .withSparkConfig(
                    mapOf("jphozymcypdbuoqn", "dataliivyatyzwybgay", "gidgwscosmhgza", "datatlz", "yavfc", "datacgdk"));
        model = BinaryData.fromObject(model).toObject(HDInsightSparkActivityTypeProperties.class);
        Assertions.assertEquals(HDInsightActivityDebugInfoOption.NONE, model.getDebugInfo());
        Assertions.assertEquals("xpmoadjooernzl", model.sparkJobLinkedService().referenceName());
        Assertions.assertEquals("cepp", model.className());
    }

    // Use "Map.of" if available
    @SuppressWarnings("unchecked")
    private static <T> Map<String, T> mapOf(Object... inputs) {
        Map<String, T> map = new HashMap<>();
        for (int i = 0; i < inputs.length; i += 2) {
            String key = (String) inputs[i];
            T value = (T) inputs[i + 1];
            map.put(key, value);
        }
        return map;
    }
}
