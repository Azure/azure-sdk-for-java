// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) AutoRest Code Generator.

package com.azure.resourcemanager.datafactory.generated;

import com.azure.core.util.BinaryData;
import com.azure.resourcemanager.datafactory.fluent.models.HDInsightSparkActivityTypeProperties;
import com.azure.resourcemanager.datafactory.models.HDInsightActivityDebugInfoOption;
import com.azure.resourcemanager.datafactory.models.LinkedServiceReference;
import java.util.Arrays;
import java.util.HashMap;
import java.util.Map;
import org.junit.jupiter.api.Assertions;

public final class HDInsightSparkActivityTypePropertiesTests {
    @org.junit.jupiter.api.Test
    public void testDeserialize() throws Exception {
        HDInsightSparkActivityTypeProperties model = BinaryData.fromString(
            "{\"rootPath\":\"datavwmybokqpfhs\",\"entryFilePath\":\"databpjzoyzy\",\"arguments\":[\"dataszthpnwzpki\",\"dataefygdaumerkgmgqy\",\"dataejqka\",\"dataxi\"],\"getDebugInfo\":\"None\",\"sparkJobLinkedService\":{\"referenceName\":\"xoihcqxexbksa\",\"parameters\":{\"gpszwvooxieyyww\":\"datacwyrtluujyesp\",\"fybktbviaqvzzszc\":\"dataiwiaqrc\",\"rxo\":\"dataw\",\"twwaxx\":\"datavygdefpy\"}},\"className\":\"rdsmra\",\"proxyUser\":\"datat\",\"sparkConfig\":{\"dlbocecmnqcgbi\":\"dataxmd\",\"ebvxu\":\"dataypcwbyrkx\",\"kcrc\":\"datachegeog\"}}")
            .toObject(HDInsightSparkActivityTypeProperties.class);
        Assertions.assertEquals(HDInsightActivityDebugInfoOption.NONE, model.getDebugInfo());
        Assertions.assertEquals("xoihcqxexbksa", model.sparkJobLinkedService().referenceName());
        Assertions.assertEquals("rdsmra", model.className());
    }

    @org.junit.jupiter.api.Test
    public void testSerialize() throws Exception {
        HDInsightSparkActivityTypeProperties model
            = new HDInsightSparkActivityTypeProperties().withRootPath("datavwmybokqpfhs")
                .withEntryFilePath("databpjzoyzy")
                .withArguments(Arrays.asList("dataszthpnwzpki", "dataefygdaumerkgmgqy", "dataejqka", "dataxi"))
                .withGetDebugInfo(HDInsightActivityDebugInfoOption.NONE)
                .withSparkJobLinkedService(new LinkedServiceReference().withReferenceName("xoihcqxexbksa")
                    .withParameters(mapOf("gpszwvooxieyyww", "datacwyrtluujyesp", "fybktbviaqvzzszc", "dataiwiaqrc",
                        "rxo", "dataw", "twwaxx", "datavygdefpy")))
                .withClassName("rdsmra")
                .withProxyUser("datat")
                .withSparkConfig(mapOf("dlbocecmnqcgbi", "dataxmd", "ebvxu", "dataypcwbyrkx", "kcrc", "datachegeog"));
        model = BinaryData.fromObject(model).toObject(HDInsightSparkActivityTypeProperties.class);
        Assertions.assertEquals(HDInsightActivityDebugInfoOption.NONE, model.getDebugInfo());
        Assertions.assertEquals("xoihcqxexbksa", model.sparkJobLinkedService().referenceName());
        Assertions.assertEquals("rdsmra", model.className());
    }

    // Use "Map.of" if available
    @SuppressWarnings("unchecked")
    private static <T> Map<String, T> mapOf(Object... inputs) {
        Map<String, T> map = new HashMap<>();
        for (int i = 0; i < inputs.length; i += 2) {
            String key = (String) inputs[i];
            T value = (T) inputs[i + 1];
            map.put(key, value);
        }
        return map;
    }
}
