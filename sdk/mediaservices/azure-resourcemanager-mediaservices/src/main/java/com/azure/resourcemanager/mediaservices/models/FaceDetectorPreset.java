// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) AutoRest Code Generator.

package com.azure.resourcemanager.mediaservices.models;

import com.azure.core.annotation.Fluent;
import com.fasterxml.jackson.annotation.JsonInclude;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonTypeInfo;
import com.fasterxml.jackson.annotation.JsonTypeName;
import java.util.Map;

/**
 * Describes all the settings to be used when analyzing a video in order to detect (and optionally redact) all the faces
 * present.
 */
@JsonTypeInfo(use = JsonTypeInfo.Id.NAME, include = JsonTypeInfo.As.PROPERTY, property = "@odata.type")
@JsonTypeName("#Microsoft.Media.FaceDetectorPreset")
@Fluent
public final class FaceDetectorPreset extends Preset {
    /*
     * Specifies the maximum resolution at which your video is analyzed. The default behavior is "SourceResolution,"
     * which will keep the input video at its original resolution when analyzed. Using "StandardDefinition" will resize
     * input videos to standard definition while preserving the appropriate aspect ratio. It will only resize if the
     * video is of higher resolution. For example, a 1920x1080 input would be scaled to 640x360 before processing.
     * Switching to "StandardDefinition" will reduce the time it takes to process high resolution video. It may also
     * reduce the cost of using this component (see
     * https://azure.microsoft.com/en-us/pricing/details/media-services/#analytics for details). However, faces that
     * end up being too small in the resized video may not be detected.
     */
    @JsonProperty(value = "resolution")
    private AnalysisResolution resolution;

    /*
     * This mode provides the ability to choose between the following settings: 1) Analyze - For detection only.This
     * mode generates a metadata JSON file marking appearances of faces throughout the video.Where possible,
     * appearances of the same person are assigned the same ID. 2) Combined - Additionally redacts(blurs) detected
     * faces. 3) Redact - This enables a 2-pass process, allowing for selective redaction of a subset of detected
     * faces.It takes in the metadata file from a prior analyze pass, along with the source video, and a user-selected
     * subset of IDs that require redaction.
     */
    @JsonProperty(value = "mode")
    private FaceRedactorMode mode;

    /*
     * Blur type
     */
    @JsonProperty(value = "blurType")
    private BlurType blurType;

    /*
     * Dictionary containing key value pairs for parameters not exposed in the preset itself
     */
    @JsonProperty(value = "experimentalOptions")
    @JsonInclude(value = JsonInclude.Include.NON_NULL, content = JsonInclude.Include.ALWAYS)
    private Map<String, String> experimentalOptions;

    /** Creates an instance of FaceDetectorPreset class. */
    public FaceDetectorPreset() {
    }

    /**
     * Get the resolution property: Specifies the maximum resolution at which your video is analyzed. The default
     * behavior is "SourceResolution," which will keep the input video at its original resolution when analyzed. Using
     * "StandardDefinition" will resize input videos to standard definition while preserving the appropriate aspect
     * ratio. It will only resize if the video is of higher resolution. For example, a 1920x1080 input would be scaled
     * to 640x360 before processing. Switching to "StandardDefinition" will reduce the time it takes to process high
     * resolution video. It may also reduce the cost of using this component (see
     * https://azure.microsoft.com/en-us/pricing/details/media-services/#analytics for details). However, faces that end
     * up being too small in the resized video may not be detected.
     *
     * @return the resolution value.
     */
    public AnalysisResolution resolution() {
        return this.resolution;
    }

    /**
     * Set the resolution property: Specifies the maximum resolution at which your video is analyzed. The default
     * behavior is "SourceResolution," which will keep the input video at its original resolution when analyzed. Using
     * "StandardDefinition" will resize input videos to standard definition while preserving the appropriate aspect
     * ratio. It will only resize if the video is of higher resolution. For example, a 1920x1080 input would be scaled
     * to 640x360 before processing. Switching to "StandardDefinition" will reduce the time it takes to process high
     * resolution video. It may also reduce the cost of using this component (see
     * https://azure.microsoft.com/en-us/pricing/details/media-services/#analytics for details). However, faces that end
     * up being too small in the resized video may not be detected.
     *
     * @param resolution the resolution value to set.
     * @return the FaceDetectorPreset object itself.
     */
    public FaceDetectorPreset withResolution(AnalysisResolution resolution) {
        this.resolution = resolution;
        return this;
    }

    /**
     * Get the mode property: This mode provides the ability to choose between the following settings: 1) Analyze - For
     * detection only.This mode generates a metadata JSON file marking appearances of faces throughout the video.Where
     * possible, appearances of the same person are assigned the same ID. 2) Combined - Additionally redacts(blurs)
     * detected faces. 3) Redact - This enables a 2-pass process, allowing for selective redaction of a subset of
     * detected faces.It takes in the metadata file from a prior analyze pass, along with the source video, and a
     * user-selected subset of IDs that require redaction.
     *
     * @return the mode value.
     */
    public FaceRedactorMode mode() {
        return this.mode;
    }

    /**
     * Set the mode property: This mode provides the ability to choose between the following settings: 1) Analyze - For
     * detection only.This mode generates a metadata JSON file marking appearances of faces throughout the video.Where
     * possible, appearances of the same person are assigned the same ID. 2) Combined - Additionally redacts(blurs)
     * detected faces. 3) Redact - This enables a 2-pass process, allowing for selective redaction of a subset of
     * detected faces.It takes in the metadata file from a prior analyze pass, along with the source video, and a
     * user-selected subset of IDs that require redaction.
     *
     * @param mode the mode value to set.
     * @return the FaceDetectorPreset object itself.
     */
    public FaceDetectorPreset withMode(FaceRedactorMode mode) {
        this.mode = mode;
        return this;
    }

    /**
     * Get the blurType property: Blur type.
     *
     * @return the blurType value.
     */
    public BlurType blurType() {
        return this.blurType;
    }

    /**
     * Set the blurType property: Blur type.
     *
     * @param blurType the blurType value to set.
     * @return the FaceDetectorPreset object itself.
     */
    public FaceDetectorPreset withBlurType(BlurType blurType) {
        this.blurType = blurType;
        return this;
    }

    /**
     * Get the experimentalOptions property: Dictionary containing key value pairs for parameters not exposed in the
     * preset itself.
     *
     * @return the experimentalOptions value.
     */
    public Map<String, String> experimentalOptions() {
        return this.experimentalOptions;
    }

    /**
     * Set the experimentalOptions property: Dictionary containing key value pairs for parameters not exposed in the
     * preset itself.
     *
     * @param experimentalOptions the experimentalOptions value to set.
     * @return the FaceDetectorPreset object itself.
     */
    public FaceDetectorPreset withExperimentalOptions(Map<String, String> experimentalOptions) {
        this.experimentalOptions = experimentalOptions;
        return this;
    }

    /**
     * Validates the instance.
     *
     * @throws IllegalArgumentException thrown if the instance is not valid.
     */
    @Override
    public void validate() {
        super.validate();
    }
}
