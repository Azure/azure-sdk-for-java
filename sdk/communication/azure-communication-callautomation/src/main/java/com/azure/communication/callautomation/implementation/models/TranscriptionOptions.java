// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) AutoRest Code Generator.

package com.azure.communication.callautomation.implementation.models;

import com.azure.core.annotation.Fluent;
import com.fasterxml.jackson.annotation.JsonProperty;

/** Configuration of live transcription. */
@Fluent
public final class TranscriptionOptions {
    /*
     * Transport URL for live transcription
     */
    @JsonProperty(value = "transportUrl", required = true)
    private String transportUrl;

    /*
     * The type of transport to be used for live transcription, eg. Websocket
     */
    @JsonProperty(value = "transportType", required = true)
    private TranscriptionTransportTypeInternal transportType;

    /*
     * Defines the locale for the data e.g en-CA, en-AU
     */
    @JsonProperty(value = "locale", required = true)
    private String locale;

    /*
     * Endpoint where the custom model was deployed.
     */
    @JsonProperty(value = "speechRecognitionModelEndpointId")
    private String speechRecognitionModelEndpointId;

    /*
     * Determines if the transcription should be started immediately after call
     * is answered or not.
     */
    @JsonProperty(value = "startTranscription", required = true)
    private boolean startTranscription;

    /*
     * Enables intermediate results for the transcribed speech.
     */
    @JsonProperty(value = "enableIntermediateResults")
    private Boolean enableIntermediateResults;

    /**
     * Get the transportUrl property: Transport URL for live transcription.
     *
     * @return the transportUrl value.
     */
    public String getTransportUrl() {
        return this.transportUrl;
    }

    /**
     * Set the transportUrl property: Transport URL for live transcription.
     *
     * @param transportUrl the transportUrl value to set.
     * @return the TranscriptionOptions object itself.
     */
    public TranscriptionOptions setTransportUrl(String transportUrl) {
        this.transportUrl = transportUrl;
        return this;
    }

    /**
     * Get the transportType property: The type of transport to be used for live transcription, eg. Websocket.
     *
     * @return the transportType value.
     */
    public TranscriptionTransportTypeInternal getTransportType() {
        return this.transportType;
    }

    /**
     * Set the transportType property: The type of transport to be used for live transcription, eg. Websocket.
     *
     * @param transportType the transportType value to set.
     * @return the TranscriptionOptions object itself.
     */
    public TranscriptionOptions setTransportType(TranscriptionTransportTypeInternal transportType) {
        this.transportType = transportType;
        return this;
    }

    /**
     * Get the locale property: Defines the locale for the data e.g en-CA, en-AU.
     *
     * @return the locale value.
     */
    public String getLocale() {
        return this.locale;
    }

    /**
     * Set the locale property: Defines the locale for the data e.g en-CA, en-AU.
     *
     * @param locale the locale value to set.
     * @return the TranscriptionOptions object itself.
     */
    public TranscriptionOptions setLocale(String locale) {
        this.locale = locale;
        return this;
    }

    /**
     * Get the speechRecognitionModelEndpointId property: Endpoint where the custom model was deployed.
     *
     * @return the speechRecognitionModelEndpointId value.
     */
    public String getSpeechRecognitionModelEndpointId() {
        return this.speechRecognitionModelEndpointId;
    }

    /**
     * Set the speechRecognitionModelEndpointId property: Endpoint where the custom model was deployed.
     *
     * @param speechRecognitionModelEndpointId the speechRecognitionModelEndpointId value to set.
     * @return the TranscriptionOptions object itself.
     */
    public TranscriptionOptions setSpeechRecognitionModelEndpointId(String speechRecognitionModelEndpointId) {
        this.speechRecognitionModelEndpointId = speechRecognitionModelEndpointId;
        return this;
    }

    /**
     * Get the startTranscription property: Determines if the transcription should be started immediately after call is
     * answered or not.
     *
     * @return the startTranscription value.
     */
    public boolean isStartTranscription() {
        return this.startTranscription;
    }

    /**
     * Set the startTranscription property: Determines if the transcription should be started immediately after call is
     * answered or not.
     *
     * @param startTranscription the startTranscription value to set.
     * @return the TranscriptionOptions object itself.
     */
    public TranscriptionOptions setStartTranscription(boolean startTranscription) {
        this.startTranscription = startTranscription;
        return this;
    }

    /**
     * Get the enableIntermediateResults property: Enables intermediate results for the transcribed speech.
     *
     * @return the enableIntermediateResults value.
     */
    public Boolean isEnableIntermediateResults() {
        return this.enableIntermediateResults;
    }

    /**
     * Set the enableIntermediateResults property: Enables intermediate results for the transcribed speech.
     *
     * @param enableIntermediateResults the enableIntermediateResults value to set.
     * @return the TranscriptionOptions object itself.
     */
    public TranscriptionOptions setEnableIntermediateResults(Boolean enableIntermediateResults) {
        this.enableIntermediateResults = enableIntermediateResults;
        return this;
    }
}
