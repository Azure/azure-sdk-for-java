// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) TypeSpec Code Generator.
package com.azure.ai.vision.face;

import com.azure.ai.vision.face.implementation.FaceClientImpl;
import com.azure.ai.vision.face.implementation.models.DetectFromUrlImplOptions;
import com.azure.ai.vision.face.implementation.models.DetectFromUrlImplRequest;
import com.azure.ai.vision.face.implementation.models.FindSimilarRequest;
import com.azure.ai.vision.face.implementation.models.GroupRequest;
import com.azure.ai.vision.face.implementation.models.VerifyFaceToFaceRequest;
import com.azure.ai.vision.face.models.FaceAttributeType;
import com.azure.ai.vision.face.models.FaceDetectionModel;
import com.azure.ai.vision.face.models.FaceDetectionResult;
import com.azure.ai.vision.face.models.FaceFindSimilarResult;
import com.azure.ai.vision.face.models.FaceGroupingResult;
import com.azure.ai.vision.face.models.FaceRecognitionModel;
import com.azure.ai.vision.face.models.FaceVerificationResult;
import com.azure.ai.vision.face.models.FindSimilarMatchMode;
import com.azure.core.annotation.Generated;
import com.azure.core.annotation.ReturnType;
import com.azure.core.annotation.ServiceClient;
import com.azure.core.annotation.ServiceMethod;
import com.azure.core.exception.ClientAuthenticationException;
import com.azure.core.exception.HttpResponseException;
import com.azure.core.exception.ResourceModifiedException;
import com.azure.core.exception.ResourceNotFoundException;
import com.azure.core.http.rest.RequestOptions;
import com.azure.core.http.rest.Response;
import com.azure.core.util.BinaryData;
import com.azure.core.util.serializer.TypeReference;
import java.util.List;
import java.util.Objects;
import java.util.stream.Collectors;
import com.azure.ai.vision.face.models.DetectOptions;
import static com.azure.ai.vision.face.implementation.ClientUtils.addOptionalQueryParameterForDetection;
import static com.azure.ai.vision.face.implementation.ClientUtils.addRequiredQueryParameterForDetection;

/**
 * Initializes a new instance of the synchronous FaceClient type.
 */
@ServiceClient(builder = FaceClientBuilder.class)
public final class FaceClient {

    @Generated
    private final FaceClientImpl serviceClient;

    /**
     * Initializes an instance of FaceClient class.
     *
     * @param serviceClient the service client implementation.
     */
    @Generated
    FaceClient(FaceClientImpl serviceClient) {
        this.serviceClient = serviceClient;
    }

    /**
     * Given query face's faceId, to search the similar-looking faces from a faceId array. A faceId array contains the
     * faces created by Detect.
     *
     * Depending on the input the returned similar faces list contains faceIds or persistedFaceIds ranked by similarity.
     *
     * Find similar has two working modes, "matchPerson" and "matchFace". "matchPerson" is the default mode that it
     * tries to find faces of the same person as possible by using internal same-person thresholds. It is useful to find
     * a known person's other photos. Note that an empty list will be returned if no faces pass the internal thresholds.
     * "matchFace" mode ignores same-person thresholds and returns ranked similar faces anyway, even the similarity is
     * low. It can be used in the cases like searching celebrity-looking faces.
     *
     * The 'recognitionModel' associated with the query faceId should be the same as the 'recognitionModel' used by the
     * target faceId array.
     * <p><strong>Request Body Schema</strong></p>
     * 
     * <pre>{@code
     * {
     *     faceId: String (Required)
     *     maxNumOfCandidatesReturned: Integer (Optional)
     *     mode: String(matchPerson/matchFace) (Optional)
     *     faceIds (Required): [
     *         String (Required)
     *     ]
     * }
     * }</pre>
     * 
     * <p><strong>Response Body Schema</strong></p>
     * 
     * <pre>{@code
     * [
     *      (Required){
     *         confidence: double (Required)
     *         faceId: String (Optional)
     *         persistedFaceId: String (Optional)
     *     }
     * ]
     * }</pre>
     *
     * @param findSimilarRequest The findSimilarRequest parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the response body along with {@link Response}.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> findSimilarWithResponse(BinaryData findSimilarRequest, RequestOptions requestOptions) {
        return this.serviceClient.findSimilarWithResponse(findSimilarRequest, requestOptions);
    }

    /**
     * Verify whether two faces belong to a same person.
     *
     * &gt; [!NOTE]
     * &gt;
     * &gt; *
     * &gt; * Higher face image quality means better identification precision. Please consider high-quality faces:
     * frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.
     * &gt; * For the scenarios that are sensitive to accuracy please make your own judgment.
     * &gt; * The 'recognitionModel' associated with the both faces should be the same.
     * <p><strong>Request Body Schema</strong></p>
     * 
     * <pre>{@code
     * {
     *     faceId1: String (Required)
     *     faceId2: String (Required)
     * }
     * }</pre>
     * 
     * <p><strong>Response Body Schema</strong></p>
     * 
     * <pre>{@code
     * {
     *     isIdentical: boolean (Required)
     *     confidence: double (Required)
     * }
     * }</pre>
     *
     * @param verifyFaceToFaceRequest The verifyFaceToFaceRequest parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return verify result along with {@link Response}.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> verifyFaceToFaceWithResponse(BinaryData verifyFaceToFaceRequest,
        RequestOptions requestOptions) {
        return this.serviceClient.verifyFaceToFaceWithResponse(verifyFaceToFaceRequest, requestOptions);
    }

    /**
     * Divide candidate faces into groups based on face similarity.
     *
     * &gt;
     * *
     * * The output is one or more disjointed face groups and a messyGroup. A face group contains faces that have
     * similar looking, often of the same person. Face groups are ranked by group size, i.e. number of faces. Notice
     * that faces belonging to a same person might be split into several groups in the result.
     * * MessyGroup is a special face group containing faces that cannot find any similar counterpart face from original
     * faces. The messyGroup will not appear in the result if all faces found their counterparts.
     * * Group API needs at least 2 candidate faces and 1000 at most. We suggest to try "Verify Face To Face" when you
     * only have 2 candidate faces.
     * * The 'recognitionModel' associated with the query faces' faceIds should be the same.
     * <p><strong>Request Body Schema</strong></p>
     * 
     * <pre>{@code
     * {
     *     faceIds (Required): [
     *         String (Required)
     *     ]
     * }
     * }</pre>
     * 
     * <p><strong>Response Body Schema</strong></p>
     * 
     * <pre>{@code
     * {
     *     groups (Required): [
     *          (Required)[
     *             String (Required)
     *         ]
     *     ]
     *     messyGroup (Required): [
     *         String (Required)
     *     ]
     * }
     * }</pre>
     *
     * @param groupRequest The groupRequest parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return response body for group face operation along with {@link Response}.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    public Response<BinaryData> groupWithResponse(BinaryData groupRequest, RequestOptions requestOptions) {
        return this.serviceClient.groupWithResponse(groupRequest, requestOptions);
    }

    /**
     * Given query face's faceId, to search the similar-looking faces from a faceId array. A faceId array contains the
     * faces created by Detect.
     *
     * Depending on the input the returned similar faces list contains faceIds or persistedFaceIds ranked by similarity.
     *
     * Find similar has two working modes, "matchPerson" and "matchFace". "matchPerson" is the default mode that it
     * tries to find faces of the same person as possible by using internal same-person thresholds. It is useful to find
     * a known person's other photos. Note that an empty list will be returned if no faces pass the internal thresholds.
     * "matchFace" mode ignores same-person thresholds and returns ranked similar faces anyway, even the similarity is
     * low. It can be used in the cases like searching celebrity-looking faces.
     *
     * The 'recognitionModel' associated with the query faceId should be the same as the 'recognitionModel' used by the
     * target faceId array.
     *
     * @param faceId faceId of the query face. User needs to call "Detect" first to get a valid faceId. Note that this
     * faceId is not persisted and will expire 24 hours after the detection call.
     * @param faceIds An array of candidate faceIds. All of them are created by "Detect" and the faceIds will expire 24
     * hours after the detection call. The number of faceIds is limited to 1000.
     * @param maxNumOfCandidatesReturned The number of top similar faces returned. The valid range is [1, 1000]. Default
     * value is 20.
     * @param mode Similar face searching mode. It can be 'matchPerson' or 'matchFace'. Default value is 'matchPerson'.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    public List<FaceFindSimilarResult> findSimilar(String faceId, List<String> faceIds,
        Integer maxNumOfCandidatesReturned, FindSimilarMatchMode mode) {
        // Generated convenience method for findSimilarWithResponse
        RequestOptions requestOptions = new RequestOptions();
        FindSimilarRequest findSimilarRequestObj
            = new FindSimilarRequest(faceId, faceIds).setMaxNumOfCandidatesReturned(maxNumOfCandidatesReturned)
                .setMode(mode);
        BinaryData findSimilarRequest = BinaryData.fromObject(findSimilarRequestObj);
        return findSimilarWithResponse(findSimilarRequest, requestOptions).getValue()
            .toObject(TYPE_REFERENCE_LIST_FACE_FIND_SIMILAR_RESULT);
    }

    /**
     * Given query face's faceId, to search the similar-looking faces from a faceId array. A faceId array contains the
     * faces created by Detect.
     *
     * Depending on the input the returned similar faces list contains faceIds or persistedFaceIds ranked by similarity.
     *
     * Find similar has two working modes, "matchPerson" and "matchFace". "matchPerson" is the default mode that it
     * tries to find faces of the same person as possible by using internal same-person thresholds. It is useful to find
     * a known person's other photos. Note that an empty list will be returned if no faces pass the internal thresholds.
     * "matchFace" mode ignores same-person thresholds and returns ranked similar faces anyway, even the similarity is
     * low. It can be used in the cases like searching celebrity-looking faces.
     *
     * The 'recognitionModel' associated with the query faceId should be the same as the 'recognitionModel' used by the
     * target faceId array.
     *
     * @param faceId faceId of the query face. User needs to call "Detect" first to get a valid faceId. Note that this
     * faceId is not persisted and will expire 24 hours after the detection call.
     * @param faceIds An array of candidate faceIds. All of them are created by "Detect" and the faceIds will expire 24
     * hours after the detection call. The number of faceIds is limited to 1000.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    public List<FaceFindSimilarResult> findSimilar(String faceId, List<String> faceIds) {
        // Generated convenience method for findSimilarWithResponse
        RequestOptions requestOptions = new RequestOptions();
        FindSimilarRequest findSimilarRequestObj = new FindSimilarRequest(faceId, faceIds);
        BinaryData findSimilarRequest = BinaryData.fromObject(findSimilarRequestObj);
        return findSimilarWithResponse(findSimilarRequest, requestOptions).getValue()
            .toObject(TYPE_REFERENCE_LIST_FACE_FIND_SIMILAR_RESULT);
    }

    /**
     * Verify whether two faces belong to a same person.
     *
     * &gt; [!NOTE]
     * &gt;
     * &gt; *
     * &gt; * Higher face image quality means better identification precision. Please consider high-quality faces:
     * frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.
     * &gt; * For the scenarios that are sensitive to accuracy please make your own judgment.
     * &gt; * The 'recognitionModel' associated with the both faces should be the same.
     *
     * @param faceId1 The faceId of one face, come from "Detect".
     * @param faceId2 The faceId of another face, come from "Detect".
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return verify result.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    public FaceVerificationResult verifyFaceToFace(String faceId1, String faceId2) {
        // Generated convenience method for verifyFaceToFaceWithResponse
        RequestOptions requestOptions = new RequestOptions();
        VerifyFaceToFaceRequest verifyFaceToFaceRequestObj = new VerifyFaceToFaceRequest(faceId1, faceId2);
        BinaryData verifyFaceToFaceRequest = BinaryData.fromObject(verifyFaceToFaceRequestObj);
        return verifyFaceToFaceWithResponse(verifyFaceToFaceRequest, requestOptions).getValue()
            .toObject(FaceVerificationResult.class);
    }

    /**
     * Divide candidate faces into groups based on face similarity.
     *
     * &gt;
     * *
     * * The output is one or more disjointed face groups and a messyGroup. A face group contains faces that have
     * similar looking, often of the same person. Face groups are ranked by group size, i.e. number of faces. Notice
     * that faces belonging to a same person might be split into several groups in the result.
     * * MessyGroup is a special face group containing faces that cannot find any similar counterpart face from original
     * faces. The messyGroup will not appear in the result if all faces found their counterparts.
     * * Group API needs at least 2 candidate faces and 1000 at most. We suggest to try "Verify Face To Face" when you
     * only have 2 candidate faces.
     * * The 'recognitionModel' associated with the query faces' faceIds should be the same.
     *
     * @param faceIds Array of candidate faceIds created by "Detect". The maximum is 1000 faces.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return response body for group face operation.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    public FaceGroupingResult group(List<String> faceIds) {
        // Generated convenience method for groupWithResponse
        RequestOptions requestOptions = new RequestOptions();
        GroupRequest groupRequestObj = new GroupRequest(faceIds);
        BinaryData groupRequest = BinaryData.fromObject(groupRequestObj);
        return groupWithResponse(groupRequest, requestOptions).getValue().toObject(FaceGroupingResult.class);
    }

    @Generated
    private static final TypeReference<List<FaceFindSimilarResult>> TYPE_REFERENCE_LIST_FACE_FIND_SIMILAR_RESULT
        = new TypeReference<List<FaceFindSimilarResult>>() {
        };

    /**
     * Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.
     *
     * &gt; [!IMPORTANT]
     * &gt; To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of
     * services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and
     * makeup. Read more about this decision
     * https://azure.microsoft.com/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/.
     *
     * *
     * * No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an
     * identifier of the face feature and will be used in "Identify", "Verify", and "Find Similar". The stored face
     * features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call.
     * * Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion,
     * accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific
     * attributes may not be highly accurate.
     * * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.
     * * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with
     * dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.
     * * Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.
     * * For optimal results when querying "Identify", "Verify", and "Find Similar" ('returnFaceId' is true), please use
     * faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).
     * * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer
     * to https://learn.microsoft.com/azure/ai-services/computer-vision/how-to/specify-detection-model
     * * 'detection_02': Face attributes and landmarks are disabled if you choose this detection model.
     * * 'detection_03': Face attributes (mask, blur, and headPose) and landmarks are supported if you choose this
     * detection model.
     * * Different 'recognitionModel' values are provided. If follow-up operations like "Verify", "Identify", "Find
     * Similar" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value
     * for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need
     * in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model.
     * More details, please refer to
     * https://learn.microsoft.com/azure/ai-services/computer-vision/how-to/specify-recognition-model.
     * <p><strong>Query Parameters</strong></p>
     * <table border="1">
     * <caption>Query Parameters</caption>
     * <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     * <tr><td>detectionModel</td><td>String</td><td>No</td><td>The 'detectionModel' associated with the detected
     * faceIds. Supported 'detectionModel' values include 'detection_01', 'detection_02' and 'detection_03'. The default
     * value is 'detection_01'. Allowed values: "detection_01", "detection_02", "detection_03".</td></tr>
     * <tr><td>recognitionModel</td><td>String</td><td>No</td><td>The 'recognitionModel' associated with the detected
     * faceIds. Supported 'recognitionModel' values include 'recognition_01', 'recognition_02', 'recognition_03' or
     * 'recognition_04'. The default value is 'recognition_01'. 'recognition_04' is recommended since its accuracy is
     * improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared
     * with 'recognition_01' and 'recognition_02'. Allowed values: "recognition_01", "recognition_02", "recognition_03",
     * "recognition_04".</td></tr>
     * <tr><td>returnFaceId</td><td>Boolean</td><td>No</td><td>Return faceIds of the detected faces or not. The default
     * value is true.</td></tr>
     * <tr><td>returnFaceAttributes</td><td>List&lt;String&gt;</td><td>No</td><td>Analyze and return the one or more
     * specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Face
     * attribute analysis has additional computational and time cost. In the form of "," separated string.</td></tr>
     * <tr><td>returnFaceLandmarks</td><td>Boolean</td><td>No</td><td>Return face landmarks of the detected faces or
     * not. The default value is false.</td></tr>
     * <tr><td>returnRecognitionModel</td><td>Boolean</td><td>No</td><td>Return 'recognitionModel' or not. The default
     * value is false. This is only applicable when returnFaceId = true.</td></tr>
     * <tr><td>faceIdTimeToLive</td><td>Integer</td><td>No</td><td>The number of seconds for the face ID being cached.
     * Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours).</td></tr>
     * </table>
     * You can add these to a request with {@link RequestOptions#addQueryParam}
     * <p><strong>Request Body Schema</strong></p>
     * 
     * <pre>{@code
     * {
     *     url: String (Required)
     * }
     * }</pre>
     * 
     * <p><strong>Response Body Schema</strong></p>
     * 
     * <pre>{@code
     * [
     *      (Required){
     *         faceId: String (Optional)
     *         recognitionModel: String(recognition_01/recognition_02/recognition_03/recognition_04) (Optional)
     *         faceRectangle (Required): {
     *             top: int (Required)
     *             left: int (Required)
     *             width: int (Required)
     *             height: int (Required)
     *         }
     *         faceLandmarks (Optional): {
     *             pupilLeft (Required): {
     *                 x: double (Required)
     *                 y: double (Required)
     *             }
     *             pupilRight (Required): (recursive schema, see pupilRight above)
     *             noseTip (Required): (recursive schema, see noseTip above)
     *             mouthLeft (Required): (recursive schema, see mouthLeft above)
     *             mouthRight (Required): (recursive schema, see mouthRight above)
     *             eyebrowLeftOuter (Required): (recursive schema, see eyebrowLeftOuter above)
     *             eyebrowLeftInner (Required): (recursive schema, see eyebrowLeftInner above)
     *             eyeLeftOuter (Required): (recursive schema, see eyeLeftOuter above)
     *             eyeLeftTop (Required): (recursive schema, see eyeLeftTop above)
     *             eyeLeftBottom (Required): (recursive schema, see eyeLeftBottom above)
     *             eyeLeftInner (Required): (recursive schema, see eyeLeftInner above)
     *             eyebrowRightInner (Required): (recursive schema, see eyebrowRightInner above)
     *             eyebrowRightOuter (Required): (recursive schema, see eyebrowRightOuter above)
     *             eyeRightInner (Required): (recursive schema, see eyeRightInner above)
     *             eyeRightTop (Required): (recursive schema, see eyeRightTop above)
     *             eyeRightBottom (Required): (recursive schema, see eyeRightBottom above)
     *             eyeRightOuter (Required): (recursive schema, see eyeRightOuter above)
     *             noseRootLeft (Required): (recursive schema, see noseRootLeft above)
     *             noseRootRight (Required): (recursive schema, see noseRootRight above)
     *             noseLeftAlarTop (Required): (recursive schema, see noseLeftAlarTop above)
     *             noseRightAlarTop (Required): (recursive schema, see noseRightAlarTop above)
     *             noseLeftAlarOutTip (Required): (recursive schema, see noseLeftAlarOutTip above)
     *             noseRightAlarOutTip (Required): (recursive schema, see noseRightAlarOutTip above)
     *             upperLipTop (Required): (recursive schema, see upperLipTop above)
     *             upperLipBottom (Required): (recursive schema, see upperLipBottom above)
     *             underLipTop (Required): (recursive schema, see underLipTop above)
     *             underLipBottom (Required): (recursive schema, see underLipBottom above)
     *         }
     *         faceAttributes (Optional): {
     *             age: Double (Optional)
     *             smile: Double (Optional)
     *             facialHair (Optional): {
     *                 moustache: double (Required)
     *                 beard: double (Required)
     *                 sideburns: double (Required)
     *             }
     *             glasses: String(noGlasses/readingGlasses/sunglasses/swimmingGoggles) (Optional)
     *             headPose (Optional): {
     *                 pitch: double (Required)
     *                 roll: double (Required)
     *                 yaw: double (Required)
     *             }
     *             hair (Optional): {
     *                 bald: double (Required)
     *                 invisible: boolean (Required)
     *                 hairColor (Required): [
     *                      (Required){
     *                         color: String(unknown/white/gray/blond/brown/red/black/other) (Required)
     *                         confidence: double (Required)
     *                     }
     *                 ]
     *             }
     *             occlusion (Optional): {
     *                 foreheadOccluded: boolean (Required)
     *                 eyeOccluded: boolean (Required)
     *                 mouthOccluded: boolean (Required)
     *             }
     *             accessories (Optional): [
     *                  (Optional){
     *                     type: String(headwear/glasses/mask) (Required)
     *                     confidence: double (Required)
     *                 }
     *             ]
     *             blur (Optional): {
     *                 blurLevel: String(low/medium/high) (Required)
     *                 value: double (Required)
     *             }
     *             exposure (Optional): {
     *                 exposureLevel: String(underExposure/goodExposure/overExposure) (Required)
     *                 value: double (Required)
     *             }
     *             noise (Optional): {
     *                 noiseLevel: String(low/medium/high) (Required)
     *                 value: double (Required)
     *             }
     *             mask (Optional): {
     *                 noseAndMouthCovered: boolean (Required)
     *                 type: String(faceMask/noMask/otherMaskOrOcclusion/uncertain) (Required)
     *             }
     *             qualityForRecognition: String(low/medium/high) (Optional)
     *         }
     *     }
     * ]
     * }</pre>
     *
     * @param request The request parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the response body along with {@link Response}.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    Response<BinaryData> detectFromUrlImplWithResponse(BinaryData request, RequestOptions requestOptions) {
        return this.serviceClient.detectFromUrlImplWithResponse(request, requestOptions);
    }

    /**
     * Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.
     *
     * &gt; [!IMPORTANT]
     * &gt; To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of
     * services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and
     * makeup. Read more about this decision
     * https://azure.microsoft.com/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/.
     *
     * *
     * * No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an
     * identifier of the face feature and will be used in "Identify", "Verify", and "Find Similar". The stored face
     * features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call.
     * * Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion,
     * accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific
     * attributes may not be highly accurate.
     * * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.
     * * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with
     * dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.
     * * Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.
     * * For optimal results when querying "Identify", "Verify", and "Find Similar" ('returnFaceId' is true), please use
     * faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).
     * * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer
     * to https://learn.microsoft.com/azure/ai-services/computer-vision/how-to/specify-detection-model
     * * 'detection_02': Face attributes and landmarks are disabled if you choose this detection model.
     * * 'detection_03': Face attributes (mask, blur, and headPose) and landmarks are supported if you choose this
     * detection model.
     * * Different 'recognitionModel' values are provided. If follow-up operations like "Verify", "Identify", "Find
     * Similar" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value
     * for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need
     * in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model.
     * More details, please refer to
     * https://learn.microsoft.com/azure/ai-services/computer-vision/how-to/specify-recognition-model.
     * <p><strong>Query Parameters</strong></p>
     * <table border="1">
     * <caption>Query Parameters</caption>
     * <tr><th>Name</th><th>Type</th><th>Required</th><th>Description</th></tr>
     * <tr><td>detectionModel</td><td>String</td><td>No</td><td>The 'detectionModel' associated with the detected
     * faceIds. Supported 'detectionModel' values include 'detection_01', 'detection_02' and 'detection_03'. The default
     * value is 'detection_01'. Allowed values: "detection_01", "detection_02", "detection_03".</td></tr>
     * <tr><td>recognitionModel</td><td>String</td><td>No</td><td>The 'recognitionModel' associated with the detected
     * faceIds. Supported 'recognitionModel' values include 'recognition_01', 'recognition_02', 'recognition_03' or
     * 'recognition_04'. The default value is 'recognition_01'. 'recognition_04' is recommended since its accuracy is
     * improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared
     * with 'recognition_01' and 'recognition_02'. Allowed values: "recognition_01", "recognition_02", "recognition_03",
     * "recognition_04".</td></tr>
     * <tr><td>returnFaceId</td><td>Boolean</td><td>No</td><td>Return faceIds of the detected faces or not. The default
     * value is true.</td></tr>
     * <tr><td>returnFaceAttributes</td><td>List&lt;String&gt;</td><td>No</td><td>Analyze and return the one or more
     * specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Face
     * attribute analysis has additional computational and time cost. In the form of "," separated string.</td></tr>
     * <tr><td>returnFaceLandmarks</td><td>Boolean</td><td>No</td><td>Return face landmarks of the detected faces or
     * not. The default value is false.</td></tr>
     * <tr><td>returnRecognitionModel</td><td>Boolean</td><td>No</td><td>Return 'recognitionModel' or not. The default
     * value is false. This is only applicable when returnFaceId = true.</td></tr>
     * <tr><td>faceIdTimeToLive</td><td>Integer</td><td>No</td><td>The number of seconds for the face ID being cached.
     * Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours).</td></tr>
     * </table>
     * You can add these to a request with {@link RequestOptions#addQueryParam}
     * <p><strong>Request Body Schema</strong></p>
     * 
     * <pre>{@code
     * BinaryData
     * }</pre>
     * 
     * <p><strong>Response Body Schema</strong></p>
     * 
     * <pre>{@code
     * [
     *      (Required){
     *         faceId: String (Optional)
     *         recognitionModel: String(recognition_01/recognition_02/recognition_03/recognition_04) (Optional)
     *         faceRectangle (Required): {
     *             top: int (Required)
     *             left: int (Required)
     *             width: int (Required)
     *             height: int (Required)
     *         }
     *         faceLandmarks (Optional): {
     *             pupilLeft (Required): {
     *                 x: double (Required)
     *                 y: double (Required)
     *             }
     *             pupilRight (Required): (recursive schema, see pupilRight above)
     *             noseTip (Required): (recursive schema, see noseTip above)
     *             mouthLeft (Required): (recursive schema, see mouthLeft above)
     *             mouthRight (Required): (recursive schema, see mouthRight above)
     *             eyebrowLeftOuter (Required): (recursive schema, see eyebrowLeftOuter above)
     *             eyebrowLeftInner (Required): (recursive schema, see eyebrowLeftInner above)
     *             eyeLeftOuter (Required): (recursive schema, see eyeLeftOuter above)
     *             eyeLeftTop (Required): (recursive schema, see eyeLeftTop above)
     *             eyeLeftBottom (Required): (recursive schema, see eyeLeftBottom above)
     *             eyeLeftInner (Required): (recursive schema, see eyeLeftInner above)
     *             eyebrowRightInner (Required): (recursive schema, see eyebrowRightInner above)
     *             eyebrowRightOuter (Required): (recursive schema, see eyebrowRightOuter above)
     *             eyeRightInner (Required): (recursive schema, see eyeRightInner above)
     *             eyeRightTop (Required): (recursive schema, see eyeRightTop above)
     *             eyeRightBottom (Required): (recursive schema, see eyeRightBottom above)
     *             eyeRightOuter (Required): (recursive schema, see eyeRightOuter above)
     *             noseRootLeft (Required): (recursive schema, see noseRootLeft above)
     *             noseRootRight (Required): (recursive schema, see noseRootRight above)
     *             noseLeftAlarTop (Required): (recursive schema, see noseLeftAlarTop above)
     *             noseRightAlarTop (Required): (recursive schema, see noseRightAlarTop above)
     *             noseLeftAlarOutTip (Required): (recursive schema, see noseLeftAlarOutTip above)
     *             noseRightAlarOutTip (Required): (recursive schema, see noseRightAlarOutTip above)
     *             upperLipTop (Required): (recursive schema, see upperLipTop above)
     *             upperLipBottom (Required): (recursive schema, see upperLipBottom above)
     *             underLipTop (Required): (recursive schema, see underLipTop above)
     *             underLipBottom (Required): (recursive schema, see underLipBottom above)
     *         }
     *         faceAttributes (Optional): {
     *             age: Double (Optional)
     *             smile: Double (Optional)
     *             facialHair (Optional): {
     *                 moustache: double (Required)
     *                 beard: double (Required)
     *                 sideburns: double (Required)
     *             }
     *             glasses: String(noGlasses/readingGlasses/sunglasses/swimmingGoggles) (Optional)
     *             headPose (Optional): {
     *                 pitch: double (Required)
     *                 roll: double (Required)
     *                 yaw: double (Required)
     *             }
     *             hair (Optional): {
     *                 bald: double (Required)
     *                 invisible: boolean (Required)
     *                 hairColor (Required): [
     *                      (Required){
     *                         color: String(unknown/white/gray/blond/brown/red/black/other) (Required)
     *                         confidence: double (Required)
     *                     }
     *                 ]
     *             }
     *             occlusion (Optional): {
     *                 foreheadOccluded: boolean (Required)
     *                 eyeOccluded: boolean (Required)
     *                 mouthOccluded: boolean (Required)
     *             }
     *             accessories (Optional): [
     *                  (Optional){
     *                     type: String(headwear/glasses/mask) (Required)
     *                     confidence: double (Required)
     *                 }
     *             ]
     *             blur (Optional): {
     *                 blurLevel: String(low/medium/high) (Required)
     *                 value: double (Required)
     *             }
     *             exposure (Optional): {
     *                 exposureLevel: String(underExposure/goodExposure/overExposure) (Required)
     *                 value: double (Required)
     *             }
     *             noise (Optional): {
     *                 noiseLevel: String(low/medium/high) (Required)
     *                 value: double (Required)
     *             }
     *             mask (Optional): {
     *                 noseAndMouthCovered: boolean (Required)
     *                 type: String(faceMask/noMask/otherMaskOrOcclusion/uncertain) (Required)
     *             }
     *             qualityForRecognition: String(low/medium/high) (Optional)
     *         }
     *     }
     * ]
     * }</pre>
     *
     * @param imageContent The input image binary.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @return the response body along with {@link Response}.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    Response<BinaryData> detectImplWithResponse(BinaryData imageContent, RequestOptions requestOptions) {
        return this.serviceClient.detectImplWithResponse(imageContent, requestOptions);
    }

    /**
     * Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.
     *
     * &gt; [!IMPORTANT]
     * &gt; To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of
     * services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and
     * makeup. Read more about this decision
     * https://azure.microsoft.com/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/.
     *
     * *
     * * No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an
     * identifier of the face feature and will be used in "Identify", "Verify", and "Find Similar". The stored face
     * features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call.
     * * Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion,
     * accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific
     * attributes may not be highly accurate.
     * * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.
     * * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with
     * dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.
     * * Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.
     * * For optimal results when querying "Identify", "Verify", and "Find Similar" ('returnFaceId' is true), please use
     * faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).
     * * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer
     * to https://learn.microsoft.com/azure/ai-services/computer-vision/how-to/specify-detection-model
     * * 'detection_02': Face attributes and landmarks are disabled if you choose this detection model.
     * * 'detection_03': Face attributes (mask, blur, and headPose) and landmarks are supported if you choose this
     * detection model.
     * * Different 'recognitionModel' values are provided. If follow-up operations like "Verify", "Identify", "Find
     * Similar" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value
     * for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need
     * in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model.
     * More details, please refer to
     * https://learn.microsoft.com/azure/ai-services/computer-vision/how-to/specify-recognition-model.
     *
     * @param options Options for detectFromUrlImpl API.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    List<FaceDetectionResult> detectFromUrlImpl(DetectFromUrlImplOptions options) {
        // Generated convenience method for detectFromUrlImplWithResponse
        RequestOptions requestOptions = new RequestOptions();
        DetectFromUrlImplRequest requestObj = new DetectFromUrlImplRequest(options.getUrl());
        BinaryData request = BinaryData.fromObject(requestObj);
        FaceDetectionModel detectionModel = options.getDetectionModel();
        FaceRecognitionModel recognitionModel = options.getRecognitionModel();
        Boolean returnFaceId = options.isReturnFaceId();
        List<FaceAttributeType> returnFaceAttributes = options.getReturnFaceAttributes();
        Boolean returnFaceLandmarks = options.isReturnFaceLandmarks();
        Boolean returnRecognitionModel = options.isReturnRecognitionModel();
        Integer faceIdTimeToLive = options.getFaceIdTimeToLive();
        if (detectionModel != null) {
            requestOptions.addQueryParam("detectionModel", detectionModel.toString(), false);
        }
        if (recognitionModel != null) {
            requestOptions.addQueryParam("recognitionModel", recognitionModel.toString(), false);
        }
        if (returnFaceId != null) {
            requestOptions.addQueryParam("returnFaceId", String.valueOf(returnFaceId), false);
        }
        if (returnFaceAttributes != null) {
            requestOptions.addQueryParam("returnFaceAttributes",
                returnFaceAttributes.stream()
                    .map(paramItemValue -> Objects.toString(paramItemValue, ""))
                    .collect(Collectors.joining(",")),
                false);
        }
        if (returnFaceLandmarks != null) {
            requestOptions.addQueryParam("returnFaceLandmarks", String.valueOf(returnFaceLandmarks), false);
        }
        if (returnRecognitionModel != null) {
            requestOptions.addQueryParam("returnRecognitionModel", String.valueOf(returnRecognitionModel), false);
        }
        if (faceIdTimeToLive != null) {
            requestOptions.addQueryParam("faceIdTimeToLive", String.valueOf(faceIdTimeToLive), false);
        }
        return detectFromUrlImplWithResponse(request, requestOptions).getValue()
            .toObject(TYPE_REFERENCE_LIST_FACE_DETECTION_RESULT);
    }

    /**
     * Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.
     *
     * &gt; [!IMPORTANT]
     * &gt; To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of
     * services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and
     * makeup. Read more about this decision
     * https://azure.microsoft.com/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/.
     *
     * *
     * * No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an
     * identifier of the face feature and will be used in "Identify", "Verify", and "Find Similar". The stored face
     * features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call.
     * * Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion,
     * accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific
     * attributes may not be highly accurate.
     * * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.
     * * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with
     * dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.
     * * Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.
     * * For optimal results when querying "Identify", "Verify", and "Find Similar" ('returnFaceId' is true), please use
     * faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).
     * * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer
     * to https://learn.microsoft.com/azure/ai-services/computer-vision/how-to/specify-detection-model
     * * 'detection_02': Face attributes and landmarks are disabled if you choose this detection model.
     * * 'detection_03': Face attributes (mask, blur, and headPose) and landmarks are supported if you choose this
     * detection model.
     * * Different 'recognitionModel' values are provided. If follow-up operations like "Verify", "Identify", "Find
     * Similar" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value
     * for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need
     * in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model.
     * More details, please refer to
     * https://learn.microsoft.com/azure/ai-services/computer-vision/how-to/specify-recognition-model.
     *
     * @param imageContent The input image binary.
     * @param detectionModel The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel'
     * values include 'detection_01', 'detection_02' and 'detection_03'. The default value is 'detection_01'.
     * @param recognitionModel The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel'
     * values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'. The default value is
     * 'recognition_01'. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared
     * with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'.
     * @param returnFaceId Return faceIds of the detected faces or not. The default value is true.
     * @param returnFaceAttributes Analyze and return the one or more specified face attributes in the comma-separated
     * string like 'returnFaceAttributes=headPose,glasses'. Face attribute analysis has additional computational and
     * time cost.
     * @param returnFaceLandmarks Return face landmarks of the detected faces or not. The default value is false.
     * @param returnRecognitionModel Return 'recognitionModel' or not. The default value is false. This is only
     * applicable when returnFaceId = true.
     * @param faceIdTimeToLive The number of seconds for the face ID being cached. Supported range from 60 seconds up to
     * 86400 seconds. The default value is 86400 (24 hours).
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    List<FaceDetectionResult> detectImpl(BinaryData imageContent, FaceDetectionModel detectionModel,
        FaceRecognitionModel recognitionModel, Boolean returnFaceId, List<FaceAttributeType> returnFaceAttributes,
        Boolean returnFaceLandmarks, Boolean returnRecognitionModel, Integer faceIdTimeToLive) {
        // Generated convenience method for detectImplWithResponse
        RequestOptions requestOptions = new RequestOptions();
        if (detectionModel != null) {
            requestOptions.addQueryParam("detectionModel", detectionModel.toString(), false);
        }
        if (recognitionModel != null) {
            requestOptions.addQueryParam("recognitionModel", recognitionModel.toString(), false);
        }
        if (returnFaceId != null) {
            requestOptions.addQueryParam("returnFaceId", String.valueOf(returnFaceId), false);
        }
        if (returnFaceAttributes != null) {
            requestOptions.addQueryParam("returnFaceAttributes",
                returnFaceAttributes.stream()
                    .map(paramItemValue -> Objects.toString(paramItemValue, ""))
                    .collect(Collectors.joining(",")),
                false);
        }
        if (returnFaceLandmarks != null) {
            requestOptions.addQueryParam("returnFaceLandmarks", String.valueOf(returnFaceLandmarks), false);
        }
        if (returnRecognitionModel != null) {
            requestOptions.addQueryParam("returnRecognitionModel", String.valueOf(returnRecognitionModel), false);
        }
        if (faceIdTimeToLive != null) {
            requestOptions.addQueryParam("faceIdTimeToLive", String.valueOf(faceIdTimeToLive), false);
        }
        return detectImplWithResponse(imageContent, requestOptions).getValue()
            .toObject(TYPE_REFERENCE_LIST_FACE_DETECTION_RESULT);
    }

    /**
     * Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.
     *
     * &gt; [!IMPORTANT]
     * &gt; To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of
     * services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and
     * makeup. Read more about this decision
     * https://azure.microsoft.com/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/.
     *
     * *
     * * No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an
     * identifier of the face feature and will be used in "Identify", "Verify", and "Find Similar". The stored face
     * features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call.
     * * Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion,
     * accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific
     * attributes may not be highly accurate.
     * * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.
     * * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with
     * dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.
     * * Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.
     * * For optimal results when querying "Identify", "Verify", and "Find Similar" ('returnFaceId' is true), please use
     * faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).
     * * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer
     * to https://learn.microsoft.com/azure/ai-services/computer-vision/how-to/specify-detection-model
     * * 'detection_02': Face attributes and landmarks are disabled if you choose this detection model.
     * * 'detection_03': Face attributes (mask, blur, and headPose) and landmarks are supported if you choose this
     * detection model.
     * * Different 'recognitionModel' values are provided. If follow-up operations like "Verify", "Identify", "Find
     * Similar" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value
     * for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need
     * in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model.
     * More details, please refer to
     * https://learn.microsoft.com/azure/ai-services/computer-vision/how-to/specify-recognition-model.
     *
     * @param imageContent The input image binary.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @Generated
    @ServiceMethod(returns = ReturnType.SINGLE)
    List<FaceDetectionResult> detectImpl(BinaryData imageContent) {
        // Generated convenience method for detectImplWithResponse
        RequestOptions requestOptions = new RequestOptions();
        return detectImplWithResponse(imageContent, requestOptions).getValue()
            .toObject(TYPE_REFERENCE_LIST_FACE_DETECTION_RESULT);
    }

    @Generated
    private static final TypeReference<List<FaceDetectionResult>> TYPE_REFERENCE_LIST_FACE_DETECTION_RESULT
        = new TypeReference<List<FaceDetectionResult>>() {
        };

    /**
     * Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.
     *
     * &gt; [!IMPORTANT]
     * &gt; To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of
     * services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and
     * makeup. Read more about this decision
     * https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/.
     *
     * *
     * * No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an
     * identifier of the face feature and will be used in "Identify", "Verify", and "Find Similar". The stored face
     * features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call.
     * * Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion,
     * accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific
     * attributes may not be highly accurate.
     * * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.
     * * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with
     * dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.
     * * Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.
     * * For optimal results when querying "Identify", "Verify", and "Find Similar" ('returnFaceId' is true), please use
     * faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).
     * * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer
     * to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model
     * * 'detection_02': Face attributes and landmarks are disabled if you choose this detection model.
     * * 'detection_03': Face attributes (mask and headPose only) and landmarks are supported if you choose this
     * detection model.
     * * Different 'recognitionModel' values are provided. If follow-up operations like "Verify", "Identify", "Find
     * Similar" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value
     * for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need
     * in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model.
     * More details, please refer to
     * https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-recognition-model.
     *
     * @param imageContent The input image binary.
     * @param options Options for detect API.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public List<FaceDetectionResult> detect(BinaryData imageContent, DetectOptions options) {
        return this.detectImpl(imageContent, options.getDetectionModel(), options.getRecognitionModel(),
            options.isReturnFaceId(), options.getReturnFaceAttributes(), options.isReturnFaceLandmarks(),
            options.isReturnRecognitionModel(), options.getFaceIdTimeToLive());
    }

    /**
     * Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.
     *
     * &gt; [!IMPORTANT]
     * &gt; To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of
     * services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and
     * makeup. Read more about this decision
     * https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/.
     *
     * *
     * * No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an
     * identifier of the face feature and will be used in "Identify", "Verify", and "Find Similar". The stored face
     * features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call.
     * * Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion,
     * accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific
     * attributes may not be highly accurate.
     * * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.
     * * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with
     * dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.
     * * Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.
     * * For optimal results when querying "Identify", "Verify", and "Find Similar" ('returnFaceId' is true), please use
     * faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).
     * * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer
     * to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model
     * * 'detection_02': Face attributes and landmarks are disabled if you choose this detection model.
     * * 'detection_03': Face attributes (mask and headPose only) and landmarks are supported if you choose this
     * detection model.
     * * Different 'recognitionModel' values are provided. If follow-up operations like "Verify", "Identify", "Find
     * Similar" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value
     * for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need
     * in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model.
     * More details, please refer to
     * https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-recognition-model.
     *
     * @param imageContent The input image binary.
     * @param detectionModel The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel'
     * values include 'detection_01', 'detection_02' and 'detection_03'.
     * @param recognitionModel The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel'
     * values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'.
     * 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with
     * 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'.
     * @param returnFaceId Return faceIds of the detected faces or not. The default value is true.
     * @param returnFaceAttributes Analyze and return the one or more specified face attributes in the comma-separated
     * string like 'returnFaceAttributes=headPose,glasses'. Face attribute analysis has additional computational and
     * time cost.
     * @param returnFaceLandmarks Return face landmarks of the detected faces or not. The default value is false.
     * @param returnRecognitionModel Return 'recognitionModel' or not. The default value is false.
     * @param faceIdTimeToLive The number of seconds for the face ID being cached. Supported range from 60 seconds up to
     * 86400 seconds. The default value is 86400 (24 hours).
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public List<FaceDetectionResult> detect(BinaryData imageContent, FaceDetectionModel detectionModel,
        FaceRecognitionModel recognitionModel, boolean returnFaceId, List<FaceAttributeType> returnFaceAttributes,
        Boolean returnFaceLandmarks, Boolean returnRecognitionModel, Integer faceIdTimeToLive) {
        return this.detectImpl(imageContent, detectionModel, recognitionModel, returnFaceId, returnFaceAttributes,
            returnFaceLandmarks, returnRecognitionModel, faceIdTimeToLive);
    }

    /**
     * Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.
     *
     * &gt; [!IMPORTANT]
     * &gt; To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of
     * services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and
     * makeup. Read more about this decision
     * https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/.
     *
     * *
     * * No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an
     * identifier of the face feature and will be used in "Identify", "Verify", and "Find Similar". The stored face
     * features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call.
     * * Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion,
     * accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific
     * attributes may not be highly accurate.
     * * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.
     * * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with
     * dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.
     * * Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.
     * * For optimal results when querying "Identify", "Verify", and "Find Similar" ('returnFaceId' is true), please use
     * faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).
     * * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer
     * to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model
     * * 'detection_02': Face attributes and landmarks are disabled if you choose this detection model.
     * * 'detection_03': Face attributes (mask and headPose only) and landmarks are supported if you choose this
     * detection model.
     * * Different 'recognitionModel' values are provided. If follow-up operations like "Verify", "Identify", "Find
     * Similar" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value
     * for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need
     * in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model.
     * More details, please refer to
     * https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-recognition-model.
     *
     * @param imageContent The input image binary.
     * @param detectionModel The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel'
     * values include 'detection_01', 'detection_02' and 'detection_03'.
     * @param recognitionModel The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel'
     * values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'.
     * 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with
     * 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'.
     * @param returnFaceId Return faceIds of the detected faces or not. The default value is true.
     * string like 'returnFaceAttributes=headPose,glasses'. Face attribute analysis has additional computational and
     * time cost.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public List<FaceDetectionResult> detect(BinaryData imageContent, FaceDetectionModel detectionModel,
        FaceRecognitionModel recognitionModel, boolean returnFaceId) {
        return this.detectImpl(imageContent, detectionModel, recognitionModel, returnFaceId, null, null, null, null);
    }

    /**
     * Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.
     *
     * &gt; [!IMPORTANT]
     * &gt; To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of
     * services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and
     * makeup. Read more about this decision
     * https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/.
     *
     * *
     * * No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an
     * identifier of the face feature and will be used in "Identify", "Verify", and "Find Similar". The stored face
     * features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call.
     * * Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion,
     * accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific
     * attributes may not be highly accurate.
     * * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.
     * * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with
     * dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.
     * * Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.
     * * For optimal results when querying "Identify", "Verify", and "Find Similar" ('returnFaceId' is true), please use
     * faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).
     * * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer
     * to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model
     * * 'detection_02': Face attributes and landmarks are disabled if you choose this detection model.
     * * 'detection_03': Face attributes (mask and headPose only) and landmarks are supported if you choose this
     * detection model.
     * * Different 'recognitionModel' values are provided. If follow-up operations like "Verify", "Identify", "Find
     * Similar" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value
     * for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need
     * in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model.
     * More details, please refer to
     * https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-recognition-model.
     *
     * @param imageContent The input image binary.
     * @param detectionModel The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel'
     * values include 'detection_01', 'detection_02' and 'detection_03'.
     * @param recognitionModel The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel'
     * values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'.
     * 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with
     * 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'.
     * @param returnFaceId Return faceIds of the detected faces or not. The default value is true.
     * @param returnFaceAttributes Analyze and return the one or more specified face attributes in the comma-separated
     * string like 'returnFaceAttributes=headPose,glasses'. Face attribute analysis has additional computational and
     * time cost.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public List<FaceDetectionResult> detect(BinaryData imageContent, FaceDetectionModel detectionModel,
        FaceRecognitionModel recognitionModel, Boolean returnFaceId, List<FaceAttributeType> returnFaceAttributes) {
        return this.detectImpl(imageContent, detectionModel, recognitionModel, returnFaceId, returnFaceAttributes, null,
            null, null);
    }

    /**
     * Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.
     *
     * &gt; [!IMPORTANT]
     * &gt; To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of
     * services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and
     * makeup. Read more about this decision
     * https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/.
     *
     * *
     * * No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an
     * identifier of the face feature and will be used in "Identify", "Verify", and "Find Similar". The stored face
     * features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call.
     * * Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion,
     * accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific
     * attributes may not be highly accurate.
     * * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.
     * * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with
     * dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.
     * * Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.
     * * For optimal results when querying "Identify", "Verify", and "Find Similar" ('returnFaceId' is true), please use
     * faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).
     * * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer
     * to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model
     * * 'detection_02': Face attributes and landmarks are disabled if you choose this detection model.
     * * 'detection_03': Face attributes (mask and headPose only) and landmarks are supported if you choose this
     * detection model.
     * * Different 'recognitionModel' values are provided. If follow-up operations like "Verify", "Identify", "Find
     * Similar" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value
     * for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need
     * in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model.
     * More details, please refer to
     * https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-recognition-model.
     *
     * @param url the URL of input image.
     * @param options Options for detectFromUrl API.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public List<FaceDetectionResult> detect(String url, DetectOptions options) {
        return this.detect(url, options.getDetectionModel(), options.getRecognitionModel(), options.isReturnFaceId(),
            options.getReturnFaceAttributes(), options.isReturnFaceLandmarks(), options.isReturnRecognitionModel(),
            options.getFaceIdTimeToLive());
    }

    /**
     * Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.
     *
     * &gt; [!IMPORTANT]
     * &gt; To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of
     * services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and
     * makeup. Read more about this decision
     * https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/.
     *
     * *
     * * No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an
     * identifier of the face feature and will be used in "Identify", "Verify", and "Find Similar". The stored face
     * features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call.
     * * Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion,
     * accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific
     * attributes may not be highly accurate.
     * * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.
     * * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with
     * dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.
     * * Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.
     * * For optimal results when querying "Identify", "Verify", and "Find Similar" ('returnFaceId' is true), please use
     * faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).
     * * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer
     * to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model
     * * 'detection_02': Face attributes and landmarks are disabled if you choose this detection model.
     * * 'detection_03': Face attributes (mask and headPose only) and landmarks are supported if you choose this
     * detection model.
     * * Different 'recognitionModel' values are provided. If follow-up operations like "Verify", "Identify", "Find
     * Similar" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value
     * for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need
     * in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model.
     * More details, please refer to
     * https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-recognition-model.
     *
     * @param url the URL of input image.
     * @param detectionModel The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel'
     * values include 'detection_01', 'detection_02' and 'detection_03'.
     * @param recognitionModel The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel'
     * values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'.
     * 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with
     * 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'.
     * @param returnFaceId Return faceIds of the detected faces or not. The default value is true.
     * @param returnFaceAttributes Analyze and return the one or more specified face attributes in the comma-separated
     * string like 'returnFaceAttributes=headPose,glasses'. Face attribute analysis has additional computational and
     * time cost.
     * @param returnFaceLandmarks Return face landmarks of the detected faces or not. The default value is false.
     * @param returnRecognitionModel Return 'recognitionModel' or not. The default value is false.
     * @param faceIdTimeToLive The number of seconds for the face ID being cached. Supported range from 60 seconds up to
     * 86400 seconds. The default value is 86400 (24 hours).
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public List<FaceDetectionResult> detect(String url, FaceDetectionModel detectionModel,
        FaceRecognitionModel recognitionModel, boolean returnFaceId, List<FaceAttributeType> returnFaceAttributes,
        Boolean returnFaceLandmarks, Boolean returnRecognitionModel, Integer faceIdTimeToLive) {
        RequestOptions requestOptions = new RequestOptions();
        addRequiredQueryParameterForDetection(requestOptions, detectionModel, recognitionModel, returnFaceId);
        addOptionalQueryParameterForDetection(requestOptions, returnFaceAttributes, returnFaceLandmarks,
            returnRecognitionModel, faceIdTimeToLive);
        DetectFromUrlImplRequest requestObj = new DetectFromUrlImplRequest(url);
        BinaryData request = BinaryData.fromObject(requestObj);
        return detectFromUrlImplWithResponse(request, requestOptions).getValue()
            .toObject(TYPE_REFERENCE_LIST_FACE_DETECTION_RESULT);
    }

    /**
     * Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.
     *
     * &gt; [!IMPORTANT]
     * &gt; To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of
     * services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and
     * makeup. Read more about this decision
     * https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/.
     *
     * *
     * * No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an
     * identifier of the face feature and will be used in "Identify", "Verify", and "Find Similar". The stored face
     * features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call.
     * * Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion,
     * accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific
     * attributes may not be highly accurate.
     * * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.
     * * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with
     * dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.
     * * Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.
     * * For optimal results when querying "Identify", "Verify", and "Find Similar" ('returnFaceId' is true), please use
     * faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).
     * * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer
     * to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model
     * * 'detection_02': Face attributes and landmarks are disabled if you choose this detection model.
     * * 'detection_03': Face attributes (mask and headPose only) and landmarks are supported if you choose this
     * detection model.
     * * Different 'recognitionModel' values are provided. If follow-up operations like "Verify", "Identify", "Find
     * Similar" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value
     * for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need
     * in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model.
     * More details, please refer to
     * https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-recognition-model.
     *
     * @param url the URL of input image.
     * @param detectionModel The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel'
     * values include 'detection_01', 'detection_02' and 'detection_03'.
     * @param recognitionModel The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel'
     * values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'.
     * 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with
     * 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'.
     * 86400 seconds. The default value is 86400 (24 hours).
     * @param returnFaceId Return faceIds of the detected faces or not. The default value is true.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public List<FaceDetectionResult> detect(String url, FaceDetectionModel detectionModel,
        FaceRecognitionModel recognitionModel, boolean returnFaceId) {
        return this.detect(url, detectionModel, recognitionModel, returnFaceId, null, null, null, null);
    }

    /**
     * Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.
     *
     * &gt; [!IMPORTANT]
     * &gt; To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of
     * services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and
     * makeup. Read more about this decision
     * https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/.
     *
     * *
     * * No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an
     * identifier of the face feature and will be used in "Identify", "Verify", and "Find Similar". The stored face
     * features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call.
     * * Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion,
     * accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific
     * attributes may not be highly accurate.
     * * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.
     * * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with
     * dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.
     * * Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.
     * * For optimal results when querying "Identify", "Verify", and "Find Similar" ('returnFaceId' is true), please use
     * faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).
     * * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer
     * to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model
     * * 'detection_02': Face attributes and landmarks are disabled if you choose this detection model.
     * * 'detection_03': Face attributes (mask and headPose only) and landmarks are supported if you choose this
     * detection model.
     * * Different 'recognitionModel' values are provided. If follow-up operations like "Verify", "Identify", "Find
     * Similar" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value
     * for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need
     * in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model.
     * More details, please refer to
     * https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-recognition-model.
     *
     * @param url the URL of input image.
     * @param detectionModel The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel'
     * values include 'detection_01', 'detection_02' and 'detection_03'.
     * @param recognitionModel The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel'
     * values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'.
     * 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with
     * 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'.
     * @param returnFaceId Return faceIds of the detected faces or not. The default value is true.
     * @param returnFaceAttributes Analyze and return the one or more specified face attributes in the comma-separated
     * string like 'returnFaceAttributes=headPose,glasses'. Face attribute analysis has additional computational and
     * time cost.
     * 86400 seconds. The default value is 86400 (24 hours).
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws HttpResponseException thrown if the request is rejected by server.
     * @throws ClientAuthenticationException thrown if the request is rejected by server on status code 401.
     * @throws ResourceNotFoundException thrown if the request is rejected by server on status code 404.
     * @throws ResourceModifiedException thrown if the request is rejected by server on status code 409.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    public List<FaceDetectionResult> detect(String url, FaceDetectionModel detectionModel,
        FaceRecognitionModel recognitionModel, boolean returnFaceId, List<FaceAttributeType> returnFaceAttributes) {
        return this.detect(url, detectionModel, recognitionModel, returnFaceId, returnFaceAttributes, null, null, null);
    }
}
