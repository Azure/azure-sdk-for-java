// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) TypeSpec Code Generator.

package com.azure.resourcemanager.iotoperations.models;

import com.azure.core.annotation.Fluent;
import com.azure.json.JsonReader;
import com.azure.json.JsonSerializable;
import com.azure.json.JsonToken;
import com.azure.json.JsonWriter;
import java.io.IOException;

/**
 * Kafka endpoint Batching properties.
 */
@Fluent
public final class DataflowEndpointKafkaBatching implements JsonSerializable<DataflowEndpointKafkaBatching> {
    /*
     * Mode for batching.
     */
    private OperationalMode mode;

    /*
     * Batching latency in milliseconds.
     */
    private Integer latencyMs;

    /*
     * Maximum number of bytes in a batch.
     */
    private Integer maxBytes;

    /*
     * Maximum number of messages in a batch.
     */
    private Integer maxMessages;

    /**
     * Creates an instance of DataflowEndpointKafkaBatching class.
     */
    public DataflowEndpointKafkaBatching() {
    }

    /**
     * Get the mode property: Mode for batching.
     * 
     * @return the mode value.
     */
    public OperationalMode mode() {
        return this.mode;
    }

    /**
     * Set the mode property: Mode for batching.
     * 
     * @param mode the mode value to set.
     * @return the DataflowEndpointKafkaBatching object itself.
     */
    public DataflowEndpointKafkaBatching withMode(OperationalMode mode) {
        this.mode = mode;
        return this;
    }

    /**
     * Get the latencyMs property: Batching latency in milliseconds.
     * 
     * @return the latencyMs value.
     */
    public Integer latencyMs() {
        return this.latencyMs;
    }

    /**
     * Set the latencyMs property: Batching latency in milliseconds.
     * 
     * @param latencyMs the latencyMs value to set.
     * @return the DataflowEndpointKafkaBatching object itself.
     */
    public DataflowEndpointKafkaBatching withLatencyMs(Integer latencyMs) {
        this.latencyMs = latencyMs;
        return this;
    }

    /**
     * Get the maxBytes property: Maximum number of bytes in a batch.
     * 
     * @return the maxBytes value.
     */
    public Integer maxBytes() {
        return this.maxBytes;
    }

    /**
     * Set the maxBytes property: Maximum number of bytes in a batch.
     * 
     * @param maxBytes the maxBytes value to set.
     * @return the DataflowEndpointKafkaBatching object itself.
     */
    public DataflowEndpointKafkaBatching withMaxBytes(Integer maxBytes) {
        this.maxBytes = maxBytes;
        return this;
    }

    /**
     * Get the maxMessages property: Maximum number of messages in a batch.
     * 
     * @return the maxMessages value.
     */
    public Integer maxMessages() {
        return this.maxMessages;
    }

    /**
     * Set the maxMessages property: Maximum number of messages in a batch.
     * 
     * @param maxMessages the maxMessages value to set.
     * @return the DataflowEndpointKafkaBatching object itself.
     */
    public DataflowEndpointKafkaBatching withMaxMessages(Integer maxMessages) {
        this.maxMessages = maxMessages;
        return this;
    }

    /**
     * Validates the instance.
     * 
     * @throws IllegalArgumentException thrown if the instance is not valid.
     */
    public void validate() {
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public JsonWriter toJson(JsonWriter jsonWriter) throws IOException {
        jsonWriter.writeStartObject();
        jsonWriter.writeStringField("mode", this.mode == null ? null : this.mode.toString());
        jsonWriter.writeNumberField("latencyMs", this.latencyMs);
        jsonWriter.writeNumberField("maxBytes", this.maxBytes);
        jsonWriter.writeNumberField("maxMessages", this.maxMessages);
        return jsonWriter.writeEndObject();
    }

    /**
     * Reads an instance of DataflowEndpointKafkaBatching from the JsonReader.
     * 
     * @param jsonReader The JsonReader being read.
     * @return An instance of DataflowEndpointKafkaBatching if the JsonReader was pointing to an instance of it, or null
     * if it was pointing to JSON null.
     * @throws IOException If an error occurs while reading the DataflowEndpointKafkaBatching.
     */
    public static DataflowEndpointKafkaBatching fromJson(JsonReader jsonReader) throws IOException {
        return jsonReader.readObject(reader -> {
            DataflowEndpointKafkaBatching deserializedDataflowEndpointKafkaBatching
                = new DataflowEndpointKafkaBatching();
            while (reader.nextToken() != JsonToken.END_OBJECT) {
                String fieldName = reader.getFieldName();
                reader.nextToken();

                if ("mode".equals(fieldName)) {
                    deserializedDataflowEndpointKafkaBatching.mode = OperationalMode.fromString(reader.getString());
                } else if ("latencyMs".equals(fieldName)) {
                    deserializedDataflowEndpointKafkaBatching.latencyMs = reader.getNullable(JsonReader::getInt);
                } else if ("maxBytes".equals(fieldName)) {
                    deserializedDataflowEndpointKafkaBatching.maxBytes = reader.getNullable(JsonReader::getInt);
                } else if ("maxMessages".equals(fieldName)) {
                    deserializedDataflowEndpointKafkaBatching.maxMessages = reader.getNullable(JsonReader::getInt);
                } else {
                    reader.skipChildren();
                }
            }

            return deserializedDataflowEndpointKafkaBatching;
        });
    }
}
