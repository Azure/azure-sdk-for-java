// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) TypeSpec Code Generator.

package com.azure.resourcemanager.iotoperations.models;

import com.azure.core.annotation.Fluent;
import com.azure.core.util.logging.ClientLogger;
import com.azure.json.JsonReader;
import com.azure.json.JsonSerializable;
import com.azure.json.JsonToken;
import com.azure.json.JsonWriter;
import java.io.IOException;

/**
 * Microsoft Fabric endpoint properties.
 */
@Fluent
public final class DataflowEndpointFabricOneLake implements JsonSerializable<DataflowEndpointFabricOneLake> {
    /*
     * Authentication configuration. NOTE - only one authentication property is allowed per entry.
     */
    private DataflowEndpointFabricOneLakeAuthentication authentication;

    /*
     * Names of the workspace and lakehouse.
     */
    private DataflowEndpointFabricOneLakeNames names;

    /*
     * Type of location of the data in the workspace. Can be either tables or files.
     */
    private DataflowEndpointFabricPathType oneLakePathType;

    /*
     * Host of the Microsoft Fabric in the form of https://<host>.fabric.microsoft.com.
     */
    private String host;

    /*
     * Batching configuration.
     */
    private BatchingConfiguration batching;

    /**
     * Creates an instance of DataflowEndpointFabricOneLake class.
     */
    public DataflowEndpointFabricOneLake() {
    }

    /**
     * Get the authentication property: Authentication configuration. NOTE - only one authentication property is allowed
     * per entry.
     * 
     * @return the authentication value.
     */
    public DataflowEndpointFabricOneLakeAuthentication authentication() {
        return this.authentication;
    }

    /**
     * Set the authentication property: Authentication configuration. NOTE - only one authentication property is allowed
     * per entry.
     * 
     * @param authentication the authentication value to set.
     * @return the DataflowEndpointFabricOneLake object itself.
     */
    public DataflowEndpointFabricOneLake
        withAuthentication(DataflowEndpointFabricOneLakeAuthentication authentication) {
        this.authentication = authentication;
        return this;
    }

    /**
     * Get the names property: Names of the workspace and lakehouse.
     * 
     * @return the names value.
     */
    public DataflowEndpointFabricOneLakeNames names() {
        return this.names;
    }

    /**
     * Set the names property: Names of the workspace and lakehouse.
     * 
     * @param names the names value to set.
     * @return the DataflowEndpointFabricOneLake object itself.
     */
    public DataflowEndpointFabricOneLake withNames(DataflowEndpointFabricOneLakeNames names) {
        this.names = names;
        return this;
    }

    /**
     * Get the oneLakePathType property: Type of location of the data in the workspace. Can be either tables or files.
     * 
     * @return the oneLakePathType value.
     */
    public DataflowEndpointFabricPathType oneLakePathType() {
        return this.oneLakePathType;
    }

    /**
     * Set the oneLakePathType property: Type of location of the data in the workspace. Can be either tables or files.
     * 
     * @param oneLakePathType the oneLakePathType value to set.
     * @return the DataflowEndpointFabricOneLake object itself.
     */
    public DataflowEndpointFabricOneLake withOneLakePathType(DataflowEndpointFabricPathType oneLakePathType) {
        this.oneLakePathType = oneLakePathType;
        return this;
    }

    /**
     * Get the host property: Host of the Microsoft Fabric in the form of https://&lt;host&gt;.fabric.microsoft.com.
     * 
     * @return the host value.
     */
    public String host() {
        return this.host;
    }

    /**
     * Set the host property: Host of the Microsoft Fabric in the form of https://&lt;host&gt;.fabric.microsoft.com.
     * 
     * @param host the host value to set.
     * @return the DataflowEndpointFabricOneLake object itself.
     */
    public DataflowEndpointFabricOneLake withHost(String host) {
        this.host = host;
        return this;
    }

    /**
     * Get the batching property: Batching configuration.
     * 
     * @return the batching value.
     */
    public BatchingConfiguration batching() {
        return this.batching;
    }

    /**
     * Set the batching property: Batching configuration.
     * 
     * @param batching the batching value to set.
     * @return the DataflowEndpointFabricOneLake object itself.
     */
    public DataflowEndpointFabricOneLake withBatching(BatchingConfiguration batching) {
        this.batching = batching;
        return this;
    }

    /**
     * Validates the instance.
     * 
     * @throws IllegalArgumentException thrown if the instance is not valid.
     */
    public void validate() {
        if (authentication() == null) {
            throw LOGGER.atError()
                .log(new IllegalArgumentException(
                    "Missing required property authentication in model DataflowEndpointFabricOneLake"));
        } else {
            authentication().validate();
        }
        if (names() == null) {
            throw LOGGER.atError()
                .log(new IllegalArgumentException(
                    "Missing required property names in model DataflowEndpointFabricOneLake"));
        } else {
            names().validate();
        }
        if (oneLakePathType() == null) {
            throw LOGGER.atError()
                .log(new IllegalArgumentException(
                    "Missing required property oneLakePathType in model DataflowEndpointFabricOneLake"));
        }
        if (host() == null) {
            throw LOGGER.atError()
                .log(new IllegalArgumentException(
                    "Missing required property host in model DataflowEndpointFabricOneLake"));
        }
        if (batching() != null) {
            batching().validate();
        }
    }

    private static final ClientLogger LOGGER = new ClientLogger(DataflowEndpointFabricOneLake.class);

    /**
     * {@inheritDoc}
     */
    @Override
    public JsonWriter toJson(JsonWriter jsonWriter) throws IOException {
        jsonWriter.writeStartObject();
        jsonWriter.writeJsonField("authentication", this.authentication);
        jsonWriter.writeJsonField("names", this.names);
        jsonWriter.writeStringField("oneLakePathType",
            this.oneLakePathType == null ? null : this.oneLakePathType.toString());
        jsonWriter.writeStringField("host", this.host);
        jsonWriter.writeJsonField("batching", this.batching);
        return jsonWriter.writeEndObject();
    }

    /**
     * Reads an instance of DataflowEndpointFabricOneLake from the JsonReader.
     * 
     * @param jsonReader The JsonReader being read.
     * @return An instance of DataflowEndpointFabricOneLake if the JsonReader was pointing to an instance of it, or null
     * if it was pointing to JSON null.
     * @throws IllegalStateException If the deserialized JSON object was missing any required properties.
     * @throws IOException If an error occurs while reading the DataflowEndpointFabricOneLake.
     */
    public static DataflowEndpointFabricOneLake fromJson(JsonReader jsonReader) throws IOException {
        return jsonReader.readObject(reader -> {
            DataflowEndpointFabricOneLake deserializedDataflowEndpointFabricOneLake
                = new DataflowEndpointFabricOneLake();
            while (reader.nextToken() != JsonToken.END_OBJECT) {
                String fieldName = reader.getFieldName();
                reader.nextToken();

                if ("authentication".equals(fieldName)) {
                    deserializedDataflowEndpointFabricOneLake.authentication
                        = DataflowEndpointFabricOneLakeAuthentication.fromJson(reader);
                } else if ("names".equals(fieldName)) {
                    deserializedDataflowEndpointFabricOneLake.names
                        = DataflowEndpointFabricOneLakeNames.fromJson(reader);
                } else if ("oneLakePathType".equals(fieldName)) {
                    deserializedDataflowEndpointFabricOneLake.oneLakePathType
                        = DataflowEndpointFabricPathType.fromString(reader.getString());
                } else if ("host".equals(fieldName)) {
                    deserializedDataflowEndpointFabricOneLake.host = reader.getString();
                } else if ("batching".equals(fieldName)) {
                    deserializedDataflowEndpointFabricOneLake.batching = BatchingConfiguration.fromJson(reader);
                } else {
                    reader.skipChildren();
                }
            }

            return deserializedDataflowEndpointFabricOneLake;
        });
    }
}
