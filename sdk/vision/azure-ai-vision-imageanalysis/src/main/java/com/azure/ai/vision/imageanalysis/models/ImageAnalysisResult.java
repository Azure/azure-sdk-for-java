// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) TypeSpec Code Generator.
package com.azure.ai.vision.imageanalysis.models;

import com.azure.core.annotation.Generated;
import com.azure.core.annotation.Immutable;
import com.fasterxml.jackson.annotation.JsonCreator;
import com.fasterxml.jackson.annotation.JsonProperty;

/**
 * Represents the outcome of an Image Analysis operation.
 */
@Immutable
public final class ImageAnalysisResult {

    /*
     * The generated phrase that describes the content of the analyzed image.
     */
    @Generated
    @JsonProperty(value = "captionResult")
    private CaptionResult caption;

    /*
     * The up to 10 generated phrases, the first describing the content of the whole image,
     * and the others describing the content of different regions of the image.
     */
    @Generated
    @JsonProperty(value = "denseCaptionsResult")
    private DenseCaptionsResult denseCaptions;

    /*
     * Metadata associated with the analyzed image.
     */
    @Generated
    @JsonProperty(value = "metadata")
    private ImageMetadata metadata;

    /*
     * The cloud AI model used for the analysis
     */
    @Generated
    @JsonProperty(value = "modelVersion")
    private String modelVersion;

    /*
     * A list of detected physical objects in the analyzed image, and their location.
     */
    @Generated
    @JsonProperty(value = "objectsResult")
    private ObjectsResult objects;

    /*
     * A list of detected people in the analyzed image, and their location.
     */
    @Generated
    @JsonProperty(value = "peopleResult")
    private PeopleResult people;

    /*
     * The extracted printed and hand-written text in the analyze image. Also knows as OCR.
     */
    @Generated
    @JsonProperty(value = "readResult")
    private ReadResult read;

    /*
     * A list of crop regions at the desired as aspect ratios (if provided) that can be used as image thumbnails.
     * These regions preserve as much content as possible from the analyzed image, with priority given to detected
     * faces.
     */
    @Generated
    @JsonProperty(value = "smartCropsResult")
    private SmartCropsResult smartCrops;

    /*
     * A list of content tags in the analyzed image.
     */
    @Generated
    @JsonProperty(value = "tagsResult")
    private TagsResult tags;

    /**
     * Creates an instance of ImageAnalysisResult class.
     *
     * @param metadata the metadata value to set.
     * @param modelVersion the modelVersion value to set.
     */
    @Generated
    @JsonCreator
    private ImageAnalysisResult(@JsonProperty(value = "metadata") ImageMetadata metadata,
        @JsonProperty(value = "modelVersion") String modelVersion) {
        this.metadata = metadata;
        this.modelVersion = modelVersion;
    }

    /**
     * Get the caption property: The generated phrase that describes the content of the analyzed image.
     *
     * @return the caption value.
     */
    @Generated
    public CaptionResult getCaption() {
        return this.caption;
    }

    /**
     * Get the denseCaptions property: The up to 10 generated phrases, the first describing the content of the whole
     * image,
     * and the others describing the content of different regions of the image.
     *
     * @return the denseCaptions value.
     */
    @Generated
    public DenseCaptionsResult getDenseCaptions() {
        return this.denseCaptions;
    }

    /**
     * Get the metadata property: Metadata associated with the analyzed image.
     *
     * @return the metadata value.
     */
    @Generated
    public ImageMetadata getMetadata() {
        return this.metadata;
    }

    /**
     * Get the modelVersion property: The cloud AI model used for the analysis.
     *
     * @return the modelVersion value.
     */
    @Generated
    public String getModelVersion() {
        return this.modelVersion;
    }

    /**
     * Get the objects property: A list of detected physical objects in the analyzed image, and their location.
     *
     * @return the objects value.
     */
    @Generated
    public ObjectsResult getObjects() {
        return this.objects;
    }

    /**
     * Get the people property: A list of detected people in the analyzed image, and their location.
     *
     * @return the people value.
     */
    @Generated
    public PeopleResult getPeople() {
        return this.people;
    }

    /**
     * Get the read property: The extracted printed and hand-written text in the analyze image. Also knows as OCR.
     *
     * @return the read value.
     */
    @Generated
    public ReadResult getRead() {
        return this.read;
    }

    /**
     * Get the smartCrops property: A list of crop regions at the desired as aspect ratios (if provided) that can be
     * used as image thumbnails.
     * These regions preserve as much content as possible from the analyzed image, with priority given to detected
     * faces.
     *
     * @return the smartCrops value.
     */
    @Generated
    public SmartCropsResult getSmartCrops() {
        return this.smartCrops;
    }

    /**
     * Get the tags property: A list of content tags in the analyzed image.
     *
     * @return the tags value.
     */
    @Generated
    public TagsResult getTags() {
        return this.tags;
    }
}
