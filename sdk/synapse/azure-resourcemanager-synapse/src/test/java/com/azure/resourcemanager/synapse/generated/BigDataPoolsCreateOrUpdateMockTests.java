// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) AutoRest Code Generator.

package com.azure.resourcemanager.synapse.generated;

import com.azure.core.credential.AccessToken;
import com.azure.core.http.HttpClient;
import com.azure.core.http.HttpHeaders;
import com.azure.core.http.HttpRequest;
import com.azure.core.http.HttpResponse;
import com.azure.core.management.AzureEnvironment;
import com.azure.core.management.profile.AzureProfile;
import com.azure.resourcemanager.synapse.SynapseManager;
import com.azure.resourcemanager.synapse.models.AutoPauseProperties;
import com.azure.resourcemanager.synapse.models.AutoScaleProperties;
import com.azure.resourcemanager.synapse.models.BigDataPoolResourceInfo;
import com.azure.resourcemanager.synapse.models.ConfigurationType;
import com.azure.resourcemanager.synapse.models.DynamicExecutorAllocation;
import com.azure.resourcemanager.synapse.models.LibraryRequirements;
import com.azure.resourcemanager.synapse.models.NodeSize;
import com.azure.resourcemanager.synapse.models.NodeSizeFamily;
import com.azure.resourcemanager.synapse.models.SparkConfigProperties;
import java.nio.ByteBuffer;
import java.nio.charset.StandardCharsets;
import java.time.OffsetDateTime;
import java.util.Arrays;
import java.util.HashMap;
import java.util.Map;
import org.junit.jupiter.api.Assertions;
import org.junit.jupiter.api.Test;
import org.mockito.ArgumentCaptor;
import org.mockito.Mockito;
import reactor.core.publisher.Flux;
import reactor.core.publisher.Mono;

public final class BigDataPoolsCreateOrUpdateMockTests {
    @Test
    public void testCreateOrUpdate() throws Exception {
        HttpClient httpClient = Mockito.mock(HttpClient.class);
        HttpResponse httpResponse = Mockito.mock(HttpResponse.class);
        ArgumentCaptor<HttpRequest> httpRequest = ArgumentCaptor.forClass(HttpRequest.class);

        String responseStr =
            "{\"properties\":{\"provisioningState\":\"Succeeded\",\"autoScale\":{\"minNodeCount\":985648973,\"enabled\":true,\"maxNodeCount\":1004177849},\"creationDate\":\"2021-05-07T09:49:36Z\",\"autoPause\":{\"delayInMinutes\":26783847,\"enabled\":false},\"isComputeIsolationEnabled\":false,\"isAutotuneEnabled\":false,\"sessionLevelPackagesEnabled\":false,\"cacheSize\":880047238,\"dynamicExecutorAllocation\":{\"enabled\":true,\"minExecutors\":876002990,\"maxExecutors\":21089033},\"sparkEventsFolder\":\"tkutnjil\",\"nodeCount\":1110899441,\"libraryRequirements\":{\"time\":\"2021-06-03T08:07:55Z\",\"content\":\"yhtmjoduif\",\"filename\":\"lxfary\"},\"customLibraries\":[],\"sparkConfigProperties\":{\"time\":\"2021-05-20T15:40Z\",\"content\":\"zvj\",\"filename\":\"ahoyiyaxqvj\",\"configurationType\":\"File\"},\"sparkVersion\":\"tcz\",\"defaultSparkLogFolder\":\"dn\",\"nodeSize\":\"XXXLarge\",\"nodeSizeFamily\":\"None\",\"lastSucceededTimestamp\":\"2021-02-26T05:46:20Z\"},\"location\":\"bmdqrxyglae\",\"tags\":{\"riefoo\":\"flwtjdt\",\"dudgcozzomeh\":\"ycuxdtzcqip\",\"juxkqll\":\"lantolamlb\"},\"id\":\"z\",\"name\":\"pvwdtgckzdqiq\",\"type\":\"lrat\"}";

        Mockito.when(httpResponse.getStatusCode()).thenReturn(200);
        Mockito.when(httpResponse.getHeaders()).thenReturn(new HttpHeaders());
        Mockito
            .when(httpResponse.getBody())
            .thenReturn(Flux.just(ByteBuffer.wrap(responseStr.getBytes(StandardCharsets.UTF_8))));
        Mockito
            .when(httpResponse.getBodyAsByteArray())
            .thenReturn(Mono.just(responseStr.getBytes(StandardCharsets.UTF_8)));
        Mockito
            .when(httpClient.send(httpRequest.capture(), Mockito.any()))
            .thenReturn(
                Mono
                    .defer(
                        () -> {
                            Mockito.when(httpResponse.getRequest()).thenReturn(httpRequest.getValue());
                            return Mono.just(httpResponse);
                        }));

        SynapseManager manager =
            SynapseManager
                .configure()
                .withHttpClient(httpClient)
                .authenticate(
                    tokenRequestContext -> Mono.just(new AccessToken("this_is_a_token", OffsetDateTime.MAX)),
                    new AzureProfile("", "", AzureEnvironment.AZURE));

        BigDataPoolResourceInfo response =
            manager
                .bigDataPools()
                .define("afofu")
                .withRegion("wfldsiuorinik")
                .withExistingWorkspace("hnzrsbkkzovlzdm", "fmfws")
                .withTags(mapOf("iwm", "pks"))
                .withProvisioningState("immovzwd")
                .withAutoScale(
                    new AutoScaleProperties()
                        .withMinNodeCount(1674817788)
                        .withEnabled(false)
                        .withMaxNodeCount(1123352219))
                .withAutoPause(new AutoPauseProperties().withDelayInMinutes(960263436).withEnabled(true))
                .withIsComputeIsolationEnabled(false)
                .withIsAutotuneEnabled(false)
                .withSessionLevelPackagesEnabled(false)
                .withDynamicExecutorAllocation(
                    new DynamicExecutorAllocation()
                        .withEnabled(true)
                        .withMinExecutors(420672272)
                        .withMaxExecutors(1302381284))
                .withSparkEventsFolder("aq")
                .withNodeCount(806621998)
                .withLibraryRequirements(new LibraryRequirements().withContent("qoq").withFilename("movsfbpbvz"))
                .withCustomLibraries(Arrays.asList())
                .withSparkConfigProperties(
                    new SparkConfigProperties()
                        .withContent("vsmcwo")
                        .withFilename("axdtnqif")
                        .withConfigurationType(ConfigurationType.FILE))
                .withSparkVersion("roiauesugmo")
                .withDefaultSparkLogFolder("cjycb")
                .withNodeSize(NodeSize.XLARGE)
                .withNodeSizeFamily(NodeSizeFamily.HARDWARE_ACCELERATED_FPGA)
                .withForce(false)
                .create();

        Assertions.assertEquals("bmdqrxyglae", response.location());
        Assertions.assertEquals("flwtjdt", response.tags().get("riefoo"));
        Assertions.assertEquals("Succeeded", response.provisioningState());
        Assertions.assertEquals(985648973, response.autoScale().minNodeCount());
        Assertions.assertEquals(true, response.autoScale().enabled());
        Assertions.assertEquals(1004177849, response.autoScale().maxNodeCount());
        Assertions.assertEquals(26783847, response.autoPause().delayInMinutes());
        Assertions.assertEquals(false, response.autoPause().enabled());
        Assertions.assertEquals(false, response.isComputeIsolationEnabled());
        Assertions.assertEquals(false, response.isAutotuneEnabled());
        Assertions.assertEquals(false, response.sessionLevelPackagesEnabled());
        Assertions.assertEquals(true, response.dynamicExecutorAllocation().enabled());
        Assertions.assertEquals(876002990, response.dynamicExecutorAllocation().minExecutors());
        Assertions.assertEquals(21089033, response.dynamicExecutorAllocation().maxExecutors());
        Assertions.assertEquals("tkutnjil", response.sparkEventsFolder());
        Assertions.assertEquals(1110899441, response.nodeCount());
        Assertions.assertEquals("yhtmjoduif", response.libraryRequirements().content());
        Assertions.assertEquals("lxfary", response.libraryRequirements().filename());
        Assertions.assertEquals("zvj", response.sparkConfigProperties().content());
        Assertions.assertEquals("ahoyiyaxqvj", response.sparkConfigProperties().filename());
        Assertions.assertEquals(ConfigurationType.FILE, response.sparkConfigProperties().configurationType());
        Assertions.assertEquals("tcz", response.sparkVersion());
        Assertions.assertEquals("dn", response.defaultSparkLogFolder());
        Assertions.assertEquals(NodeSize.XXXLARGE, response.nodeSize());
        Assertions.assertEquals(NodeSizeFamily.NONE, response.nodeSizeFamily());
    }

    @SuppressWarnings("unchecked")
    private static <T> Map<String, T> mapOf(Object... inputs) {
        Map<String, T> map = new HashMap<>();
        for (int i = 0; i < inputs.length; i += 2) {
            String key = (String) inputs[i];
            T value = (T) inputs[i + 1];
            map.put(key, value);
        }
        return map;
    }
}
