// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) AutoRest Code Generator.

package com.azure.resourcemanager.synapse.fluent.models;

import com.azure.core.annotation.Fluent;
import com.azure.core.annotation.JsonFlatten;
import com.azure.core.management.Resource;
import com.azure.core.util.logging.ClientLogger;
import com.azure.resourcemanager.synapse.models.AutoPauseProperties;
import com.azure.resourcemanager.synapse.models.AutoScaleProperties;
import com.azure.resourcemanager.synapse.models.DynamicExecutorAllocation;
import com.azure.resourcemanager.synapse.models.LibraryInfo;
import com.azure.resourcemanager.synapse.models.LibraryRequirements;
import com.azure.resourcemanager.synapse.models.NodeSize;
import com.azure.resourcemanager.synapse.models.NodeSizeFamily;
import com.fasterxml.jackson.annotation.JsonIgnore;
import com.fasterxml.jackson.annotation.JsonProperty;
import java.time.OffsetDateTime;
import java.util.List;
import java.util.Map;

/** A Big Data pool. */
@JsonFlatten
@Fluent
public class BigDataPoolResourceInfoInner extends Resource {
    @JsonIgnore private final ClientLogger logger = new ClientLogger(BigDataPoolResourceInfoInner.class);

    /*
     * The state of the Big Data pool.
     */
    @JsonProperty(value = "properties.provisioningState")
    private String provisioningState;

    /*
     * Auto-scaling properties
     */
    @JsonProperty(value = "properties.autoScale")
    private AutoScaleProperties autoScale;

    /*
     * The time when the Big Data pool was created.
     */
    @JsonProperty(value = "properties.creationDate")
    private OffsetDateTime creationDate;

    /*
     * Auto-pausing properties
     */
    @JsonProperty(value = "properties.autoPause")
    private AutoPauseProperties autoPause;

    /*
     * Whether compute isolation is required or not.
     */
    @JsonProperty(value = "properties.isComputeIsolationEnabled")
    private Boolean isComputeIsolationEnabled;

    /*
     * Whether session level packages enabled.
     */
    @JsonProperty(value = "properties.sessionLevelPackagesEnabled")
    private Boolean sessionLevelPackagesEnabled;

    /*
     * The cache size
     */
    @JsonProperty(value = "properties.cacheSize")
    private Integer cacheSize;

    /*
     * Dynamic Executor Allocation
     */
    @JsonProperty(value = "properties.dynamicExecutorAllocation")
    private DynamicExecutorAllocation dynamicExecutorAllocation;

    /*
     * The Spark events folder
     */
    @JsonProperty(value = "properties.sparkEventsFolder")
    private String sparkEventsFolder;

    /*
     * The number of nodes in the Big Data pool.
     */
    @JsonProperty(value = "properties.nodeCount")
    private Integer nodeCount;

    /*
     * Library version requirements
     */
    @JsonProperty(value = "properties.libraryRequirements")
    private LibraryRequirements libraryRequirements;

    /*
     * List of custom libraries/packages associated with the spark pool.
     */
    @JsonProperty(value = "properties.customLibraries")
    private List<LibraryInfo> customLibraries;

    /*
     * Spark configuration file to specify additional properties
     */
    @JsonProperty(value = "properties.sparkConfigProperties")
    private LibraryRequirements sparkConfigProperties;

    /*
     * The Apache Spark version.
     */
    @JsonProperty(value = "properties.sparkVersion")
    private String sparkVersion;

    /*
     * The default folder where Spark logs will be written.
     */
    @JsonProperty(value = "properties.defaultSparkLogFolder")
    private String defaultSparkLogFolder;

    /*
     * The level of compute power that each node in the Big Data pool has.
     */
    @JsonProperty(value = "properties.nodeSize")
    private NodeSize nodeSize;

    /*
     * The kind of nodes that the Big Data pool provides.
     */
    @JsonProperty(value = "properties.nodeSizeFamily")
    private NodeSizeFamily nodeSizeFamily;

    /*
     * The time when the Big Data pool was updated successfully.
     */
    @JsonProperty(value = "properties.lastSucceededTimestamp", access = JsonProperty.Access.WRITE_ONLY)
    private OffsetDateTime lastSucceededTimestamp;

    /**
     * Get the provisioningState property: The state of the Big Data pool.
     *
     * @return the provisioningState value.
     */
    public String provisioningState() {
        return this.provisioningState;
    }

    /**
     * Set the provisioningState property: The state of the Big Data pool.
     *
     * @param provisioningState the provisioningState value to set.
     * @return the BigDataPoolResourceInfoInner object itself.
     */
    public BigDataPoolResourceInfoInner withProvisioningState(String provisioningState) {
        this.provisioningState = provisioningState;
        return this;
    }

    /**
     * Get the autoScale property: Auto-scaling properties.
     *
     * @return the autoScale value.
     */
    public AutoScaleProperties autoScale() {
        return this.autoScale;
    }

    /**
     * Set the autoScale property: Auto-scaling properties.
     *
     * @param autoScale the autoScale value to set.
     * @return the BigDataPoolResourceInfoInner object itself.
     */
    public BigDataPoolResourceInfoInner withAutoScale(AutoScaleProperties autoScale) {
        this.autoScale = autoScale;
        return this;
    }

    /**
     * Get the creationDate property: The time when the Big Data pool was created.
     *
     * @return the creationDate value.
     */
    public OffsetDateTime creationDate() {
        return this.creationDate;
    }

    /**
     * Set the creationDate property: The time when the Big Data pool was created.
     *
     * @param creationDate the creationDate value to set.
     * @return the BigDataPoolResourceInfoInner object itself.
     */
    public BigDataPoolResourceInfoInner withCreationDate(OffsetDateTime creationDate) {
        this.creationDate = creationDate;
        return this;
    }

    /**
     * Get the autoPause property: Auto-pausing properties.
     *
     * @return the autoPause value.
     */
    public AutoPauseProperties autoPause() {
        return this.autoPause;
    }

    /**
     * Set the autoPause property: Auto-pausing properties.
     *
     * @param autoPause the autoPause value to set.
     * @return the BigDataPoolResourceInfoInner object itself.
     */
    public BigDataPoolResourceInfoInner withAutoPause(AutoPauseProperties autoPause) {
        this.autoPause = autoPause;
        return this;
    }

    /**
     * Get the isComputeIsolationEnabled property: Whether compute isolation is required or not.
     *
     * @return the isComputeIsolationEnabled value.
     */
    public Boolean isComputeIsolationEnabled() {
        return this.isComputeIsolationEnabled;
    }

    /**
     * Set the isComputeIsolationEnabled property: Whether compute isolation is required or not.
     *
     * @param isComputeIsolationEnabled the isComputeIsolationEnabled value to set.
     * @return the BigDataPoolResourceInfoInner object itself.
     */
    public BigDataPoolResourceInfoInner withIsComputeIsolationEnabled(Boolean isComputeIsolationEnabled) {
        this.isComputeIsolationEnabled = isComputeIsolationEnabled;
        return this;
    }

    /**
     * Get the sessionLevelPackagesEnabled property: Whether session level packages enabled.
     *
     * @return the sessionLevelPackagesEnabled value.
     */
    public Boolean sessionLevelPackagesEnabled() {
        return this.sessionLevelPackagesEnabled;
    }

    /**
     * Set the sessionLevelPackagesEnabled property: Whether session level packages enabled.
     *
     * @param sessionLevelPackagesEnabled the sessionLevelPackagesEnabled value to set.
     * @return the BigDataPoolResourceInfoInner object itself.
     */
    public BigDataPoolResourceInfoInner withSessionLevelPackagesEnabled(Boolean sessionLevelPackagesEnabled) {
        this.sessionLevelPackagesEnabled = sessionLevelPackagesEnabled;
        return this;
    }

    /**
     * Get the cacheSize property: The cache size.
     *
     * @return the cacheSize value.
     */
    public Integer cacheSize() {
        return this.cacheSize;
    }

    /**
     * Set the cacheSize property: The cache size.
     *
     * @param cacheSize the cacheSize value to set.
     * @return the BigDataPoolResourceInfoInner object itself.
     */
    public BigDataPoolResourceInfoInner withCacheSize(Integer cacheSize) {
        this.cacheSize = cacheSize;
        return this;
    }

    /**
     * Get the dynamicExecutorAllocation property: Dynamic Executor Allocation.
     *
     * @return the dynamicExecutorAllocation value.
     */
    public DynamicExecutorAllocation dynamicExecutorAllocation() {
        return this.dynamicExecutorAllocation;
    }

    /**
     * Set the dynamicExecutorAllocation property: Dynamic Executor Allocation.
     *
     * @param dynamicExecutorAllocation the dynamicExecutorAllocation value to set.
     * @return the BigDataPoolResourceInfoInner object itself.
     */
    public BigDataPoolResourceInfoInner withDynamicExecutorAllocation(
        DynamicExecutorAllocation dynamicExecutorAllocation) {
        this.dynamicExecutorAllocation = dynamicExecutorAllocation;
        return this;
    }

    /**
     * Get the sparkEventsFolder property: The Spark events folder.
     *
     * @return the sparkEventsFolder value.
     */
    public String sparkEventsFolder() {
        return this.sparkEventsFolder;
    }

    /**
     * Set the sparkEventsFolder property: The Spark events folder.
     *
     * @param sparkEventsFolder the sparkEventsFolder value to set.
     * @return the BigDataPoolResourceInfoInner object itself.
     */
    public BigDataPoolResourceInfoInner withSparkEventsFolder(String sparkEventsFolder) {
        this.sparkEventsFolder = sparkEventsFolder;
        return this;
    }

    /**
     * Get the nodeCount property: The number of nodes in the Big Data pool.
     *
     * @return the nodeCount value.
     */
    public Integer nodeCount() {
        return this.nodeCount;
    }

    /**
     * Set the nodeCount property: The number of nodes in the Big Data pool.
     *
     * @param nodeCount the nodeCount value to set.
     * @return the BigDataPoolResourceInfoInner object itself.
     */
    public BigDataPoolResourceInfoInner withNodeCount(Integer nodeCount) {
        this.nodeCount = nodeCount;
        return this;
    }

    /**
     * Get the libraryRequirements property: Library version requirements.
     *
     * @return the libraryRequirements value.
     */
    public LibraryRequirements libraryRequirements() {
        return this.libraryRequirements;
    }

    /**
     * Set the libraryRequirements property: Library version requirements.
     *
     * @param libraryRequirements the libraryRequirements value to set.
     * @return the BigDataPoolResourceInfoInner object itself.
     */
    public BigDataPoolResourceInfoInner withLibraryRequirements(LibraryRequirements libraryRequirements) {
        this.libraryRequirements = libraryRequirements;
        return this;
    }

    /**
     * Get the customLibraries property: List of custom libraries/packages associated with the spark pool.
     *
     * @return the customLibraries value.
     */
    public List<LibraryInfo> customLibraries() {
        return this.customLibraries;
    }

    /**
     * Set the customLibraries property: List of custom libraries/packages associated with the spark pool.
     *
     * @param customLibraries the customLibraries value to set.
     * @return the BigDataPoolResourceInfoInner object itself.
     */
    public BigDataPoolResourceInfoInner withCustomLibraries(List<LibraryInfo> customLibraries) {
        this.customLibraries = customLibraries;
        return this;
    }

    /**
     * Get the sparkConfigProperties property: Spark configuration file to specify additional properties.
     *
     * @return the sparkConfigProperties value.
     */
    public LibraryRequirements sparkConfigProperties() {
        return this.sparkConfigProperties;
    }

    /**
     * Set the sparkConfigProperties property: Spark configuration file to specify additional properties.
     *
     * @param sparkConfigProperties the sparkConfigProperties value to set.
     * @return the BigDataPoolResourceInfoInner object itself.
     */
    public BigDataPoolResourceInfoInner withSparkConfigProperties(LibraryRequirements sparkConfigProperties) {
        this.sparkConfigProperties = sparkConfigProperties;
        return this;
    }

    /**
     * Get the sparkVersion property: The Apache Spark version.
     *
     * @return the sparkVersion value.
     */
    public String sparkVersion() {
        return this.sparkVersion;
    }

    /**
     * Set the sparkVersion property: The Apache Spark version.
     *
     * @param sparkVersion the sparkVersion value to set.
     * @return the BigDataPoolResourceInfoInner object itself.
     */
    public BigDataPoolResourceInfoInner withSparkVersion(String sparkVersion) {
        this.sparkVersion = sparkVersion;
        return this;
    }

    /**
     * Get the defaultSparkLogFolder property: The default folder where Spark logs will be written.
     *
     * @return the defaultSparkLogFolder value.
     */
    public String defaultSparkLogFolder() {
        return this.defaultSparkLogFolder;
    }

    /**
     * Set the defaultSparkLogFolder property: The default folder where Spark logs will be written.
     *
     * @param defaultSparkLogFolder the defaultSparkLogFolder value to set.
     * @return the BigDataPoolResourceInfoInner object itself.
     */
    public BigDataPoolResourceInfoInner withDefaultSparkLogFolder(String defaultSparkLogFolder) {
        this.defaultSparkLogFolder = defaultSparkLogFolder;
        return this;
    }

    /**
     * Get the nodeSize property: The level of compute power that each node in the Big Data pool has.
     *
     * @return the nodeSize value.
     */
    public NodeSize nodeSize() {
        return this.nodeSize;
    }

    /**
     * Set the nodeSize property: The level of compute power that each node in the Big Data pool has.
     *
     * @param nodeSize the nodeSize value to set.
     * @return the BigDataPoolResourceInfoInner object itself.
     */
    public BigDataPoolResourceInfoInner withNodeSize(NodeSize nodeSize) {
        this.nodeSize = nodeSize;
        return this;
    }

    /**
     * Get the nodeSizeFamily property: The kind of nodes that the Big Data pool provides.
     *
     * @return the nodeSizeFamily value.
     */
    public NodeSizeFamily nodeSizeFamily() {
        return this.nodeSizeFamily;
    }

    /**
     * Set the nodeSizeFamily property: The kind of nodes that the Big Data pool provides.
     *
     * @param nodeSizeFamily the nodeSizeFamily value to set.
     * @return the BigDataPoolResourceInfoInner object itself.
     */
    public BigDataPoolResourceInfoInner withNodeSizeFamily(NodeSizeFamily nodeSizeFamily) {
        this.nodeSizeFamily = nodeSizeFamily;
        return this;
    }

    /**
     * Get the lastSucceededTimestamp property: The time when the Big Data pool was updated successfully.
     *
     * @return the lastSucceededTimestamp value.
     */
    public OffsetDateTime lastSucceededTimestamp() {
        return this.lastSucceededTimestamp;
    }

    /** {@inheritDoc} */
    @Override
    public BigDataPoolResourceInfoInner withLocation(String location) {
        super.withLocation(location);
        return this;
    }

    /** {@inheritDoc} */
    @Override
    public BigDataPoolResourceInfoInner withTags(Map<String, String> tags) {
        super.withTags(tags);
        return this;
    }

    /**
     * Validates the instance.
     *
     * @throws IllegalArgumentException thrown if the instance is not valid.
     */
    public void validate() {
        if (autoScale() != null) {
            autoScale().validate();
        }
        if (autoPause() != null) {
            autoPause().validate();
        }
        if (dynamicExecutorAllocation() != null) {
            dynamicExecutorAllocation().validate();
        }
        if (libraryRequirements() != null) {
            libraryRequirements().validate();
        }
        if (customLibraries() != null) {
            customLibraries().forEach(e -> e.validate());
        }
        if (sparkConfigProperties() != null) {
            sparkConfigProperties().validate();
        }
    }
}
