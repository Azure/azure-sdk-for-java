// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) AutoRest Code Generator.

package com.azure.resourcemanager.synapse.fluent.models;

import com.azure.core.annotation.Fluent;
import com.azure.core.util.CoreUtils;
import com.azure.json.JsonReader;
import com.azure.json.JsonSerializable;
import com.azure.json.JsonToken;
import com.azure.json.JsonWriter;
import com.azure.resourcemanager.synapse.models.AutoPauseProperties;
import com.azure.resourcemanager.synapse.models.AutoScaleProperties;
import com.azure.resourcemanager.synapse.models.DynamicExecutorAllocation;
import com.azure.resourcemanager.synapse.models.LibraryRequirements;
import com.azure.resourcemanager.synapse.models.NodeSize;
import com.azure.resourcemanager.synapse.models.NodeSizeFamily;
import java.io.IOException;
import java.time.OffsetDateTime;
import java.time.format.DateTimeFormatter;
import java.util.List;

/**
 * Spark pool properties
 * 
 * Properties of a Big Data pool powered by Apache Spark.
 */
@Fluent
public final class BigDataPoolResourceProperties implements JsonSerializable<BigDataPoolResourceProperties> {
    /*
     * The state of the Big Data pool.
     */
    private String provisioningState;

    /*
     * Auto-scaling properties
     */
    private AutoScaleProperties autoScale;

    /*
     * The time when the Big Data pool was created.
     */
    private OffsetDateTime creationDate;

    /*
     * Auto-pausing properties
     */
    private AutoPauseProperties autoPause;

    /*
     * Whether compute isolation is required or not.
     */
    private Boolean isComputeIsolationEnabled;

    /*
     * Whether session level packages enabled.
     */
    private Boolean sessionLevelPackagesEnabled;

    /*
     * The cache size
     */
    private Integer cacheSize;

    /*
     * Dynamic Executor Allocation
     */
    private DynamicExecutorAllocation dynamicExecutorAllocation;

    /*
     * The Spark events folder
     */
    private String sparkEventsFolder;

    /*
     * The number of nodes in the Big Data pool.
     */
    private Integer nodeCount;

    /*
     * Library version requirements
     */
    private LibraryRequirements libraryRequirements;

    /*
     * List of custom libraries/packages associated with the spark pool.
     */
    private List<LibraryInfo> customLibraries;

    /*
     * Spark configuration file to specify additional properties
     */
    private LibraryRequirements sparkConfigProperties;

    /*
     * The Apache Spark version.
     */
    private String sparkVersion;

    /*
     * The default folder where Spark logs will be written.
     */
    private String defaultSparkLogFolder;

    /*
     * The level of compute power that each node in the Big Data pool has.
     */
    private NodeSize nodeSize;

    /*
     * The kind of nodes that the Big Data pool provides.
     */
    private NodeSizeFamily nodeSizeFamily;

    /*
     * The time when the Big Data pool was updated successfully.
     */
    private OffsetDateTime lastSucceededTimestamp;

    /**
     * Creates an instance of BigDataPoolResourceProperties class.
     */
    public BigDataPoolResourceProperties() {
    }

    /**
     * Get the provisioningState property: The state of the Big Data pool.
     * 
     * @return the provisioningState value.
     */
    public String provisioningState() {
        return this.provisioningState;
    }

    /**
     * Set the provisioningState property: The state of the Big Data pool.
     * 
     * @param provisioningState the provisioningState value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withProvisioningState(String provisioningState) {
        this.provisioningState = provisioningState;
        return this;
    }

    /**
     * Get the autoScale property: Auto-scaling properties.
     * 
     * @return the autoScale value.
     */
    public AutoScaleProperties autoScale() {
        return this.autoScale;
    }

    /**
     * Set the autoScale property: Auto-scaling properties.
     * 
     * @param autoScale the autoScale value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withAutoScale(AutoScaleProperties autoScale) {
        this.autoScale = autoScale;
        return this;
    }

    /**
     * Get the creationDate property: The time when the Big Data pool was created.
     * 
     * @return the creationDate value.
     */
    public OffsetDateTime creationDate() {
        return this.creationDate;
    }

    /**
     * Set the creationDate property: The time when the Big Data pool was created.
     * 
     * @param creationDate the creationDate value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withCreationDate(OffsetDateTime creationDate) {
        this.creationDate = creationDate;
        return this;
    }

    /**
     * Get the autoPause property: Auto-pausing properties.
     * 
     * @return the autoPause value.
     */
    public AutoPauseProperties autoPause() {
        return this.autoPause;
    }

    /**
     * Set the autoPause property: Auto-pausing properties.
     * 
     * @param autoPause the autoPause value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withAutoPause(AutoPauseProperties autoPause) {
        this.autoPause = autoPause;
        return this;
    }

    /**
     * Get the isComputeIsolationEnabled property: Whether compute isolation is required or not.
     * 
     * @return the isComputeIsolationEnabled value.
     */
    public Boolean isComputeIsolationEnabled() {
        return this.isComputeIsolationEnabled;
    }

    /**
     * Set the isComputeIsolationEnabled property: Whether compute isolation is required or not.
     * 
     * @param isComputeIsolationEnabled the isComputeIsolationEnabled value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withIsComputeIsolationEnabled(Boolean isComputeIsolationEnabled) {
        this.isComputeIsolationEnabled = isComputeIsolationEnabled;
        return this;
    }

    /**
     * Get the sessionLevelPackagesEnabled property: Whether session level packages enabled.
     * 
     * @return the sessionLevelPackagesEnabled value.
     */
    public Boolean sessionLevelPackagesEnabled() {
        return this.sessionLevelPackagesEnabled;
    }

    /**
     * Set the sessionLevelPackagesEnabled property: Whether session level packages enabled.
     * 
     * @param sessionLevelPackagesEnabled the sessionLevelPackagesEnabled value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withSessionLevelPackagesEnabled(Boolean sessionLevelPackagesEnabled) {
        this.sessionLevelPackagesEnabled = sessionLevelPackagesEnabled;
        return this;
    }

    /**
     * Get the cacheSize property: The cache size.
     * 
     * @return the cacheSize value.
     */
    public Integer cacheSize() {
        return this.cacheSize;
    }

    /**
     * Set the cacheSize property: The cache size.
     * 
     * @param cacheSize the cacheSize value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withCacheSize(Integer cacheSize) {
        this.cacheSize = cacheSize;
        return this;
    }

    /**
     * Get the dynamicExecutorAllocation property: Dynamic Executor Allocation.
     * 
     * @return the dynamicExecutorAllocation value.
     */
    public DynamicExecutorAllocation dynamicExecutorAllocation() {
        return this.dynamicExecutorAllocation;
    }

    /**
     * Set the dynamicExecutorAllocation property: Dynamic Executor Allocation.
     * 
     * @param dynamicExecutorAllocation the dynamicExecutorAllocation value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties
        withDynamicExecutorAllocation(DynamicExecutorAllocation dynamicExecutorAllocation) {
        this.dynamicExecutorAllocation = dynamicExecutorAllocation;
        return this;
    }

    /**
     * Get the sparkEventsFolder property: The Spark events folder.
     * 
     * @return the sparkEventsFolder value.
     */
    public String sparkEventsFolder() {
        return this.sparkEventsFolder;
    }

    /**
     * Set the sparkEventsFolder property: The Spark events folder.
     * 
     * @param sparkEventsFolder the sparkEventsFolder value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withSparkEventsFolder(String sparkEventsFolder) {
        this.sparkEventsFolder = sparkEventsFolder;
        return this;
    }

    /**
     * Get the nodeCount property: The number of nodes in the Big Data pool.
     * 
     * @return the nodeCount value.
     */
    public Integer nodeCount() {
        return this.nodeCount;
    }

    /**
     * Set the nodeCount property: The number of nodes in the Big Data pool.
     * 
     * @param nodeCount the nodeCount value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withNodeCount(Integer nodeCount) {
        this.nodeCount = nodeCount;
        return this;
    }

    /**
     * Get the libraryRequirements property: Library version requirements.
     * 
     * @return the libraryRequirements value.
     */
    public LibraryRequirements libraryRequirements() {
        return this.libraryRequirements;
    }

    /**
     * Set the libraryRequirements property: Library version requirements.
     * 
     * @param libraryRequirements the libraryRequirements value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withLibraryRequirements(LibraryRequirements libraryRequirements) {
        this.libraryRequirements = libraryRequirements;
        return this;
    }

    /**
     * Get the customLibraries property: List of custom libraries/packages associated with the spark pool.
     * 
     * @return the customLibraries value.
     */
    public List<LibraryInfo> customLibraries() {
        return this.customLibraries;
    }

    /**
     * Set the customLibraries property: List of custom libraries/packages associated with the spark pool.
     * 
     * @param customLibraries the customLibraries value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withCustomLibraries(List<LibraryInfo> customLibraries) {
        this.customLibraries = customLibraries;
        return this;
    }

    /**
     * Get the sparkConfigProperties property: Spark configuration file to specify additional properties.
     * 
     * @return the sparkConfigProperties value.
     */
    public LibraryRequirements sparkConfigProperties() {
        return this.sparkConfigProperties;
    }

    /**
     * Set the sparkConfigProperties property: Spark configuration file to specify additional properties.
     * 
     * @param sparkConfigProperties the sparkConfigProperties value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withSparkConfigProperties(LibraryRequirements sparkConfigProperties) {
        this.sparkConfigProperties = sparkConfigProperties;
        return this;
    }

    /**
     * Get the sparkVersion property: The Apache Spark version.
     * 
     * @return the sparkVersion value.
     */
    public String sparkVersion() {
        return this.sparkVersion;
    }

    /**
     * Set the sparkVersion property: The Apache Spark version.
     * 
     * @param sparkVersion the sparkVersion value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withSparkVersion(String sparkVersion) {
        this.sparkVersion = sparkVersion;
        return this;
    }

    /**
     * Get the defaultSparkLogFolder property: The default folder where Spark logs will be written.
     * 
     * @return the defaultSparkLogFolder value.
     */
    public String defaultSparkLogFolder() {
        return this.defaultSparkLogFolder;
    }

    /**
     * Set the defaultSparkLogFolder property: The default folder where Spark logs will be written.
     * 
     * @param defaultSparkLogFolder the defaultSparkLogFolder value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withDefaultSparkLogFolder(String defaultSparkLogFolder) {
        this.defaultSparkLogFolder = defaultSparkLogFolder;
        return this;
    }

    /**
     * Get the nodeSize property: The level of compute power that each node in the Big Data pool has.
     * 
     * @return the nodeSize value.
     */
    public NodeSize nodeSize() {
        return this.nodeSize;
    }

    /**
     * Set the nodeSize property: The level of compute power that each node in the Big Data pool has.
     * 
     * @param nodeSize the nodeSize value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withNodeSize(NodeSize nodeSize) {
        this.nodeSize = nodeSize;
        return this;
    }

    /**
     * Get the nodeSizeFamily property: The kind of nodes that the Big Data pool provides.
     * 
     * @return the nodeSizeFamily value.
     */
    public NodeSizeFamily nodeSizeFamily() {
        return this.nodeSizeFamily;
    }

    /**
     * Set the nodeSizeFamily property: The kind of nodes that the Big Data pool provides.
     * 
     * @param nodeSizeFamily the nodeSizeFamily value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withNodeSizeFamily(NodeSizeFamily nodeSizeFamily) {
        this.nodeSizeFamily = nodeSizeFamily;
        return this;
    }

    /**
     * Get the lastSucceededTimestamp property: The time when the Big Data pool was updated successfully.
     * 
     * @return the lastSucceededTimestamp value.
     */
    public OffsetDateTime lastSucceededTimestamp() {
        return this.lastSucceededTimestamp;
    }

    /**
     * Validates the instance.
     * 
     * @throws IllegalArgumentException thrown if the instance is not valid.
     */
    public void validate() {
        if (autoScale() != null) {
            autoScale().validate();
        }
        if (autoPause() != null) {
            autoPause().validate();
        }
        if (dynamicExecutorAllocation() != null) {
            dynamicExecutorAllocation().validate();
        }
        if (libraryRequirements() != null) {
            libraryRequirements().validate();
        }
        if (customLibraries() != null) {
            customLibraries().forEach(e -> e.validate());
        }
        if (sparkConfigProperties() != null) {
            sparkConfigProperties().validate();
        }
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public JsonWriter toJson(JsonWriter jsonWriter) throws IOException {
        jsonWriter.writeStartObject();
        jsonWriter.writeStringField("provisioningState", this.provisioningState);
        jsonWriter.writeJsonField("autoScale", this.autoScale);
        jsonWriter.writeStringField("creationDate",
            this.creationDate == null ? null : DateTimeFormatter.ISO_OFFSET_DATE_TIME.format(this.creationDate));
        jsonWriter.writeJsonField("autoPause", this.autoPause);
        jsonWriter.writeBooleanField("isComputeIsolationEnabled", this.isComputeIsolationEnabled);
        jsonWriter.writeBooleanField("sessionLevelPackagesEnabled", this.sessionLevelPackagesEnabled);
        jsonWriter.writeNumberField("cacheSize", this.cacheSize);
        jsonWriter.writeJsonField("dynamicExecutorAllocation", this.dynamicExecutorAllocation);
        jsonWriter.writeStringField("sparkEventsFolder", this.sparkEventsFolder);
        jsonWriter.writeNumberField("nodeCount", this.nodeCount);
        jsonWriter.writeJsonField("libraryRequirements", this.libraryRequirements);
        jsonWriter.writeArrayField("customLibraries", this.customLibraries,
            (writer, element) -> writer.writeJson(element));
        jsonWriter.writeJsonField("sparkConfigProperties", this.sparkConfigProperties);
        jsonWriter.writeStringField("sparkVersion", this.sparkVersion);
        jsonWriter.writeStringField("defaultSparkLogFolder", this.defaultSparkLogFolder);
        jsonWriter.writeStringField("nodeSize", this.nodeSize == null ? null : this.nodeSize.toString());
        jsonWriter.writeStringField("nodeSizeFamily",
            this.nodeSizeFamily == null ? null : this.nodeSizeFamily.toString());
        return jsonWriter.writeEndObject();
    }

    /**
     * Reads an instance of BigDataPoolResourceProperties from the JsonReader.
     * 
     * @param jsonReader The JsonReader being read.
     * @return An instance of BigDataPoolResourceProperties if the JsonReader was pointing to an instance of it, or null
     * if it was pointing to JSON null.
     * @throws IOException If an error occurs while reading the BigDataPoolResourceProperties.
     */
    public static BigDataPoolResourceProperties fromJson(JsonReader jsonReader) throws IOException {
        return jsonReader.readObject(reader -> {
            BigDataPoolResourceProperties deserializedBigDataPoolResourceProperties
                = new BigDataPoolResourceProperties();
            while (reader.nextToken() != JsonToken.END_OBJECT) {
                String fieldName = reader.getFieldName();
                reader.nextToken();

                if ("provisioningState".equals(fieldName)) {
                    deserializedBigDataPoolResourceProperties.provisioningState = reader.getString();
                } else if ("autoScale".equals(fieldName)) {
                    deserializedBigDataPoolResourceProperties.autoScale = AutoScaleProperties.fromJson(reader);
                } else if ("creationDate".equals(fieldName)) {
                    deserializedBigDataPoolResourceProperties.creationDate = reader
                        .getNullable(nonNullReader -> CoreUtils.parseBestOffsetDateTime(nonNullReader.getString()));
                } else if ("autoPause".equals(fieldName)) {
                    deserializedBigDataPoolResourceProperties.autoPause = AutoPauseProperties.fromJson(reader);
                } else if ("isComputeIsolationEnabled".equals(fieldName)) {
                    deserializedBigDataPoolResourceProperties.isComputeIsolationEnabled
                        = reader.getNullable(JsonReader::getBoolean);
                } else if ("sessionLevelPackagesEnabled".equals(fieldName)) {
                    deserializedBigDataPoolResourceProperties.sessionLevelPackagesEnabled
                        = reader.getNullable(JsonReader::getBoolean);
                } else if ("cacheSize".equals(fieldName)) {
                    deserializedBigDataPoolResourceProperties.cacheSize = reader.getNullable(JsonReader::getInt);
                } else if ("dynamicExecutorAllocation".equals(fieldName)) {
                    deserializedBigDataPoolResourceProperties.dynamicExecutorAllocation
                        = DynamicExecutorAllocation.fromJson(reader);
                } else if ("sparkEventsFolder".equals(fieldName)) {
                    deserializedBigDataPoolResourceProperties.sparkEventsFolder = reader.getString();
                } else if ("nodeCount".equals(fieldName)) {
                    deserializedBigDataPoolResourceProperties.nodeCount = reader.getNullable(JsonReader::getInt);
                } else if ("libraryRequirements".equals(fieldName)) {
                    deserializedBigDataPoolResourceProperties.libraryRequirements
                        = LibraryRequirements.fromJson(reader);
                } else if ("customLibraries".equals(fieldName)) {
                    List<LibraryInfo> customLibraries = reader.readArray(reader1 -> LibraryInfo.fromJson(reader1));
                    deserializedBigDataPoolResourceProperties.customLibraries = customLibraries;
                } else if ("sparkConfigProperties".equals(fieldName)) {
                    deserializedBigDataPoolResourceProperties.sparkConfigProperties
                        = LibraryRequirements.fromJson(reader);
                } else if ("sparkVersion".equals(fieldName)) {
                    deserializedBigDataPoolResourceProperties.sparkVersion = reader.getString();
                } else if ("defaultSparkLogFolder".equals(fieldName)) {
                    deserializedBigDataPoolResourceProperties.defaultSparkLogFolder = reader.getString();
                } else if ("nodeSize".equals(fieldName)) {
                    deserializedBigDataPoolResourceProperties.nodeSize = NodeSize.fromString(reader.getString());
                } else if ("nodeSizeFamily".equals(fieldName)) {
                    deserializedBigDataPoolResourceProperties.nodeSizeFamily
                        = NodeSizeFamily.fromString(reader.getString());
                } else if ("lastSucceededTimestamp".equals(fieldName)) {
                    deserializedBigDataPoolResourceProperties.lastSucceededTimestamp = reader
                        .getNullable(nonNullReader -> CoreUtils.parseBestOffsetDateTime(nonNullReader.getString()));
                } else {
                    reader.skipChildren();
                }
            }

            return deserializedBigDataPoolResourceProperties;
        });
    }
}
