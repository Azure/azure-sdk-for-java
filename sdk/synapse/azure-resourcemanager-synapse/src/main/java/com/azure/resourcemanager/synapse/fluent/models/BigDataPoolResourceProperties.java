// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) AutoRest Code Generator.

package com.azure.resourcemanager.synapse.fluent.models;

import com.azure.core.annotation.Fluent;
import com.azure.resourcemanager.synapse.models.AutoPauseProperties;
import com.azure.resourcemanager.synapse.models.AutoScaleProperties;
import com.azure.resourcemanager.synapse.models.DynamicExecutorAllocation;
import com.azure.resourcemanager.synapse.models.LibraryRequirements;
import com.azure.resourcemanager.synapse.models.NodeSize;
import com.azure.resourcemanager.synapse.models.NodeSizeFamily;
import com.azure.resourcemanager.synapse.models.SparkConfigProperties;
import com.fasterxml.jackson.annotation.JsonProperty;
import java.time.OffsetDateTime;
import java.util.List;

/**
 * Spark pool properties
 *
 * <p>Properties of a Big Data pool powered by Apache Spark.
 */
@Fluent
public final class BigDataPoolResourceProperties {
    /*
     * The state of the Big Data pool.
     */
    @JsonProperty(value = "provisioningState")
    private String provisioningState;

    /*
     * Spark pool auto-scaling properties
     *
     * Auto-scaling properties
     */
    @JsonProperty(value = "autoScale")
    private AutoScaleProperties autoScale;

    /*
     * The time when the Big Data pool was created.
     */
    @JsonProperty(value = "creationDate", access = JsonProperty.Access.WRITE_ONLY)
    private OffsetDateTime creationDate;

    /*
     * Spark pool auto-pausing properties
     *
     * Auto-pausing properties
     */
    @JsonProperty(value = "autoPause")
    private AutoPauseProperties autoPause;

    /*
     * Whether compute isolation is required or not.
     */
    @JsonProperty(value = "isComputeIsolationEnabled")
    private Boolean isComputeIsolationEnabled;

    /*
     * Enable Autotune
     *
     * Whether autotune is required or not.
     */
    @JsonProperty(value = "isAutotuneEnabled")
    private Boolean isAutotuneEnabled;

    /*
     * Whether session level packages enabled.
     */
    @JsonProperty(value = "sessionLevelPackagesEnabled")
    private Boolean sessionLevelPackagesEnabled;

    /*
     * The cache size
     */
    @JsonProperty(value = "cacheSize", access = JsonProperty.Access.WRITE_ONLY)
    private Integer cacheSize;

    /*
     * Dynamic Executor Allocation
     */
    @JsonProperty(value = "dynamicExecutorAllocation")
    private DynamicExecutorAllocation dynamicExecutorAllocation;

    /*
     * The Spark events folder
     */
    @JsonProperty(value = "sparkEventsFolder")
    private String sparkEventsFolder;

    /*
     * The number of nodes in the Big Data pool.
     */
    @JsonProperty(value = "nodeCount")
    private Integer nodeCount;

    /*
     * Spark pool library version requirements
     *
     * Library version requirements
     */
    @JsonProperty(value = "libraryRequirements")
    private LibraryRequirements libraryRequirements;

    /*
     * List of custom libraries/packages associated with the spark pool.
     */
    @JsonProperty(value = "customLibraries")
    private List<LibraryInfo> customLibraries;

    /*
     * Spark pool Config Properties
     *
     * Spark configuration file to specify additional properties
     */
    @JsonProperty(value = "sparkConfigProperties")
    private SparkConfigProperties sparkConfigProperties;

    /*
     * The Apache Spark version.
     */
    @JsonProperty(value = "sparkVersion")
    private String sparkVersion;

    /*
     * The default folder where Spark logs will be written.
     */
    @JsonProperty(value = "defaultSparkLogFolder")
    private String defaultSparkLogFolder;

    /*
     * The level of compute power that each node in the Big Data pool has.
     */
    @JsonProperty(value = "nodeSize")
    private NodeSize nodeSize;

    /*
     * The kind of nodes that the Big Data pool provides.
     */
    @JsonProperty(value = "nodeSizeFamily")
    private NodeSizeFamily nodeSizeFamily;

    /*
     * The time when the Big Data pool was updated successfully.
     */
    @JsonProperty(value = "lastSucceededTimestamp", access = JsonProperty.Access.WRITE_ONLY)
    private OffsetDateTime lastSucceededTimestamp;

    /** Creates an instance of BigDataPoolResourceProperties class. */
    public BigDataPoolResourceProperties() {
    }

    /**
     * Get the provisioningState property: The state of the Big Data pool.
     *
     * @return the provisioningState value.
     */
    public String provisioningState() {
        return this.provisioningState;
    }

    /**
     * Set the provisioningState property: The state of the Big Data pool.
     *
     * @param provisioningState the provisioningState value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withProvisioningState(String provisioningState) {
        this.provisioningState = provisioningState;
        return this;
    }

    /**
     * Get the autoScale property: Spark pool auto-scaling properties
     *
     * <p>Auto-scaling properties.
     *
     * @return the autoScale value.
     */
    public AutoScaleProperties autoScale() {
        return this.autoScale;
    }

    /**
     * Set the autoScale property: Spark pool auto-scaling properties
     *
     * <p>Auto-scaling properties.
     *
     * @param autoScale the autoScale value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withAutoScale(AutoScaleProperties autoScale) {
        this.autoScale = autoScale;
        return this;
    }

    /**
     * Get the creationDate property: The time when the Big Data pool was created.
     *
     * @return the creationDate value.
     */
    public OffsetDateTime creationDate() {
        return this.creationDate;
    }

    /**
     * Get the autoPause property: Spark pool auto-pausing properties
     *
     * <p>Auto-pausing properties.
     *
     * @return the autoPause value.
     */
    public AutoPauseProperties autoPause() {
        return this.autoPause;
    }

    /**
     * Set the autoPause property: Spark pool auto-pausing properties
     *
     * <p>Auto-pausing properties.
     *
     * @param autoPause the autoPause value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withAutoPause(AutoPauseProperties autoPause) {
        this.autoPause = autoPause;
        return this;
    }

    /**
     * Get the isComputeIsolationEnabled property: Whether compute isolation is required or not.
     *
     * @return the isComputeIsolationEnabled value.
     */
    public Boolean isComputeIsolationEnabled() {
        return this.isComputeIsolationEnabled;
    }

    /**
     * Set the isComputeIsolationEnabled property: Whether compute isolation is required or not.
     *
     * @param isComputeIsolationEnabled the isComputeIsolationEnabled value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withIsComputeIsolationEnabled(Boolean isComputeIsolationEnabled) {
        this.isComputeIsolationEnabled = isComputeIsolationEnabled;
        return this;
    }

    /**
     * Get the isAutotuneEnabled property: Enable Autotune
     *
     * <p>Whether autotune is required or not.
     *
     * @return the isAutotuneEnabled value.
     */
    public Boolean isAutotuneEnabled() {
        return this.isAutotuneEnabled;
    }

    /**
     * Set the isAutotuneEnabled property: Enable Autotune
     *
     * <p>Whether autotune is required or not.
     *
     * @param isAutotuneEnabled the isAutotuneEnabled value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withIsAutotuneEnabled(Boolean isAutotuneEnabled) {
        this.isAutotuneEnabled = isAutotuneEnabled;
        return this;
    }

    /**
     * Get the sessionLevelPackagesEnabled property: Whether session level packages enabled.
     *
     * @return the sessionLevelPackagesEnabled value.
     */
    public Boolean sessionLevelPackagesEnabled() {
        return this.sessionLevelPackagesEnabled;
    }

    /**
     * Set the sessionLevelPackagesEnabled property: Whether session level packages enabled.
     *
     * @param sessionLevelPackagesEnabled the sessionLevelPackagesEnabled value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withSessionLevelPackagesEnabled(Boolean sessionLevelPackagesEnabled) {
        this.sessionLevelPackagesEnabled = sessionLevelPackagesEnabled;
        return this;
    }

    /**
     * Get the cacheSize property: The cache size.
     *
     * @return the cacheSize value.
     */
    public Integer cacheSize() {
        return this.cacheSize;
    }

    /**
     * Get the dynamicExecutorAllocation property: Dynamic Executor Allocation.
     *
     * @return the dynamicExecutorAllocation value.
     */
    public DynamicExecutorAllocation dynamicExecutorAllocation() {
        return this.dynamicExecutorAllocation;
    }

    /**
     * Set the dynamicExecutorAllocation property: Dynamic Executor Allocation.
     *
     * @param dynamicExecutorAllocation the dynamicExecutorAllocation value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withDynamicExecutorAllocation(
        DynamicExecutorAllocation dynamicExecutorAllocation) {
        this.dynamicExecutorAllocation = dynamicExecutorAllocation;
        return this;
    }

    /**
     * Get the sparkEventsFolder property: The Spark events folder.
     *
     * @return the sparkEventsFolder value.
     */
    public String sparkEventsFolder() {
        return this.sparkEventsFolder;
    }

    /**
     * Set the sparkEventsFolder property: The Spark events folder.
     *
     * @param sparkEventsFolder the sparkEventsFolder value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withSparkEventsFolder(String sparkEventsFolder) {
        this.sparkEventsFolder = sparkEventsFolder;
        return this;
    }

    /**
     * Get the nodeCount property: The number of nodes in the Big Data pool.
     *
     * @return the nodeCount value.
     */
    public Integer nodeCount() {
        return this.nodeCount;
    }

    /**
     * Set the nodeCount property: The number of nodes in the Big Data pool.
     *
     * @param nodeCount the nodeCount value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withNodeCount(Integer nodeCount) {
        this.nodeCount = nodeCount;
        return this;
    }

    /**
     * Get the libraryRequirements property: Spark pool library version requirements
     *
     * <p>Library version requirements.
     *
     * @return the libraryRequirements value.
     */
    public LibraryRequirements libraryRequirements() {
        return this.libraryRequirements;
    }

    /**
     * Set the libraryRequirements property: Spark pool library version requirements
     *
     * <p>Library version requirements.
     *
     * @param libraryRequirements the libraryRequirements value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withLibraryRequirements(LibraryRequirements libraryRequirements) {
        this.libraryRequirements = libraryRequirements;
        return this;
    }

    /**
     * Get the customLibraries property: List of custom libraries/packages associated with the spark pool.
     *
     * @return the customLibraries value.
     */
    public List<LibraryInfo> customLibraries() {
        return this.customLibraries;
    }

    /**
     * Set the customLibraries property: List of custom libraries/packages associated with the spark pool.
     *
     * @param customLibraries the customLibraries value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withCustomLibraries(List<LibraryInfo> customLibraries) {
        this.customLibraries = customLibraries;
        return this;
    }

    /**
     * Get the sparkConfigProperties property: Spark pool Config Properties
     *
     * <p>Spark configuration file to specify additional properties.
     *
     * @return the sparkConfigProperties value.
     */
    public SparkConfigProperties sparkConfigProperties() {
        return this.sparkConfigProperties;
    }

    /**
     * Set the sparkConfigProperties property: Spark pool Config Properties
     *
     * <p>Spark configuration file to specify additional properties.
     *
     * @param sparkConfigProperties the sparkConfigProperties value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withSparkConfigProperties(SparkConfigProperties sparkConfigProperties) {
        this.sparkConfigProperties = sparkConfigProperties;
        return this;
    }

    /**
     * Get the sparkVersion property: The Apache Spark version.
     *
     * @return the sparkVersion value.
     */
    public String sparkVersion() {
        return this.sparkVersion;
    }

    /**
     * Set the sparkVersion property: The Apache Spark version.
     *
     * @param sparkVersion the sparkVersion value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withSparkVersion(String sparkVersion) {
        this.sparkVersion = sparkVersion;
        return this;
    }

    /**
     * Get the defaultSparkLogFolder property: The default folder where Spark logs will be written.
     *
     * @return the defaultSparkLogFolder value.
     */
    public String defaultSparkLogFolder() {
        return this.defaultSparkLogFolder;
    }

    /**
     * Set the defaultSparkLogFolder property: The default folder where Spark logs will be written.
     *
     * @param defaultSparkLogFolder the defaultSparkLogFolder value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withDefaultSparkLogFolder(String defaultSparkLogFolder) {
        this.defaultSparkLogFolder = defaultSparkLogFolder;
        return this;
    }

    /**
     * Get the nodeSize property: The level of compute power that each node in the Big Data pool has.
     *
     * @return the nodeSize value.
     */
    public NodeSize nodeSize() {
        return this.nodeSize;
    }

    /**
     * Set the nodeSize property: The level of compute power that each node in the Big Data pool has.
     *
     * @param nodeSize the nodeSize value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withNodeSize(NodeSize nodeSize) {
        this.nodeSize = nodeSize;
        return this;
    }

    /**
     * Get the nodeSizeFamily property: The kind of nodes that the Big Data pool provides.
     *
     * @return the nodeSizeFamily value.
     */
    public NodeSizeFamily nodeSizeFamily() {
        return this.nodeSizeFamily;
    }

    /**
     * Set the nodeSizeFamily property: The kind of nodes that the Big Data pool provides.
     *
     * @param nodeSizeFamily the nodeSizeFamily value to set.
     * @return the BigDataPoolResourceProperties object itself.
     */
    public BigDataPoolResourceProperties withNodeSizeFamily(NodeSizeFamily nodeSizeFamily) {
        this.nodeSizeFamily = nodeSizeFamily;
        return this;
    }

    /**
     * Get the lastSucceededTimestamp property: The time when the Big Data pool was updated successfully.
     *
     * @return the lastSucceededTimestamp value.
     */
    public OffsetDateTime lastSucceededTimestamp() {
        return this.lastSucceededTimestamp;
    }

    /**
     * Validates the instance.
     *
     * @throws IllegalArgumentException thrown if the instance is not valid.
     */
    public void validate() {
        if (autoScale() != null) {
            autoScale().validate();
        }
        if (autoPause() != null) {
            autoPause().validate();
        }
        if (dynamicExecutorAllocation() != null) {
            dynamicExecutorAllocation().validate();
        }
        if (libraryRequirements() != null) {
            libraryRequirements().validate();
        }
        if (customLibraries() != null) {
            customLibraries().forEach(e -> e.validate());
        }
        if (sparkConfigProperties() != null) {
            sparkConfigProperties().validate();
        }
    }
}
