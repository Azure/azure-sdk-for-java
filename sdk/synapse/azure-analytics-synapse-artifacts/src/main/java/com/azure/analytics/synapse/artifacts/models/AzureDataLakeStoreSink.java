// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) AutoRest Code Generator.

package com.azure.analytics.synapse.artifacts.models;

import com.azure.core.annotation.Fluent;
import com.azure.json.JsonReader;
import com.azure.json.JsonToken;
import com.azure.json.JsonWriter;
import java.io.IOException;
import java.util.LinkedHashMap;
import java.util.Map;

/**
 * A copy activity Azure Data Lake Store sink.
 */
@Fluent
public final class AzureDataLakeStoreSink extends CopySink {
    /*
     * Copy sink type.
     */
    private String type = "AzureDataLakeStoreSink";

    /*
     * The type of copy behavior for copy sink. Type: string (or Expression with resultType string).
     */
    private Object copyBehavior;

    /*
     * Single File Parallel.
     */
    private Object enableAdlsSingleFileParallel;

    /**
     * Creates an instance of AzureDataLakeStoreSink class.
     */
    public AzureDataLakeStoreSink() {
    }

    /**
     * Get the type property: Copy sink type.
     * 
     * @return the type value.
     */
    @Override
    public String getType() {
        return this.type;
    }

    /**
     * Get the copyBehavior property: The type of copy behavior for copy sink. Type: string (or Expression with
     * resultType string).
     * 
     * @return the copyBehavior value.
     */
    public Object getCopyBehavior() {
        return this.copyBehavior;
    }

    /**
     * Set the copyBehavior property: The type of copy behavior for copy sink. Type: string (or Expression with
     * resultType string).
     * 
     * @param copyBehavior the copyBehavior value to set.
     * @return the AzureDataLakeStoreSink object itself.
     */
    public AzureDataLakeStoreSink setCopyBehavior(Object copyBehavior) {
        this.copyBehavior = copyBehavior;
        return this;
    }

    /**
     * Get the enableAdlsSingleFileParallel property: Single File Parallel.
     * 
     * @return the enableAdlsSingleFileParallel value.
     */
    public Object getEnableAdlsSingleFileParallel() {
        return this.enableAdlsSingleFileParallel;
    }

    /**
     * Set the enableAdlsSingleFileParallel property: Single File Parallel.
     * 
     * @param enableAdlsSingleFileParallel the enableAdlsSingleFileParallel value to set.
     * @return the AzureDataLakeStoreSink object itself.
     */
    public AzureDataLakeStoreSink setEnableAdlsSingleFileParallel(Object enableAdlsSingleFileParallel) {
        this.enableAdlsSingleFileParallel = enableAdlsSingleFileParallel;
        return this;
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public AzureDataLakeStoreSink setWriteBatchSize(Object writeBatchSize) {
        super.setWriteBatchSize(writeBatchSize);
        return this;
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public AzureDataLakeStoreSink setWriteBatchTimeout(Object writeBatchTimeout) {
        super.setWriteBatchTimeout(writeBatchTimeout);
        return this;
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public AzureDataLakeStoreSink setSinkRetryCount(Object sinkRetryCount) {
        super.setSinkRetryCount(sinkRetryCount);
        return this;
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public AzureDataLakeStoreSink setSinkRetryWait(Object sinkRetryWait) {
        super.setSinkRetryWait(sinkRetryWait);
        return this;
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public AzureDataLakeStoreSink setMaxConcurrentConnections(Object maxConcurrentConnections) {
        super.setMaxConcurrentConnections(maxConcurrentConnections);
        return this;
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public JsonWriter toJson(JsonWriter jsonWriter) throws IOException {
        jsonWriter.writeStartObject();
        jsonWriter.writeUntypedField("writeBatchSize", getWriteBatchSize());
        jsonWriter.writeUntypedField("writeBatchTimeout", getWriteBatchTimeout());
        jsonWriter.writeUntypedField("sinkRetryCount", getSinkRetryCount());
        jsonWriter.writeUntypedField("sinkRetryWait", getSinkRetryWait());
        jsonWriter.writeUntypedField("maxConcurrentConnections", getMaxConcurrentConnections());
        jsonWriter.writeStringField("type", this.type);
        jsonWriter.writeUntypedField("copyBehavior", this.copyBehavior);
        jsonWriter.writeUntypedField("enableAdlsSingleFileParallel", this.enableAdlsSingleFileParallel);
        if (getAdditionalProperties() != null) {
            for (Map.Entry<String, Object> additionalProperty : getAdditionalProperties().entrySet()) {
                jsonWriter.writeUntypedField(additionalProperty.getKey(), additionalProperty.getValue());
            }
        }
        return jsonWriter.writeEndObject();
    }

    /**
     * Reads an instance of AzureDataLakeStoreSink from the JsonReader.
     * 
     * @param jsonReader The JsonReader being read.
     * @return An instance of AzureDataLakeStoreSink if the JsonReader was pointing to an instance of it, or null if it
     * was pointing to JSON null.
     * @throws IOException If an error occurs while reading the AzureDataLakeStoreSink.
     */
    public static AzureDataLakeStoreSink fromJson(JsonReader jsonReader) throws IOException {
        return jsonReader.readObject(reader -> {
            AzureDataLakeStoreSink deserializedAzureDataLakeStoreSink = new AzureDataLakeStoreSink();
            Map<String, Object> additionalProperties = null;
            while (reader.nextToken() != JsonToken.END_OBJECT) {
                String fieldName = reader.getFieldName();
                reader.nextToken();

                if ("writeBatchSize".equals(fieldName)) {
                    deserializedAzureDataLakeStoreSink.setWriteBatchSize(reader.readUntyped());
                } else if ("writeBatchTimeout".equals(fieldName)) {
                    deserializedAzureDataLakeStoreSink.setWriteBatchTimeout(reader.readUntyped());
                } else if ("sinkRetryCount".equals(fieldName)) {
                    deserializedAzureDataLakeStoreSink.setSinkRetryCount(reader.readUntyped());
                } else if ("sinkRetryWait".equals(fieldName)) {
                    deserializedAzureDataLakeStoreSink.setSinkRetryWait(reader.readUntyped());
                } else if ("maxConcurrentConnections".equals(fieldName)) {
                    deserializedAzureDataLakeStoreSink.setMaxConcurrentConnections(reader.readUntyped());
                } else if ("type".equals(fieldName)) {
                    deserializedAzureDataLakeStoreSink.type = reader.getString();
                } else if ("copyBehavior".equals(fieldName)) {
                    deserializedAzureDataLakeStoreSink.copyBehavior = reader.readUntyped();
                } else if ("enableAdlsSingleFileParallel".equals(fieldName)) {
                    deserializedAzureDataLakeStoreSink.enableAdlsSingleFileParallel = reader.readUntyped();
                } else {
                    if (additionalProperties == null) {
                        additionalProperties = new LinkedHashMap<>();
                    }

                    additionalProperties.put(fieldName, reader.readUntyped());
                }
            }
            deserializedAzureDataLakeStoreSink.setAdditionalProperties(additionalProperties);

            return deserializedAzureDataLakeStoreSink;
        });
    }
}
