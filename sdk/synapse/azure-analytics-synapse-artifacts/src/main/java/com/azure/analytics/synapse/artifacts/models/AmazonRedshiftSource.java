// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) AutoRest Code Generator.

package com.azure.analytics.synapse.artifacts.models;

import com.azure.core.annotation.Fluent;
import com.azure.json.JsonReader;
import com.azure.json.JsonToken;
import com.azure.json.JsonWriter;
import java.io.IOException;
import java.util.LinkedHashMap;
import java.util.Map;

/**
 * A copy activity source for Amazon Redshift Source.
 */
@Fluent
public final class AmazonRedshiftSource extends TabularSource {
    /*
     * Copy source type.
     */
    private String type = "AmazonRedshiftSource";

    /*
     * Database query. Type: string (or Expression with resultType string).
     */
    private Object query;

    /*
     * The Amazon S3 settings needed for the interim Amazon S3 when copying from Amazon Redshift with unload. With this, data from Amazon Redshift source will be unloaded into S3 first and then copied into the targeted sink from the interim S3.
     */
    private RedshiftUnloadSettings redshiftUnloadSettings;

    /**
     * Creates an instance of AmazonRedshiftSource class.
     */
    public AmazonRedshiftSource() {
    }

    /**
     * Get the type property: Copy source type.
     * 
     * @return the type value.
     */
    @Override
    public String getType() {
        return this.type;
    }

    /**
     * Get the query property: Database query. Type: string (or Expression with resultType string).
     * 
     * @return the query value.
     */
    public Object getQuery() {
        return this.query;
    }

    /**
     * Set the query property: Database query. Type: string (or Expression with resultType string).
     * 
     * @param query the query value to set.
     * @return the AmazonRedshiftSource object itself.
     */
    public AmazonRedshiftSource setQuery(Object query) {
        this.query = query;
        return this;
    }

    /**
     * Get the redshiftUnloadSettings property: The Amazon S3 settings needed for the interim Amazon S3 when copying
     * from Amazon Redshift with unload. With this, data from Amazon Redshift source will be unloaded into S3 first and
     * then copied into the targeted sink from the interim S3.
     * 
     * @return the redshiftUnloadSettings value.
     */
    public RedshiftUnloadSettings getRedshiftUnloadSettings() {
        return this.redshiftUnloadSettings;
    }

    /**
     * Set the redshiftUnloadSettings property: The Amazon S3 settings needed for the interim Amazon S3 when copying
     * from Amazon Redshift with unload. With this, data from Amazon Redshift source will be unloaded into S3 first and
     * then copied into the targeted sink from the interim S3.
     * 
     * @param redshiftUnloadSettings the redshiftUnloadSettings value to set.
     * @return the AmazonRedshiftSource object itself.
     */
    public AmazonRedshiftSource setRedshiftUnloadSettings(RedshiftUnloadSettings redshiftUnloadSettings) {
        this.redshiftUnloadSettings = redshiftUnloadSettings;
        return this;
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public AmazonRedshiftSource setQueryTimeout(Object queryTimeout) {
        super.setQueryTimeout(queryTimeout);
        return this;
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public AmazonRedshiftSource setAdditionalColumns(Object additionalColumns) {
        super.setAdditionalColumns(additionalColumns);
        return this;
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public AmazonRedshiftSource setSourceRetryCount(Object sourceRetryCount) {
        super.setSourceRetryCount(sourceRetryCount);
        return this;
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public AmazonRedshiftSource setSourceRetryWait(Object sourceRetryWait) {
        super.setSourceRetryWait(sourceRetryWait);
        return this;
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public AmazonRedshiftSource setMaxConcurrentConnections(Object maxConcurrentConnections) {
        super.setMaxConcurrentConnections(maxConcurrentConnections);
        return this;
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public JsonWriter toJson(JsonWriter jsonWriter) throws IOException {
        jsonWriter.writeStartObject();
        jsonWriter.writeUntypedField("sourceRetryCount", getSourceRetryCount());
        jsonWriter.writeUntypedField("sourceRetryWait", getSourceRetryWait());
        jsonWriter.writeUntypedField("maxConcurrentConnections", getMaxConcurrentConnections());
        jsonWriter.writeUntypedField("queryTimeout", getQueryTimeout());
        jsonWriter.writeUntypedField("additionalColumns", getAdditionalColumns());
        jsonWriter.writeStringField("type", this.type);
        jsonWriter.writeUntypedField("query", this.query);
        jsonWriter.writeJsonField("redshiftUnloadSettings", this.redshiftUnloadSettings);
        if (getAdditionalProperties() != null) {
            for (Map.Entry<String, Object> additionalProperty : getAdditionalProperties().entrySet()) {
                jsonWriter.writeUntypedField(additionalProperty.getKey(), additionalProperty.getValue());
            }
        }
        return jsonWriter.writeEndObject();
    }

    /**
     * Reads an instance of AmazonRedshiftSource from the JsonReader.
     * 
     * @param jsonReader The JsonReader being read.
     * @return An instance of AmazonRedshiftSource if the JsonReader was pointing to an instance of it, or null if it
     * was pointing to JSON null.
     * @throws IOException If an error occurs while reading the AmazonRedshiftSource.
     */
    public static AmazonRedshiftSource fromJson(JsonReader jsonReader) throws IOException {
        return jsonReader.readObject(reader -> {
            AmazonRedshiftSource deserializedAmazonRedshiftSource = new AmazonRedshiftSource();
            Map<String, Object> additionalProperties = null;
            while (reader.nextToken() != JsonToken.END_OBJECT) {
                String fieldName = reader.getFieldName();
                reader.nextToken();

                if ("sourceRetryCount".equals(fieldName)) {
                    deserializedAmazonRedshiftSource.setSourceRetryCount(reader.readUntyped());
                } else if ("sourceRetryWait".equals(fieldName)) {
                    deserializedAmazonRedshiftSource.setSourceRetryWait(reader.readUntyped());
                } else if ("maxConcurrentConnections".equals(fieldName)) {
                    deserializedAmazonRedshiftSource.setMaxConcurrentConnections(reader.readUntyped());
                } else if ("queryTimeout".equals(fieldName)) {
                    deserializedAmazonRedshiftSource.setQueryTimeout(reader.readUntyped());
                } else if ("additionalColumns".equals(fieldName)) {
                    deserializedAmazonRedshiftSource.setAdditionalColumns(reader.readUntyped());
                } else if ("type".equals(fieldName)) {
                    deserializedAmazonRedshiftSource.type = reader.getString();
                } else if ("query".equals(fieldName)) {
                    deserializedAmazonRedshiftSource.query = reader.readUntyped();
                } else if ("redshiftUnloadSettings".equals(fieldName)) {
                    deserializedAmazonRedshiftSource.redshiftUnloadSettings = RedshiftUnloadSettings.fromJson(reader);
                } else {
                    if (additionalProperties == null) {
                        additionalProperties = new LinkedHashMap<>();
                    }

                    additionalProperties.put(fieldName, reader.readUntyped());
                }
            }
            deserializedAmazonRedshiftSource.setAdditionalProperties(additionalProperties);

            return deserializedAmazonRedshiftSource;
        });
    }
}
