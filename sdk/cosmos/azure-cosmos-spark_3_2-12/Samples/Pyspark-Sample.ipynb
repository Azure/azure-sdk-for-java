{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8d122d67-03ea-4684-af8d-7c68e4d6bc77",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# configuration\n",
    "cosmosEndpoint = \"https://REPLACEME.documents.azure.com:443/\"\n",
    "cosmosMasterKey = \"REPLACEME\"\n",
    "cosmosDatabaseName = \"sampleDB\"\n",
    "cosmosContainerName = \"sampleContainer\"\n",
    "\n",
    "cfg = { \n",
    "  \"spark.cosmos.accountEndpoint\" : cosmosEndpoint,\n",
    "  \"spark.cosmos.accountKey\" : cosmosMasterKey,\n",
    "  \"spark.cosmos.database\" : cosmosDatabaseName,\n",
    "  \"spark.cosmos.container\" : cosmosContainerName\n",
    "}\n",
    "\n",
    "cfgWithAutoSchemaInference = {\n",
    "  \"spark.cosmos.accountEndpoint\" : cosmosEndpoint,\n",
    "  \"spark.cosmos.accountKey\" : cosmosMasterKey,\n",
    "  \"spark.cosmos.database\" : cosmosDatabaseName,\n",
    "  \"spark.cosmos.container\" : cosmosContainerName,\n",
    "  \"spark.cosmos.read.inferSchema.enabled\" : \"true\"                          \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6207f648-b3f0-4766-a6f4-0357001ec25c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create Cosmos Database and Cosmos Container using Catalog APIs\n",
    "spark.conf.set(\"spark.sql.catalog.cosmosCatalog\", \"com.azure.cosmos.spark.CosmosCatalog\")\n",
    "spark.conf.set(\"spark.sql.catalog.cosmosCatalog.spark.cosmos.accountEndpoint\", cosmosEndpoint)\n",
    "spark.conf.set(\"spark.sql.catalog.cosmosCatalog.spark.cosmos.accountKey\", cosmosMasterKey)\n",
    "\n",
    "# create a cosmos database\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS cosmosCatalog.{};\".format(cosmosDatabaseName))\n",
    "\n",
    "# create a cosmos container\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS cosmosCatalog.{}.{} using cosmos.oltp TBLPROPERTIES(partitionKeyPath = '/id', manualThroughput = '1100')\".format(cosmosDatabaseName, cosmosContainerName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "61668bf2-6adf-48e9-b713-89ee89f8c576",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ingestion\n",
    "spark.createDataFrame(((\"cat-alive\", \"Schrodinger cat\", 2, True), (\"cat-dead\", \"Schrodinger cat\", 2, False)))\\\n",
    "  .toDF(\"id\",\"name\",\"age\",\"isAlive\") \\\n",
    "   .write\\\n",
    "   .format(\"cosmos.oltp\")\\\n",
    "   .options(**cfg)\\\n",
    "   .mode(\"APPEND\")\\\n",
    "   .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a9f3b3a1-6998-4f80-ac5b-853eb114f0dd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Show the schema of the table and data without auto schema inference\n",
    "df = spark.read.format(\"cosmos.oltp\").options(**cfg).load()\n",
    "df.printSchema()\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7ae0de19-cca9-4020-be34-2632fc1aed0a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Show the schema of the table and data with auto schema inference\n",
    "df = spark.read.format(\"cosmos.oltp\").options(**cfgWithAutoSchemaInference).load()\n",
    "df.printSchema()\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0fd089b3-7444-482a-a4f9-f392a7a97be0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Query to find the live cat and increment age of the alive cat\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df.filter(col(\"isAlive\") == True)\\\n",
    " .withColumn(\"age\", col(\"age\") + 1)\\\n",
    " .show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookName": "Pyspark Sample",
   "notebookOrigID": 2751127018611033,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
