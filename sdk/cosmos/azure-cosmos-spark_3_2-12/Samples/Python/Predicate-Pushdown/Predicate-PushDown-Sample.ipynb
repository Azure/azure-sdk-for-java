{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "25286b74-3fa0-4771-9241-fb41a2267633",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Secrets**\n",
    "\n",
    "The secrets below  like the Cosmos account key are retrieved from a secret scope. If you don't have defined a secret scope for a Cosmos Account you want to use when going through this sample you can find the instructions on how to create one here:\n",
    "- Here you can [Create a new secret scope](./#secrets/createScope) for the current Databricks workspace\n",
    "  - See how you can create an [Azure Key Vault backed secret scope](https://docs.microsoft.com/azure/databricks/security/secrets/secret-scopes#--create-an-azure-key-vault-backed-secret-scope) \n",
    "  - See how you can create a [Databricks backed secret scope](https://docs.microsoft.com/azure/databricks/security/secrets/secret-scopes#create-a-databricks-backed-secret-scope)\n",
    "- And here you can find information on how to [add secrets to your Spark configuration](https://docs.microsoft.com/azure/databricks/security/secrets/secrets#read-a-secret)\n",
    "If you don't want to use secrets at all you can of course also just assign the values in clear-text below - but for obvious reasons we recommend the usage of secrets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c6d1b866-fd0b-4646-a620-a3af8f6f473d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cosmosEndpoint = spark.conf.get(\"spark.cosmos.accountEndpoint\")\n",
    "cosmosMasterKey = spark.conf.get(\"spark.cosmos.accountKey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "dfebb07b-9f13-4817-9b3c-f3b62f994a77",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Preparation - creating the Cosmos DB container to ingest the data into**\n",
    "\n",
    "Configure the Catalog API to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b3d49ee4-b490-4e30-b9ce-5f51089c98e3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "spark.conf.set(\"spark.sql.catalog.cosmosCatalog\", \"com.azure.cosmos.spark.CosmosCatalog\")\n",
    "spark.conf.set(\"spark.sql.catalog.cosmosCatalog.spark.cosmos.accountEndpoint\", cosmosEndpoint)\n",
    "spark.conf.set(\"spark.sql.catalog.cosmosCatalog.spark.cosmos.accountKey\", cosmosMasterKey)\n",
    "spark.conf.set(\"spark.sql.catalog.cosmosCatalog.spark.cosmos.views.repositoryPath\", \"/viewDefinitions\" + str(uuid.uuid4()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4b9e4bd7-cefb-4841-b440-7432eed079d4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Creating a new container to be used for the push down sample and inserting a couple of test records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "008b13f4-7129-4296-8d49-562116408515",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE DATABASE IF NOT EXISTS cosmosCatalog.PushDownSample;\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS cosmosCatalog.PushDownSample.PushDownSample\n",
    "USING cosmos.oltp\n",
    "TBLPROPERTIES(partitionKeyPath = '/id', manualThroughput = '400', indexingPolicy = 'OnlySystemProperties');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d2bc0f0e-0759-4e70-b198-cacc55bcc0b6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Setting up the write config to ingest data into the new container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3a0dbd4a-7362-460e-a8c4-b6807fc374b9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "writeCfg = {\n",
    "  \"spark.cosmos.accountEndpoint\": cosmosEndpoint,\n",
    "  \"spark.cosmos.accountKey\": cosmosMasterKey,\n",
    "  \"spark.cosmos.database\": \"PushDownSample\",\n",
    "  \"spark.cosmos.container\": \"PushDownSample\",\n",
    "  \"spark.cosmos.write.strategy\": \"ItemOverwrite\",\n",
    "}\n",
    "\n",
    "readCfg = {\n",
    "  \"spark.cosmos.accountEndpoint\": cosmosEndpoint,\n",
    "  \"spark.cosmos.accountKey\": cosmosMasterKey,\n",
    "  \"spark.cosmos.database\": \"PushDownSample\",\n",
    "  \"spark.cosmos.container\": \"PushDownSample\",\n",
    "  \"spark.cosmos.read.inferSchema.includeSystemProperties\": \"True\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d8a6e5f2-1ddc-4388-a9a4-d57588155726",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Ingesting some sample data with a 5 seconds delay to ensure different _ts values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "84057c4d-a53f-49a9-a90b-5fc89897da5e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "import time\n",
    "initialRows = [('00001','First Record'),('00002','Second Record')]\n",
    "initialRdd = sc.parallelize(initialRows)\n",
    "initialDF = sqlContext.createDataFrame(initialRdd.map(lambda x: Row(id=x[0], someValue=x[1])))\n",
    "\n",
    "initialDF \\\n",
    "  .write \\\n",
    "  .format(\"cosmos.oltp\") \\\n",
    "  .mode(\"Append\") \\\n",
    "  .options(**writeCfg) \\\n",
    "  .save()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "tsThreshold = int(time.time())\n",
    "nextRows = [('00003','Third Record'),('00004','Fourth Record')]\n",
    "nextRdd = sc.parallelize(nextRows)\n",
    "nextDF = sqlContext.createDataFrame(nextRdd.map(lambda x: Row(id=x[0], someValue=x[1])))\n",
    "\n",
    "nextDF \\\n",
    "  .write \\\n",
    "  .format(\"cosmos.oltp\") \\\n",
    "  .mode(\"Append\") \\\n",
    "  .options(**writeCfg) \\\n",
    "  .save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f6298246-d434-4c95-bf29-bcb9b3c872b3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Get all records to be able to see the _ts values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a5191816-37c9-4ef4-8092-f706c904bb86",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query_df = spark.read.format(\"cosmos.oltp\").options(**readCfg).load()\n",
    "query_df.show()\n",
    "\n",
    "assert query_df.count() == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "dbed53e4-cd53-435f-b798-96ab3ccdcb5f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Show the query plan for the unfiltered query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3436bcac-addf-40c2-9fe1-1adc174d18f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query_df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9f0deaa1-0b46-4a20-a648-c3cd2be99ad5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Get all records with a _ts high enough to filter only some of the records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9e087b88-15ec-4661-b7f2-2ca337a71a89",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "raw_query_df = spark.read.format(\"cosmos.oltp\").options(**readCfg).load()\n",
    "filtered_query_df = raw_query_df.where(\"_ts >= \" + str(tsThreshold))\n",
    "filtered_query_df.show()\n",
    "\n",
    "assert filtered_query_df.count() == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6985be8f-894e-424c-b0de-65643e3640e6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Show the query plan for the filtered query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f83a52d9-3ead-44b1-a18a-c319fa2031e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filtered_query_df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ccd4747a-dfd7-4529-81d8-57d26f8d574f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Cleanup - deleting the Cosmos DB container and database again (to reduce cost) - skip this step if you want to keep them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "42d71c79-f28d-4c27-b22f-de4b99d6c341",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DROP TABLE IF EXISTS cosmosCatalog.PushDownSample.PushDownSample;\n",
    "DROP DATABASE IF EXISTS cosmosCatalog.PushDownSample CASCADE;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Predicate-PushDown-Sample",
   "notebookOrigID": 2792655721962657,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
