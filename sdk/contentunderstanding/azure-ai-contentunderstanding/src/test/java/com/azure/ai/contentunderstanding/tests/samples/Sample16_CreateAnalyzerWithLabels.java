// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) TypeSpec Code Generator.

package com.azure.ai.contentunderstanding.tests.samples;

import com.azure.ai.contentunderstanding.models.AnalyzeInput;
import com.azure.ai.contentunderstanding.models.AnalyzeResult;
import com.azure.ai.contentunderstanding.models.ContentAnalyzer;
import com.azure.ai.contentunderstanding.models.ContentAnalyzerConfig;
import com.azure.ai.contentunderstanding.models.ContentField;
import com.azure.ai.contentunderstanding.models.ContentFieldDefinition;
import com.azure.ai.contentunderstanding.models.ContentFieldSchema;
import com.azure.ai.contentunderstanding.models.ContentFieldType;
import com.azure.ai.contentunderstanding.models.DocumentContent;
import com.azure.ai.contentunderstanding.models.GenerationMethod;
import com.azure.ai.contentunderstanding.models.KnowledgeSource;
import com.azure.ai.contentunderstanding.models.LabeledDataKnowledgeSource;
import com.azure.core.credential.TokenCredential;
import com.azure.core.util.polling.SyncPoller;
import com.azure.identity.DefaultAzureCredentialBuilder;
import com.azure.storage.blob.BlobClient;
import com.azure.storage.blob.BlobContainerClient;
import com.azure.storage.blob.BlobServiceClient;
import com.azure.storage.blob.BlobServiceClientBuilder;
import com.azure.storage.blob.sas.BlobContainerSasPermission;
import com.azure.storage.blob.sas.BlobServiceSasSignatureValues;
import com.azure.storage.blob.models.UserDelegationKey;
import org.junit.jupiter.api.Test;

import com.azure.core.test.TestMode;

import java.io.File;
import java.time.OffsetDateTime;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

import static org.junit.jupiter.api.Assertions.*;

/**
 * Sample demonstrates how to build analyzers with training labels (labeled data from Azure Blob Storage).
 *
 * This sample is mainly to show the API pattern for creating an analyzer with labeled training data.
 * For an easier labeling workflow, use Azure AI Content Understanding Studio at
 * https://contentunderstanding.ai.azure.com/
 *
 * Labeled receipt data is available in this repo at {@code src/samples/resources/receipt_labels}.
 * For LIVE mode with real training data: upload that folder to Azure Blob Storage, generate a
 * container SAS URL with List/Read permissions, then set the environment variables below. Use
 * {@code CONTENTUNDERSTANDING_TRAINING_DATA_PREFIX} if you uploaded into a subfolder
 * (e.g., "receipt_labels/"); omit or leave unset if files are at the container root.
 *
 * <p><b>Required environment variables:</b></p>
 * <ul>
 *   <li>{@code CONTENTUNDERSTANDING_ENDPOINT} – Azure Content Understanding endpoint URL</li>
 * </ul>
 *
 * <p><b>Optional environment variables (for labeled training data; used in LIVE mode):</b></p>
 * <ul>
 *   <li>{@code CONTENTUNDERSTANDING_TRAINING_DATA_SAS_URL} – SAS URL for the Azure Blob container
 *       with labeled training data.</li>
 *   <li>{@code CONTENTUNDERSTANDING_TRAINING_DATA_PREFIX} – Path prefix within the container
 *       (e.g., "receipt_labels/"). Omit or leave unset if files are at the container root.</li>
 *   <li>{@code CONTENTUNDERSTANDING_TRAINING_DATA_STORAGE_ACCOUNT} – Storage account name for
 *       auto-upload (Option B). Used when SAS URL is not set.</li>
 *   <li>{@code CONTENTUNDERSTANDING_TRAINING_DATA_CONTAINER} – Container name for auto-upload
 *       (Option B). Used when SAS URL is not set.</li>
 * </ul>
 */
public class Sample16_CreateAnalyzerWithLabels extends ContentUnderstandingClientTestBase {

    /**
     * Demonstrates creating an analyzer with labeled training data.
     *
     * This test creates an analyzer with field schema. If TRAINING_DATA_SAS_URL is provided,
     * labeled training data will be used; otherwise falls back to auto-upload if storage account
     * and container are configured, or demonstrates the API pattern without actual training data.
     */
    @Test
    public void testCreateAnalyzerWithLabels() {

        String analyzerId = testResourceNamer.randomName("test_receipt_analyzer_", 50);
        // In PLAYBACK mode, use a placeholder URL to ensure consistent test behavior
        String trainingDataSasUrl = getTestMode() == TestMode.PLAYBACK
            ? "https://placeholder.blob.core.windows.net/container?sv=placeholder"
            : System.getenv("CONTENTUNDERSTANDING_TRAINING_DATA_SAS_URL");
        // Save prefix in test proxy variable during RECORD, load back during PLAYBACK so request bodies match.
        String trainingDataPrefix;
        if (getTestMode() == TestMode.PLAYBACK) {
            String recorded = interceptorManager.getProxyVariableSupplier().get();
            trainingDataPrefix = (recorded == null || recorded.isEmpty()) ? null : recorded;
        } else if (getTestMode() == TestMode.RECORD) {
            trainingDataPrefix = System.getenv("CONTENTUNDERSTANDING_TRAINING_DATA_PREFIX");
            interceptorManager.getProxyVariableConsumer().accept(trainingDataPrefix != null ? trainingDataPrefix : "");
        } else {
            trainingDataPrefix = System.getenv("CONTENTUNDERSTANDING_TRAINING_DATA_PREFIX");
        }

        // Option B fallback: upload local label files and generate SAS URL
        if ((trainingDataSasUrl == null || trainingDataSasUrl.trim().isEmpty())
            && getTestMode() != TestMode.PLAYBACK) {
            String storageAccount = System.getenv("CONTENTUNDERSTANDING_TRAINING_DATA_STORAGE_ACCOUNT");
            String container = System.getenv("CONTENTUNDERSTANDING_TRAINING_DATA_CONTAINER");
            if (storageAccount != null && !storageAccount.trim().isEmpty()
                && container != null && !container.trim().isEmpty()) {
                TokenCredential credential = new DefaultAzureCredentialBuilder().build();
                String localDir = new File("src/samples/resources/receipt_labels").getAbsolutePath();
                uploadTrainingData(storageAccount, container, credential, localDir, trainingDataPrefix);
                trainingDataSasUrl = generateUserDelegationSasUrl(storageAccount, container, credential);
            }
        }

        try {
            // BEGIN: com.azure.ai.contentunderstanding.createAnalyzerWithLabels
            // Step 1: Define field schema for receipt extraction
            Map<String, ContentFieldDefinition> fields = new HashMap<>();

            // MerchantName field
            ContentFieldDefinition merchantNameField = new ContentFieldDefinition();
            merchantNameField.setType(ContentFieldType.STRING);
            merchantNameField.setMethod(GenerationMethod.EXTRACT);
            merchantNameField.setDescription("Name of the merchant");
            fields.put("MerchantName", merchantNameField);

            // Items array field - define item structure
            ContentFieldDefinition itemDefinition = new ContentFieldDefinition();
            itemDefinition.setType(ContentFieldType.OBJECT);
            itemDefinition.setMethod(GenerationMethod.EXTRACT);
            itemDefinition.setDescription("Individual item details");

            Map<String, ContentFieldDefinition> itemProperties = new HashMap<>();

            ContentFieldDefinition quantityField = new ContentFieldDefinition();
            quantityField.setType(ContentFieldType.STRING);
            quantityField.setMethod(GenerationMethod.EXTRACT);
            quantityField.setDescription("Quantity of the item");
            itemProperties.put("Quantity", quantityField);

            ContentFieldDefinition nameField = new ContentFieldDefinition();
            nameField.setType(ContentFieldType.STRING);
            nameField.setMethod(GenerationMethod.EXTRACT);
            nameField.setDescription("Name of the item");
            itemProperties.put("Name", nameField);

            ContentFieldDefinition priceField = new ContentFieldDefinition();
            priceField.setType(ContentFieldType.STRING);
            priceField.setMethod(GenerationMethod.EXTRACT);
            priceField.setDescription("Price of the item");
            itemProperties.put("Price", priceField);

            itemDefinition.setProperties(itemProperties);

            // Items array field
            ContentFieldDefinition itemsField = new ContentFieldDefinition();
            itemsField.setType(ContentFieldType.ARRAY);
            itemsField.setMethod(GenerationMethod.GENERATE);
            itemsField.setDescription("List of items purchased");
            itemsField.setItemDefinition(itemDefinition);
            fields.put("Items", itemsField);

            // TotalPrice field
            ContentFieldDefinition totalPriceField = new ContentFieldDefinition();
            totalPriceField.setType(ContentFieldType.STRING);
            totalPriceField.setMethod(GenerationMethod.EXTRACT);
            totalPriceField.setDescription("Total amount");
            fields.put("TotalPrice", totalPriceField);

            ContentFieldSchema fieldSchema = new ContentFieldSchema();
            fieldSchema.setName("receipt_schema");
            fieldSchema.setDescription("Schema for receipt extraction with items");
            fieldSchema.setFields(fields);

            // Step 2: Create labeled data knowledge source (optional, based on environment variable)
            List<KnowledgeSource> knowledgeSources = new ArrayList<>();
            if (trainingDataSasUrl != null && !trainingDataSasUrl.trim().isEmpty()) {
                LabeledDataKnowledgeSource knowledgeSource
                    = new LabeledDataKnowledgeSource().setContainerUrl(trainingDataSasUrl);
                if (trainingDataPrefix != null && !trainingDataPrefix.trim().isEmpty()) {
                    knowledgeSource.setPrefix(trainingDataPrefix);
                }
                knowledgeSources.add(knowledgeSource);
                System.out.println("Using labeled training data from: "
                    + trainingDataSasUrl.substring(0, Math.min(50, trainingDataSasUrl.length())) + "...");
            } else {
                System.out.println("No TRAINING_DATA_SAS_URL set, creating analyzer without labeled training data");
            }

            // Step 3: Create analyzer (with or without labeled data)
            Map<String, String> models = new HashMap<>();
            models.put("completion", "gpt-4.1");
            models.put("embedding", "text-embedding-3-large");

            ContentAnalyzer analyzer = new ContentAnalyzer().setBaseAnalyzerId("prebuilt-document")
                .setDescription("Receipt analyzer with labeled training data")
                .setConfig(new ContentAnalyzerConfig().setEnableLayout(true).setEnableOcr(true))
                .setFieldSchema(fieldSchema)
                .setModels(models);

            if (!knowledgeSources.isEmpty()) {
                analyzer.setKnowledgeSources(knowledgeSources);
            }

            SyncPoller<com.azure.ai.contentunderstanding.models.ContentAnalyzerOperationStatus, ContentAnalyzer> createPoller
                = contentUnderstandingClient.beginCreateAnalyzer(analyzerId, analyzer, true);
            ContentAnalyzer result = createPoller.getFinalResult();

            System.out.println("Analyzer created: " + analyzerId);
            System.out.println("  Description: " + result.getDescription());
            System.out.println("  Base analyzer: " + result.getBaseAnalyzerId());
            System.out.println("  Fields: " + result.getFieldSchema().getFields().size());
            System.out.println("  Knowledge srcs: " + (result.getKnowledgeSources() != null ? result.getKnowledgeSources().size() : 0));
            // END: com.azure.ai.contentunderstanding.createAnalyzerWithLabels

            // BEGIN: Assertion_ContentUnderstandingCreateAnalyzerWithLabels
            // Verify analyzer creation
            System.out.println("\nAnalyzer Creation Verification:");
            assertNotNull(result, "Analyzer should not be null");
            assertEquals("prebuilt-document", result.getBaseAnalyzerId());
            assertEquals("Receipt analyzer with labeled training data", result.getDescription());
            assertNotNull(result.getFieldSchema());
            assertEquals("receipt_schema", result.getFieldSchema().getName());
            assertEquals(3, result.getFieldSchema().getFields().size());
            System.out.println("Analyzer created successfully");

            // Verify field schema
            Map<String, ContentFieldDefinition> resultFields = result.getFieldSchema().getFields();
            assertTrue(resultFields.containsKey("MerchantName"), "Should have MerchantName field");
            assertTrue(resultFields.containsKey("Items"), "Should have Items field");
            assertTrue(resultFields.containsKey("TotalPrice"), "Should have TotalPrice field");

            ContentFieldDefinition itemsFieldResult = resultFields.get("Items");
            assertEquals(ContentFieldType.ARRAY, itemsFieldResult.getType());
            assertNotNull(itemsFieldResult.getItemDefinition());
            assertEquals(ContentFieldType.OBJECT, itemsFieldResult.getItemDefinition().getType());
            assertEquals(3, itemsFieldResult.getItemDefinition().getProperties().size());
            System.out.println("Field schema verified:");
            System.out.println("  MerchantName: String (Extract)");
            System.out.println("  Items: Array of Objects (Generate)");
            System.out.println("    - Quantity, Name, Price");
            System.out.println("  TotalPrice: String (Extract)");
            // END: Assertion_ContentUnderstandingCreateAnalyzerWithLabels

            // If training data was provided, test the analyzer with a sample document
            if (trainingDataSasUrl != null && !trainingDataSasUrl.trim().isEmpty()) {
                System.out.println("\nTesting analyzer with sample document...");
                String testDocUrl
                    = "https://github.com/Azure-Samples/cognitive-services-REST-api-samples/raw/master/curl/form-recognizer/sample-invoice.pdf";

                AnalyzeInput input = new AnalyzeInput();
                input.setUrl(testDocUrl);

                AnalyzeResult analyzeResult
                    = contentUnderstandingClient.beginAnalyze(analyzerId, Arrays.asList(input)).getFinalResult();

                System.out.println("Analysis completed!");
                assertNotNull(analyzeResult);
                assertNotNull(analyzeResult.getContents());
                assertTrue(analyzeResult.getContents().size() > 0);

                if (analyzeResult.getContents().get(0) instanceof DocumentContent) {
                    DocumentContent docContent = (DocumentContent) analyzeResult.getContents().get(0);
                    System.out.println("Extracted fields: " + docContent.getFields().size());

                    // Display extracted values
                    if (docContent.getFields().containsKey("MerchantName")) {
                        ContentField merchantField = docContent.getFields().get("MerchantName");
                        if (merchantField != null) {
                            String merchantName = (String) merchantField.getValue();
                            System.out.println("  MerchantName: " + merchantName);
                        }
                    }
                    if (docContent.getFields().containsKey("TotalPrice")) {
                        ContentField totalPriceFieldValue = docContent.getFields().get("TotalPrice");
                        if (totalPriceFieldValue != null) {
                            String totalPrice = (String) totalPriceFieldValue.getValue();
                            System.out.println("  TotalPrice: " + totalPrice);
                        }
                    }
                }
            }

            // Display API pattern information
            System.out.println("\nCreateAnalyzerWithLabels API Pattern:");
            System.out.println("   1. Define field schema with nested structures (arrays, objects)");
            System.out.println("   2. Upload training data to Azure Blob Storage:");
            System.out.println("      - Documents: receipt1.jpg, receipt2.jpg, ...");
            System.out.println("      - Labels: receipt1.jpg.labels.json, receipt2.jpg.labels.json, ...");
            System.out.println("      - OCR: receipt1.jpg.result.json, receipt2.jpg.result.json, ...");
            System.out.println("   3. Create LabeledDataKnowledgeSource with storage SAS URL");
            System.out.println("   4. Create analyzer with field schema and knowledge sources");
            System.out.println("   5. Use analyzer for document analysis");

            System.out.println("\nCreateAnalyzerWithLabels pattern demonstration completed");
            if (trainingDataSasUrl == null || trainingDataSasUrl.trim().isEmpty()) {
                System.out.println("   Note: This sample demonstrates the API pattern.");
                System.out.println(
                    "   For actual training, provide CONTENTUNDERSTANDING_TRAINING_DATA_SAS_URL with labeled data.");
            }

        } finally {
            // Cleanup
            try {
                contentUnderstandingClient.deleteAnalyzer(analyzerId);
                System.out.println("\nAnalyzer deleted: " + analyzerId);
            } catch (Exception e) {
                System.out.println("Note: Failed to delete analyzer: " + e.getMessage());
            }
        }
    }

    /**
     * Uploads local training data files (images, .labels.json, .result.json) to an
     * Azure Blob container. Existing blobs with the same name are overwritten.
     *
     * @param storageAccountName Storage account name.
     * @param containerName      Container name (created if it does not exist).
     * @param credential         Credential with write access to the container.
     * @param localDirectory     Local folder containing the label files.
     * @param prefix             Optional blob prefix (virtual folder) to prepend, e.g. "receipt_labels/".
     */
    private static void uploadTrainingData(String storageAccountName, String containerName,
        TokenCredential credential, String localDirectory, String prefix) {
        BlobContainerClient containerClient = new BlobServiceClientBuilder()
            .endpoint("https://" + storageAccountName + ".blob.core.windows.net")
            .credential(credential)
            .buildClient()
            .getBlobContainerClient(containerName);

        containerClient.createIfNotExists();

        File dir = new File(localDirectory);
        File[] files = dir.listFiles();
        if (files == null) {
            return;
        }
        for (File file : files) {
            if (!file.isFile()) {
                continue;
            }
            String blobName = (prefix == null || prefix.trim().isEmpty())
                ? file.getName()
                : prefix.replaceAll("/+$", "") + "/" + file.getName();

            System.out.println("Uploading " + file.getName() + " -> " + blobName);
            BlobClient blobClient = containerClient.getBlobClient(blobName);
            blobClient.uploadFromFile(file.getAbsolutePath(), true);
        }
    }

    /**
     * Generates a User Delegation SAS URL (Read + List) for an Azure Blob container.
     * Uses {@link TokenCredential} so no storage account key is needed.
     *
     * @param storageAccountName Storage account name.
     * @param containerName      Container name.
     * @param credential         Credential with permissions to generate user delegation key.
     * @return SAS URL for the container.
     */
    private static String generateUserDelegationSasUrl(String storageAccountName, String containerName,
        TokenCredential credential) {
        BlobServiceClient blobServiceClient = new BlobServiceClientBuilder()
            .endpoint("https://" + storageAccountName + ".blob.core.windows.net")
            .credential(credential)
            .buildClient();

        UserDelegationKey userDelegationKey = blobServiceClient.getUserDelegationKey(
            OffsetDateTime.now(), OffsetDateTime.now().plusHours(1));

        BlobContainerSasPermission permissions = new BlobContainerSasPermission()
            .setReadPermission(true)
            .setListPermission(true);

        BlobServiceSasSignatureValues sasValues = new BlobServiceSasSignatureValues(
            OffsetDateTime.now().plusHours(1), permissions);

        String sasToken = blobServiceClient.getBlobContainerClient(containerName)
            .generateUserDelegationSas(sasValues, userDelegationKey);

        return "https://" + storageAccountName + ".blob.core.windows.net/" + containerName + "?" + sasToken;
    }
}
