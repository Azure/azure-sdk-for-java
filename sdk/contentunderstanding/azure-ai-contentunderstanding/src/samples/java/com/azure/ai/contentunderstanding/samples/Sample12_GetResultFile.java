// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) TypeSpec Code Generator.

package com.azure.ai.contentunderstanding.samples;

import com.azure.ai.contentunderstanding.ContentUnderstandingClient;
import com.azure.ai.contentunderstanding.ContentUnderstandingClientBuilder;
import com.azure.ai.contentunderstanding.models.AnalyzeInput;
import com.azure.ai.contentunderstanding.models.AnalyzeResult;
import com.azure.ai.contentunderstanding.models.AudioVisualContent;
import com.azure.core.credential.AzureKeyCredential;
import com.azure.core.http.rest.Response;
import com.azure.core.util.BinaryData;
import com.azure.core.util.polling.SyncPoller;
import com.azure.identity.DefaultAzureCredentialBuilder;

import java.io.IOException;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.util.Collections;
import java.util.List;

/**
 * Sample demonstrates how to retrieve result files (like keyframe images) from video analysis operations.
 */
public class Sample12_GetResultFile {

    public static void main(String[] args) throws IOException {
        // BEGIN: com.azure.ai.contentunderstanding.sample12.buildClient
        String endpoint = System.getenv("CONTENTUNDERSTANDING_ENDPOINT");
        String key = System.getenv("AZURE_CONTENT_UNDERSTANDING_KEY");

        // Build the client with appropriate authentication
        ContentUnderstandingClientBuilder builder = new ContentUnderstandingClientBuilder().endpoint(endpoint);

        ContentUnderstandingClient client;
        if (key != null && !key.trim().isEmpty()) {
            // Use API key authentication
            client = builder.credential(new AzureKeyCredential(key)).buildClient();
        } else {
            // Use default Azure credential (for managed identity, Azure CLI, etc.)
            client = builder.credential(new DefaultAzureCredentialBuilder().build()).buildClient();
        }
        // END: com.azure.ai.contentunderstanding.sample12.buildClient

        System.out.println("Client initialized successfully");

        // BEGIN: com.azure.ai.contentunderstanding.getResultFile
        // For video analysis, use a video URL to get keyframes
        String videoUrl
            = "https://github.com/Azure-Samples/azure-ai-content-understanding-assets/raw/refs/heads/main/videos/sdk_samples/FlightSimulator.mp4";

        // Step 1: Start the video analysis operation
        AnalyzeInput input = new AnalyzeInput();
        input.setUrl(videoUrl);

        SyncPoller<com.azure.ai.contentunderstanding.models.ContentAnalyzerAnalyzeOperationStatus, AnalyzeResult> poller
            = client.beginAnalyze("prebuilt-videoSearch", null, null, Collections.singletonList(input), null);

        // Get the operation ID from the poller
        String operationId = poller.poll().getStatus().toString();
        System.out.println("Started analysis operation");

        // Wait for completion
        AnalyzeResult result = poller.getFinalResult();
        System.out.println("Analysis completed successfully!");

        // END: com.azure.ai.contentunderstanding.getResultFile

        System.out.println("Video URL: " + videoUrl);
        System.out.println("Operation ID obtained: " + operationId);
        System.out.println("  Length: " + operationId.length() + " characters");
        System.out.println("Analysis result contains " + result.getContents().size() + " content(s)");

        // BEGIN: com.azure.ai.contentunderstanding.getResultFile.keyframes
        // Step 2: Get keyframes from video analysis result
        AudioVisualContent videoContent = null;
        for (Object content : result.getContents()) {
            if (content instanceof AudioVisualContent) {
                videoContent = (AudioVisualContent) content;
                break;
            }
        }

        if (videoContent != null
            && videoContent.getKeyFrameTimesMs() != null
            && !videoContent.getKeyFrameTimesMs().isEmpty()) {
            List<Long> keyFrameTimes = videoContent.getKeyFrameTimesMs();
            System.out.println("Total keyframes: " + keyFrameTimes.size());

            // Get the first keyframe
            long firstFrameTimeMs = keyFrameTimes.get(0);
            System.out.println("First keyframe time: " + firstFrameTimeMs + " ms");

            // Construct the keyframe path
            String framePath = "keyframes/" + firstFrameTimeMs;
            System.out.println("Getting result file: " + framePath);

            // Retrieve the keyframe image
            Response<BinaryData> fileResponse = client.getResultFileWithResponse(operationId, framePath, null);
            byte[] imageBytes = fileResponse.getValue().toBytes();
            System.out.println("Retrieved keyframe image (" + String.format("%,d", imageBytes.length) + " bytes)");

            // Save the keyframe image
            Path outputDir = Paths.get("target", "sample_output");
            Files.createDirectories(outputDir);
            String outputFileName = "keyframe_" + firstFrameTimeMs + ".jpg";
            Path outputPath = outputDir.resolve(outputFileName);
            Files.write(outputPath, imageBytes);

            System.out.println("Keyframe image saved to: " + outputPath.toAbsolutePath());
            // END: com.azure.ai.contentunderstanding.getResultFile.keyframes

            System.out.println("\nðŸŽ¬ Keyframe Information:");
            System.out.println("Total keyframes: " + keyFrameTimes.size());

            // Get keyframe statistics
            long lastFrameTimeMs = keyFrameTimes.get(keyFrameTimes.size() - 1);
            double avgFrameInterval = keyFrameTimes.size() > 1
                ? (double) (lastFrameTimeMs - firstFrameTimeMs) / (keyFrameTimes.size() - 1)
                : 0;

            System.out.println("  First keyframe: " + firstFrameTimeMs + " ms ("
                + String.format("%.2f", firstFrameTimeMs / 1000.0) + " seconds)");
            System.out.println("  Last keyframe: " + lastFrameTimeMs + " ms ("
                + String.format("%.2f", lastFrameTimeMs / 1000.0) + " seconds)");
            if (keyFrameTimes.size() > 1) {
                System.out.println("  Average interval: " + String.format("%.2f", avgFrameInterval) + " ms");
            }

            System.out.println("\nðŸ“¥ File Response Verification:");
            System.out.println("File response status: " + fileResponse.getStatusCode());

            System.out.println("\nVerifying image data...");
            System.out.println("Image size: " + String.format("%,d", imageBytes.length) + " bytes ("
                + String.format("%.2f", imageBytes.length / 1024.0) + " KB)");

            // Verify image format
            String imageFormat = detectImageFormat(imageBytes);
            System.out.println("Detected image format: " + imageFormat);

            System.out.println("\nðŸ’¾ Saved File Verification:");
            long fileSize = Files.size(outputPath);
            System.out.println("File saved: " + outputPath.toAbsolutePath());
            System.out.println("File size verified: " + String.format("%,d", fileSize) + " bytes");

            // Verify file can be read back
            byte[] readBackBytes = Files.readAllBytes(outputPath);
            System.out.println("File content verified (read back matches original)");

            // Test additional keyframes if available
            if (keyFrameTimes.size() > 1) {
                System.out
                    .println("\nTesting additional keyframes (" + (keyFrameTimes.size() - 1) + " more available)...");
                int middleIndex = keyFrameTimes.size() / 2;
                long middleFrameTimeMs = keyFrameTimes.get(middleIndex);
                String middleFramePath = "keyframes/" + middleFrameTimeMs;

                Response<BinaryData> middleFileResponse
                    = client.getResultFileWithResponse(operationId, middleFramePath, null);
                System.out.println(
                    "Successfully retrieved keyframe at index " + middleIndex + " (" + middleFrameTimeMs + " ms)");
                System.out.println(
                    "  Size: " + String.format("%,d", middleFileResponse.getValue().toBytes().length) + " bytes");
            }

            // Summary
            System.out.println("\nâœ… Keyframe retrieval verification completed successfully:");
            System.out.println("  Operation ID: " + operationId);
            System.out.println("  Total keyframes: " + keyFrameTimes.size());
            System.out.println("  First keyframe time: " + firstFrameTimeMs + " ms");
            System.out.println("  Image format: " + imageFormat);
            System.out.println("  Image size: " + String.format("%,d", imageBytes.length) + " bytes");
            System.out.println("  Saved to: " + outputPath.toAbsolutePath());
            System.out.println("  File verified: Yes");
        } else {
            // No video content (expected for document analysis)
            System.out.println("\nðŸ“š GetResultFile API Usage Example:");
            System.out.println("   For video analysis with keyframes:");
            System.out.println("   1. Analyze video with prebuilt-videoSearch");
            System.out.println("   2. Get keyframe times from AudioVisualContent.getKeyFrameTimesMs()");
            System.out.println("   3. Retrieve keyframes using getResultFileWithResponse():");
            System.out.println("      Response<BinaryData> response = client.getResultFileWithResponse(\"" + operationId
                + "\", \"keyframes/1000\", null);");
            System.out.println("   4. Save or process the keyframe image");

            System.out.println("Operation ID available for GetResultFile API: " + operationId);
        }
    }

    /**
     * Detect image format from magic bytes.
     */
    private static String detectImageFormat(byte[] imageBytes) {
        if (imageBytes.length < 2) {
            return "Unknown";
        }

        // Check JPEG magic bytes (FF D8)
        if (imageBytes[0] == (byte) 0xFF && imageBytes[1] == (byte) 0xD8) {
            return "JPEG";
        }

        // Check PNG magic bytes (89 50 4E 47)
        if (imageBytes.length >= 4
            && imageBytes[0] == (byte) 0x89
            && imageBytes[1] == 0x50
            && imageBytes[2] == 0x4E
            && imageBytes[3] == 0x47) {
            return "PNG";
        }

        // Check GIF magic bytes (47 49 46)
        if (imageBytes.length >= 3 && imageBytes[0] == 0x47 && imageBytes[1] == 0x49 && imageBytes[2] == 0x46) {
            return "GIF";
        }

        // Check WebP magic bytes (52 49 46 46 ... 57 45 42 50)
        if (imageBytes.length >= 12
            && imageBytes[0] == 0x52
            && imageBytes[1] == 0x49
            && imageBytes[8] == 0x57
            && imageBytes[9] == 0x45
            && imageBytes[10] == 0x42
            && imageBytes[11] == 0x50) {
            return "WebP";
        }

        return "Unknown";
    }
}
