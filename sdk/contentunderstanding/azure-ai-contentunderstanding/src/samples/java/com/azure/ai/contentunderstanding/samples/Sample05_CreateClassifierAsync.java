// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) TypeSpec Code Generator.

package com.azure.ai.contentunderstanding.samples;

import com.azure.ai.contentunderstanding.ContentUnderstandingAsyncClient;
import com.azure.ai.contentunderstanding.ContentUnderstandingClientBuilder;
import com.azure.ai.contentunderstanding.models.ContentAnalyzer;
import com.azure.ai.contentunderstanding.models.ContentAnalyzerConfig;
import com.azure.ai.contentunderstanding.models.ContentAnalyzerOperationStatus;
import com.azure.ai.contentunderstanding.models.ContentCategoryDefinition;
import com.azure.core.credential.AzureKeyCredential;
import com.azure.core.util.polling.PollerFlux;
import com.azure.identity.DefaultAzureCredentialBuilder;
import reactor.core.publisher.Mono;

import java.util.HashMap;
import java.util.Map;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;

/**
 * Sample demonstrating how to create a classifier analyzer.
 *
 * This sample shows how to create a classifier that categorizes documents into predefined
 * custom categories using ContentCategories. Classifiers are useful for:
 * - Content organization: Organize large document collections by type through categorization
 * - Data routing (optional): Route data to specific custom analyzers based on category
 * - Multi-document processing: Process files containing multiple document types by automatically
 *   segmenting them
 *
 * Classifiers use custom categories defined in ContentCategories. Each category has a Description
 * that helps the AI model understand what documents belong to that category. You can define up to
 * 200 category names and descriptions. You can include an "other" category to handle unmatched
 * content; otherwise, all files are forced to be classified into one of your defined categories.
 *
 * The EnableSegment property in the analyzer configuration controls whether multi-document files
 * are split into segments:
 * - EnableSegment = false: Classifies the entire file as a single category (classify only)
 * - EnableSegment = true: Automatically splits the file into segments by category (classify and segment)
 */
public class Sample05_CreateClassifierAsync {

    private static String createdAnalyzerId;

    public static void main(String[] args) throws InterruptedException {
        // BEGIN: com.azure.ai.contentunderstanding.sample05Async.buildClient
        String endpoint = System.getenv("CONTENTUNDERSTANDING_ENDPOINT");
        String key = System.getenv("CONTENTUNDERSTANDING_KEY");

        // Build the client with appropriate authentication
        ContentUnderstandingClientBuilder builder = new ContentUnderstandingClientBuilder().endpoint(endpoint);

        ContentUnderstandingAsyncClient client;
        if (key != null && !key.trim().isEmpty()) {
            // Use API key authentication
            client = builder.credential(new AzureKeyCredential(key)).buildAsyncClient();
        } else {
            // Use default Azure credential (for managed identity, Azure CLI, etc.)
            client = builder.credential(new DefaultAzureCredentialBuilder().build()).buildAsyncClient();
        }
        // END: com.azure.ai.contentunderstanding.sample05Async.buildClient

        // BEGIN:ContentUnderstandingCreateClassifierAsync
        // Generate a unique classifier analyzer ID
        String analyzerId = "document_classifier_" + System.currentTimeMillis();

        System.out.println("Creating classifier analyzer '" + analyzerId + "'...");

        // Define content categories for classification
        // Each category has a description that helps the AI model understand what documents belong to it
        Map<String, ContentCategoryDefinition> categories = new HashMap<>();

        categories.put("Loan_Application", new ContentCategoryDefinition()
            .setDescription("Documents submitted by individuals or businesses to request funding, "
                + "typically including personal or business details, financial history, loan amount, "
                + "purpose, and supporting documentation."));

        categories.put("Invoice", new ContentCategoryDefinition()
            .setDescription("Billing documents issued by sellers or service providers to request payment "
                + "for goods or services, detailing items, prices, taxes, totals, and payment terms."));

        categories.put("Bank_Statement", new ContentCategoryDefinition()
            .setDescription("Official statements issued by banks that summarize account activity over a period, "
                + "including deposits, withdrawals, fees, and balances."));

        // Create analyzer configuration with content categories
        ContentAnalyzerConfig config = new ContentAnalyzerConfig()
            .setReturnDetails(true)
            .setEnableSegment(true) // Enable automatic segmentation by category
            .setContentCategories(categories);

        // Create the classifier analyzer
        // Note: models are specified using model names, not deployment names
        Map<String, String> models = new HashMap<>();
        models.put("completion", "gpt-4.1");

        ContentAnalyzer classifier = new ContentAnalyzer()
            .setBaseAnalyzerId("prebuilt-document")
            .setDescription("Custom classifier for financial document categorization")
            .setConfig(config)
            .setModels(models);

        // Create the classifier
        PollerFlux<ContentAnalyzerOperationStatus, ContentAnalyzer> operation
            = client.beginCreateAnalyzer(analyzerId, classifier, true);

        String finalAnalyzerId = analyzerId; // For use in lambda

        CountDownLatch latch = new CountDownLatch(1);

        operation.last()
            .flatMap(pollResponse -> {
                if (pollResponse.getStatus().isComplete()) {
                    System.out.println("Polling completed successfully");
                    return pollResponse.getFinalResult();
                } else {
                    return Mono.error(new RuntimeException(
                        "Polling completed unsuccessfully with status: " + pollResponse.getStatus()));
                }
            })
            .doOnNext(result -> {
                System.out.println("Classifier '" + finalAnalyzerId + "' created successfully!");

                if (result.getDescription() != null && !result.getDescription().trim().isEmpty()) {
                    System.out.println("  Description: " + result.getDescription());
                }

                if (result.getConfig() != null && result.getConfig().getContentCategories() != null) {
                    System.out.println("  Categories (" + result.getConfig().getContentCategories().size() + "):");
                    result.getConfig().getContentCategories().forEach((categoryName, categoryDef) -> {
                        System.out.println("    - " + categoryName);
                        if (categoryDef.getDescription() != null) {
                            // Truncate long descriptions for display
                            String desc = categoryDef.getDescription();
                            if (desc.length() > 60) {
                                desc = desc.substring(0, 57) + "...";
                            }
                            System.out.println("      Description: " + desc);
                        }
                    });
                }

                if (result.getConfig() != null && result.getConfig().isEnableSegment() != null) {
                    System.out.println("  Segmentation enabled: " + result.getConfig().isEnableSegment());
                }
            })
            .then(Mono.fromRunnable(() -> {
                // Cleanup - delete the created classifier analyzer
                System.out.println("\nCleaning up: deleting classifier analyzer '" + finalAnalyzerId + "'...");
            }))
            .then(client.deleteAnalyzer(finalAnalyzerId))
            .doOnSuccess(v -> {
                System.out.println("Classifier analyzer '" + finalAnalyzerId + "' deleted successfully.");
            })
            .doOnError(error -> {
                System.err.println("Error occurred: " + error.getMessage());
                error.printStackTrace();
            })
            .subscribe(
                result -> {
                    // Success - operations completed
                    latch.countDown();
                },
                error -> {
                    // Error already handled in doOnError
                    latch.countDown();
                }
            );
        // END:ContentUnderstandingCreateClassifierAsync

        // The .subscribe() creation is not a blocking call. For the purpose of this example,
        // we use a CountDownLatch so the program does not end before the async operations complete.
        if (!latch.await(2, TimeUnit.MINUTES)) {
            System.err.println("Timed out waiting for async operations to complete.");
        }
    }
}
