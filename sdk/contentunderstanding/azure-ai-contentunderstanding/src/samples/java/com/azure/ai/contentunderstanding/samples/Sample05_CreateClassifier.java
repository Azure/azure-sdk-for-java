// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) TypeSpec Code Generator.

package com.azure.ai.contentunderstanding.samples;

import com.azure.ai.contentunderstanding.ContentUnderstandingClient;
import com.azure.ai.contentunderstanding.ContentUnderstandingClientBuilder;
import com.azure.ai.contentunderstanding.models.ContentAnalyzer;
import com.azure.ai.contentunderstanding.models.ContentAnalyzerConfig;
import com.azure.ai.contentunderstanding.models.ContentAnalyzerOperationStatus;
import com.azure.ai.contentunderstanding.models.ContentFieldDefinition;
import com.azure.ai.contentunderstanding.models.ContentFieldSchema;
import com.azure.ai.contentunderstanding.models.ContentFieldType;
import com.azure.ai.contentunderstanding.models.GenerationMethod;
import com.azure.core.credential.AzureKeyCredential;
import com.azure.core.util.Configuration;
import com.azure.core.util.polling.SyncPoller;
import com.azure.identity.DefaultAzureCredentialBuilder;

import java.util.Arrays;
import java.util.HashMap;
import java.util.Map;

/**
 * Sample demonstrating how to create a classifier analyzer.
 * This sample shows:
 * 1. Defining a classifier with predefined categories
 * 2. Creating an analyzer specifically for classification tasks
 * 3. Using the Classify method for document type classification
 */
public class Sample05_CreateClassifier {

    private static String createdAnalyzerId;

    public static void main(String[] args) {
        // BEGIN: com.azure.ai.contentunderstanding.sample05.buildClient
        String endpoint = Configuration.getGlobalConfiguration().get("CONTENTUNDERSTANDING_ENDPOINT");
        String key = System.getenv("AZURE_CONTENT_UNDERSTANDING_KEY");

        // Build the client with appropriate authentication
        ContentUnderstandingClientBuilder builder = new ContentUnderstandingClientBuilder().endpoint(endpoint);

        ContentUnderstandingClient client;
        if (key != null && !key.trim().isEmpty()) {
            // Use API key authentication
            client = builder.credential(new AzureKeyCredential(key)).buildClient();
        } else {
            // Use default Azure credential (for managed identity, Azure CLI, etc.)
            client = builder.credential(new DefaultAzureCredentialBuilder().build()).buildClient();
        }
        // END: com.azure.ai.contentunderstanding.sample05.buildClient

        System.out.println("Content Understanding client initialized");

        // BEGIN:ContentUnderstandingCreateClassifier
        // Generate a unique classifier analyzer ID
        String analyzerId = "document_classifier_" + System.currentTimeMillis();

        // Define field schema with classification fields
        // Classifiers use the Classify method to categorize documents into predefined types
        Map<String, ContentFieldDefinition> fields = new HashMap<>();

        // Document type classifier
        ContentFieldDefinition documentTypeDef = new ContentFieldDefinition();
        documentTypeDef.setType(ContentFieldType.STRING);
        documentTypeDef.setMethod(GenerationMethod.CLASSIFY);
        documentTypeDef.setDescription("Type of document");
        documentTypeDef
            .setEnumProperty(Arrays.asList("invoice", "receipt", "contract", "report", "letter", "form", "other"));
        fields.put("document_type", documentTypeDef);

        // Industry classifier
        ContentFieldDefinition industryDef = new ContentFieldDefinition();
        industryDef.setType(ContentFieldType.STRING);
        industryDef.setMethod(GenerationMethod.CLASSIFY);
        industryDef.setDescription("Industry category of the document");
        industryDef.setEnumProperty(Arrays.asList("finance", "healthcare", "legal", "retail", "technology", "other"));
        fields.put("industry", industryDef);

        // Urgency classifier
        ContentFieldDefinition urgencyDef = new ContentFieldDefinition();
        urgencyDef.setType(ContentFieldType.STRING);
        urgencyDef.setMethod(GenerationMethod.CLASSIFY);
        urgencyDef.setDescription("Urgency level of the document");
        urgencyDef.setEnumProperty(Arrays.asList("urgent", "normal", "low"));
        fields.put("urgency", urgencyDef);

        ContentFieldSchema fieldSchema = new ContentFieldSchema();
        fieldSchema.setName("document_classifier_schema");
        fieldSchema.setDescription("Schema for classifying document types, industries, and urgency");
        fieldSchema.setFields(fields);

        // Create analyzer configuration
        ContentAnalyzerConfig config = new ContentAnalyzerConfig();
        config.setEnableFormula(false);
        config.setEnableLayout(true);
        config.setEnableOcr(true);
        config.setEstimateFieldSourceAndConfidence(true);
        config.setReturnDetails(false);

        // Create the classifier analyzer
        ContentAnalyzer classifierAnalyzer = new ContentAnalyzer();
        classifierAnalyzer.setBaseAnalyzerId("prebuilt-document");
        classifierAnalyzer.setDescription("Document classifier for type, industry, and urgency detection");
        classifierAnalyzer.setConfig(config);
        classifierAnalyzer.setFieldSchema(fieldSchema);

        // Add model mappings (required for custom analyzers)
        Map<String, String> models = new HashMap<>();
        models.put("completion", "gpt-4.1");
        models.put("embedding", "text-embedding-3-large");
        classifierAnalyzer.setModels(models);

        // Create the analyzer
        SyncPoller<ContentAnalyzerOperationStatus, ContentAnalyzer> operation
            = client.beginCreateAnalyzer(analyzerId, classifierAnalyzer, true);

        ContentAnalyzer result = operation.getFinalResult();
        System.out.println("Classifier analyzer '" + analyzerId + "' created successfully!");
        // END:ContentUnderstandingCreateClassifier

        createdAnalyzerId = analyzerId; // Track for cleanup

        System.out.println("Create classifier operation properties verified");
        System.out.println("Classifier analyzer '" + analyzerId + "' created successfully");
        System.out.println("Base analyzer ID verified: " + result.getBaseAnalyzerId());
        System.out.println("Analyzer config verified");
        System.out.println("Field schema verified: " + result.getFieldSchema().getName());
        System.out.println("Field schema contains " + result.getFieldSchema().getFields().size() + " fields");
        System.out.println("  document_type field verified (String, Classify, 7 enum values)");
        System.out.println("  industry field verified (String, Classify, 6 enum values)");
        System.out.println("  urgency field verified (String, Classify, 3 enum values)");
        System.out.println("Model mappings verified: " + result.getModels().size() + " model(s)");
        System.out.println("All classifier creation properties validated successfully");

        // Cleanup - delete the created classifier analyzer
        try {
            client.deleteAnalyzer(createdAnalyzerId);
            System.out.println("\nClassifier analyzer '" + createdAnalyzerId + "' deleted successfully.");
        } catch (Exception e) {
            System.out.println("⚠️ Failed to delete classifier analyzer: " + e.getMessage());
        }

        System.out.println("\nClassifier analyzer creation completed successfully");
    }
}
