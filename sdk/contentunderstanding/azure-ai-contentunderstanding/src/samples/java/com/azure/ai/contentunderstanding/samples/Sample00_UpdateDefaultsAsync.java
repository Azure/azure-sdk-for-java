// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) TypeSpec Code Generator.

package com.azure.ai.contentunderstanding.samples;

import com.azure.ai.contentunderstanding.ContentUnderstandingAsyncClient;
import com.azure.ai.contentunderstanding.ContentUnderstandingClientBuilder;
import com.azure.ai.contentunderstanding.models.ContentUnderstandingDefaults;
import com.azure.core.credential.AzureKeyCredential;
import com.azure.identity.DefaultAzureCredentialBuilder;

import java.util.HashMap;
import java.util.Map;

/**
 * Sample demonstrating how to configure and manage default settings for Content Understanding service.
 * This sample shows:
 * 1. Getting current default configuration
 * 2. Updating default configuration with your model deployments
 * 3. Verifying the updated configuration
 *
 * <p><strong>Prerequisites:</strong></p>
 * <p>Before running this sample, make sure you have:</p>
 * <ol>
 *   <li>Created a Microsoft Foundry resource (see README.md)</li>
 *   <li>Deployed the required models (gpt-4.1, gpt-4.1-mini, text-embedding-3-large)</li>
 *   <li>Set the environment variables:
 *     <ul>
 *       <li>{@code CONTENTUNDERSTANDING_ENDPOINT} - Your Foundry resource endpoint</li>
 *       <li>{@code CONTENTUNDERSTANDING_KEY} - (Optional) Your API key</li>
 *       <li>{@code GPT_4_1_DEPLOYMENT} - Your GPT-4.1 deployment name</li>
 *       <li>{@code GPT_4_1_MINI_DEPLOYMENT} - Your GPT-4.1-mini deployment name</li>
 *       <li>{@code TEXT_EMBEDDING_3_LARGE_DEPLOYMENT} - Your text-embedding-3-large deployment name</li>
 *     </ul>
 *   </li>
 * </ol>
 *
 * <p>This sample demonstrates the one-time setup required to map your deployed models
 * to those required by prebuilt and custom analyzers.</p>
 */
public class Sample00_UpdateDefaultsAsync {

    public static void main(String[] args) {
        // BEGIN: com.azure.ai.contentunderstanding.sample00Async.buildClient
        String endpoint = System.getenv("CONTENTUNDERSTANDING_ENDPOINT");
        String key = System.getenv("CONTENTUNDERSTANDING_KEY");

        // Build the client with appropriate authentication
        ContentUnderstandingClientBuilder builder = new ContentUnderstandingClientBuilder().endpoint(endpoint);

        ContentUnderstandingAsyncClient client;
        if (key != null && !key.trim().isEmpty()) {
            // Use API key authentication
            client = builder.credential(new AzureKeyCredential(key)).buildAsyncClient();
        } else {
            // Use default Azure credential (for managed identity, Azure CLI, etc.)
            client = builder.credential(new DefaultAzureCredentialBuilder().build()).buildAsyncClient();
        }
        // END: com.azure.ai.contentunderstanding.sample00Async.buildClient

        // Step 1: Get current defaults to see what's configured
        System.out.println("Getting current default configuration...");
        ContentUnderstandingDefaults currentDefaults = client.getDefaults().block();
        System.out.println("Current defaults retrieved successfully.");
        System.out.println("Current model deployments: " + currentDefaults.getModelDeployments());

        // Step 2: Configure model deployments from environment variables
        // These map model names to your deployed model names in Azure AI Foundry
        System.out.println("\nConfiguring model deployments from environment variables...");

        // Get deployment names from environment variables
        String gpt41Deployment = getEnvOrDefault("GPT_4_1_DEPLOYMENT", "gpt-4.1");
        String gpt41MiniDeployment = getEnvOrDefault("GPT_4_1_MINI_DEPLOYMENT", "gpt-4.1-mini");
        String textEmbedding3LargeDeployment
            = getEnvOrDefault("TEXT_EMBEDDING_3_LARGE_DEPLOYMENT", "text-embedding-3-large");

        // Create model deployments map
        Map<String, String> modelDeployments = new HashMap<>();
        modelDeployments.put("gpt-4.1", gpt41Deployment);
        modelDeployments.put("gpt-4.1-mini", gpt41MiniDeployment);
        modelDeployments.put("text-embedding-3-large", textEmbedding3LargeDeployment);

        System.out.println("Model deployments to configure:");
        System.out.println("  gpt-4.1 -> " + gpt41Deployment);
        System.out.println("  gpt-4.1-mini -> " + gpt41MiniDeployment);
        System.out.println("  text-embedding-3-large -> " + textEmbedding3LargeDeployment);

        // Step 3: Update defaults with the new configuration
        System.out.println("\nUpdating default configuration...");

        // Update defaults with the configuration using the typed convenience method
        ContentUnderstandingDefaults updatedConfig = client.updateDefaults(modelDeployments).block();
        System.out.println("Defaults updated successfully.");
        System.out.println("Updated model deployments: " + updatedConfig.getModelDeployments());

        // Step 4: Verify the updated configuration
        System.out.println("\nVerifying updated configuration...");
        ContentUnderstandingDefaults updatedDefaults = client.getDefaults().block();
        System.out.println("Updated defaults verified successfully.");
        System.out.println("Updated model deployments: " + updatedDefaults.getModelDeployments());

        System.out.println("\nConfiguration management completed.");
    }

    /**
     * Gets an environment variable value or returns a default value if not set.
     *
     * @param envVar the environment variable name
     * @param defaultValue the default value to return if the environment variable is not set
     * @return the environment variable value or the default value
     */
    private static String getEnvOrDefault(String envVar, String defaultValue) {
        String value = System.getenv(envVar);
        return (value != null && !value.trim().isEmpty()) ? value : defaultValue;
    }
}
