// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) TypeSpec Code Generator.

package com.azure.ai.contentunderstanding.samples;

import com.azure.ai.contentunderstanding.ContentUnderstandingAsyncClient;
import com.azure.ai.contentunderstanding.ContentUnderstandingClientBuilder;
import com.azure.ai.contentunderstanding.models.AnalyzeInput;
import com.azure.ai.contentunderstanding.models.AnalyzeResult;
import com.azure.ai.contentunderstanding.models.AudioVisualContent;
import com.azure.core.credential.AzureKeyCredential;
import com.azure.core.util.BinaryData;
import com.azure.core.util.polling.PollerFlux;
import com.azure.identity.DefaultAzureCredentialBuilder;

import java.io.IOException;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.util.Arrays;
import java.util.List;

/**
 * Sample demonstrates how to retrieve result files (like keyframe images) from video analysis operations
 * using the async client.
 */
public class Sample12_GetResultFileAsync {

    public static void main(String[] args) throws IOException {
        // BEGIN: com.azure.ai.contentunderstanding.sample12Async.buildClient
        String endpoint = System.getenv("CONTENTUNDERSTANDING_ENDPOINT");
        String key = System.getenv("CONTENTUNDERSTANDING_KEY");

        // Build the async client with appropriate authentication
        ContentUnderstandingClientBuilder builder = new ContentUnderstandingClientBuilder().endpoint(endpoint);

        ContentUnderstandingAsyncClient client;
        if (key != null && !key.trim().isEmpty()) {
            // Use API key authentication
            client = builder.credential(new AzureKeyCredential(key)).buildAsyncClient();
        } else {
            // Use default Azure credential (for managed identity, Azure CLI, etc.)
            client = builder.credential(new DefaultAzureCredentialBuilder().build()).buildAsyncClient();
        }
        // END: com.azure.ai.contentunderstanding.sample12Async.buildClient

        System.out.println("Client initialized successfully");

        // BEGIN: com.azure.ai.contentunderstanding.getResultFileAsync
        // For video analysis, use a video URL to get keyframes
        String videoUrl
            = "https://github.com/Azure-Samples/azure-ai-content-understanding-assets/raw/refs/heads/main/videos/sdk_samples/FlightSimulator.mp4";

        // Step 1: Start the video analysis operation
        AnalyzeInput input = new AnalyzeInput();
        input.setUrl(videoUrl);

        PollerFlux<com.azure.ai.contentunderstanding.models.ContentAnalyzerAnalyzeOperationStatus, AnalyzeResult> poller
            = client.beginAnalyze("prebuilt-videoSearch", Arrays.asList(input));

        System.out.println("Started analysis operation");

        // Wait for completion using getSyncPoller() for simplicity in samples
        AnalyzeResult result = poller.getSyncPoller().getFinalResult();
        System.out.println("Analysis completed successfully!");

        // Get the operation ID from the polling result using the getOperationId() convenience method
        // The operation ID is extracted from the Operation-Location header and can be used with
        // getResultFile() and deleteResult() APIs
        String operationId = poller.getSyncPoller().poll().getValue().getOperationId();
        System.out.println("Operation ID: " + operationId);

        // END: com.azure.ai.contentunderstanding.getResultFileAsync

        System.out.println("Video URL: " + videoUrl);
        System.out.println("Analysis result contains " + result.getContents().size() + " content(s)");

        // BEGIN: com.azure.ai.contentunderstanding.getResultFileAsync.keyframes
        // Step 2: Get keyframes from video analysis result
        AudioVisualContent videoContent = null;
        for (Object content : result.getContents()) {
            if (content instanceof AudioVisualContent) {
                videoContent = (AudioVisualContent) content;
                break;
            }
        }

        if (videoContent != null
            && videoContent.getKeyFrameTimesMs() != null
            && !videoContent.getKeyFrameTimesMs().isEmpty()) {
            List<Long> keyFrameTimes = videoContent.getKeyFrameTimesMs();
            System.out.println("Total keyframes: " + keyFrameTimes.size());

            // Get the first keyframe
            long firstFrameTimeMs = keyFrameTimes.get(0);
            System.out.println("First keyframe time: " + firstFrameTimeMs + " ms");

            // Construct the keyframe path
            String framePath = "keyframes/" + firstFrameTimeMs;
            System.out.println("Getting result file: " + framePath);

            // Retrieve the keyframe image with retry logic
            // Note: Result files may not be immediately available after analysis completion
            // The service requires additional time for keyframe extraction
            BinaryData fileData = null;
            int maxRetries = 12;
            int retryDelayMs = 10000; // 10 seconds between retries
            for (int attempt = 1; attempt <= maxRetries; attempt++) {
                try {
                    fileData = client.getResultFile(operationId, framePath).block();
                    break; // Success
                } catch (Exception e) {
                    if (attempt == maxRetries) {
                        throw e;
                    }
                    System.out.println("Attempt " + attempt + " failed: " + e.getMessage());
                    System.out.println("Waiting " + (retryDelayMs / 1000) + " seconds before retry...");
                    try {
                        Thread.sleep(retryDelayMs);
                    } catch (InterruptedException ie) {
                        Thread.currentThread().interrupt();
                        throw new RuntimeException("Interrupted while waiting for retry", ie);
                    }
                }
            }
            byte[] imageBytes = fileData.toBytes();
            System.out.println("Retrieved keyframe image (" + String.format("%,d", imageBytes.length) + " bytes)");

            // Save the keyframe image
            Path outputDir = Paths.get("target", "sample_output");
            Files.createDirectories(outputDir);
            String outputFileName = "keyframe_" + firstFrameTimeMs + ".jpg";
            Path outputPath = outputDir.resolve(outputFileName);
            Files.write(outputPath, imageBytes);

            System.out.println("Keyframe image saved to: " + outputPath.toAbsolutePath());
            // END: com.azure.ai.contentunderstanding.getResultFileAsync.keyframes

            System.out.println("\nðŸŽ¬ Keyframe Information:");
            System.out.println("Total keyframes: " + keyFrameTimes.size());

            // Get keyframe statistics
            long lastFrameTimeMs = keyFrameTimes.get(keyFrameTimes.size() - 1);
            double avgFrameInterval = keyFrameTimes.size() > 1
                ? (double) (lastFrameTimeMs - firstFrameTimeMs) / (keyFrameTimes.size() - 1)
                : 0;

            System.out.println("  First keyframe: " + firstFrameTimeMs + " ms ("
                + String.format("%.2f", firstFrameTimeMs / 1000.0) + " seconds)");
            System.out.println("  Last keyframe: " + lastFrameTimeMs + " ms ("
                + String.format("%.2f", lastFrameTimeMs / 1000.0) + " seconds)");
            if (keyFrameTimes.size() > 1) {
                System.out.println("  Average interval: " + String.format("%.2f", avgFrameInterval) + " ms");
            }

            System.out.println("\nðŸ“¥ File Data Retrieved");

            System.out.println("\nVerifying image data...");
            System.out.println("Image size: " + String.format("%,d", imageBytes.length) + " bytes ("
                + String.format("%.2f", imageBytes.length / 1024.0) + " KB)");

            // Verify image format
            String imageFormat = detectImageFormat(imageBytes);
            System.out.println("Detected image format: " + imageFormat);

            System.out.println("\nðŸ’¾ Saved File:");
            long fileSize = Files.size(outputPath);
            System.out.println("File saved: " + outputPath.toAbsolutePath());
            System.out.println("File size: " + String.format("%,d", fileSize) + " bytes");

            // Test additional keyframes if available
            if (keyFrameTimes.size() > 1) {
                System.out
                    .println("\nTesting additional keyframes (" + (keyFrameTimes.size() - 1) + " more available)...");
                int middleIndex = keyFrameTimes.size() / 2;
                long middleFrameTimeMs = keyFrameTimes.get(middleIndex);
                String middleFramePath = "keyframes/" + middleFrameTimeMs;

                BinaryData middleFileData = client.getResultFile(operationId, middleFramePath).block();
                System.out.println(
                    "Successfully retrieved keyframe at index " + middleIndex + " (" + middleFrameTimeMs + " ms)");
                System.out.println(
                    "  Size: " + String.format("%,d", middleFileData.toBytes().length) + " bytes");
            }

            // Summary
            System.out.println("\nKeyframe retrieval completed successfully:");
            System.out.println("  Operation ID: " + operationId);
            System.out.println("  Total keyframes: " + keyFrameTimes.size());
            System.out.println("  First keyframe time: " + firstFrameTimeMs + " ms");
            System.out.println("  Image format: " + imageFormat);
            System.out.println("  Image size: " + String.format("%,d", imageBytes.length) + " bytes");
            System.out.println("  Saved to: " + outputPath.toAbsolutePath());
        } else {
            // No video content (expected for document analysis)
            System.out.println("\nGetResultFile API Usage Example:");
            System.out.println("   For video analysis with keyframes:");
            System.out.println("   1. Analyze video with prebuilt-videoSearch");
            System.out.println("   2. Get keyframe times from AudioVisualContent.getKeyFrameTimesMs()");
            System.out.println("   3. Retrieve keyframes using getResultFile():");
            System.out.println("      Mono<BinaryData> fileData = client.getResultFile(\"" + operationId
                + "\", \"keyframes/1000\");");
            System.out.println("   4. Save or process the keyframe image");

            System.out.println("Operation ID available for GetResultFile API: " + operationId);
        }
    }

    /**
     * Detect image format from magic bytes.
     */
    private static String detectImageFormat(byte[] imageBytes) {
        if (imageBytes.length < 2) {
            return "Unknown";
        }

        // Check JPEG magic bytes (FF D8)
        if (imageBytes[0] == (byte) 0xFF && imageBytes[1] == (byte) 0xD8) {
            return "JPEG";
        }

        // Check PNG magic bytes (89 50 4E 47)
        if (imageBytes.length >= 4
            && imageBytes[0] == (byte) 0x89
            && imageBytes[1] == 0x50
            && imageBytes[2] == 0x4E
            && imageBytes[3] == 0x47) {
            return "PNG";
        }

        // Check GIF magic bytes (47 49 46)
        if (imageBytes.length >= 3 && imageBytes[0] == 0x47 && imageBytes[1] == 0x49 && imageBytes[2] == 0x46) {
            return "GIF";
        }

        // Check WebP magic bytes (52 49 46 46 ... 57 45 42 50)
        if (imageBytes.length >= 12
            && imageBytes[0] == 0x52
            && imageBytes[1] == 0x49
            && imageBytes[8] == 0x57
            && imageBytes[9] == 0x45
            && imageBytes[10] == 0x42
            && imageBytes[11] == 0x50) {
            return "WebP";
        }

        return "Unknown";
    }
}
