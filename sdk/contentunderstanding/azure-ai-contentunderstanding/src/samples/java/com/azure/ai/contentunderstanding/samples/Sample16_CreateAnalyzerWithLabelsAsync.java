// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) TypeSpec Code Generator.

package com.azure.ai.contentunderstanding.samples;

import com.azure.ai.contentunderstanding.ContentUnderstandingAsyncClient;
import com.azure.ai.contentunderstanding.ContentUnderstandingClientBuilder;
import com.azure.ai.contentunderstanding.models.ContentAnalyzer;
import com.azure.ai.contentunderstanding.models.ContentAnalyzerConfig;
import com.azure.ai.contentunderstanding.models.ContentFieldDefinition;
import com.azure.ai.contentunderstanding.models.ContentFieldSchema;
import com.azure.ai.contentunderstanding.models.ContentFieldType;
import com.azure.ai.contentunderstanding.models.GenerationMethod;
import com.azure.ai.contentunderstanding.models.KnowledgeSource;
import com.azure.ai.contentunderstanding.models.LabeledDataKnowledgeSource;
import com.azure.core.credential.AzureKeyCredential;
import com.azure.core.util.polling.PollerFlux;
import com.azure.identity.DefaultAzureCredentialBuilder;
import reactor.core.publisher.Mono;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.UUID;
import java.util.concurrent.TimeUnit;

/**
 * Async sample demonstrates how to build analyzers with training labels (labeled data from Azure Blob Storage).
 *
 * This sample is mainly to show the API pattern for creating an analyzer with labeled training data.
 * For an easier labeling workflow, use Azure AI Content Understanding Studio at
 * https://contentunderstanding.ai.azure.com/
 *
 * Labeled receipt data is available in this repo at {@code src/samples/resources/receipt_labels}
 * (images and corresponding .labels.json files). To use it for training:
 *
 * <p><b>Manual instructions to upload labels into Azure Blob Storage:</b></p>
 * <ol>
 *   <li>Create an Azure Blob Storage container (or use an existing one).</li>
 *   <li>Upload the contents of {@code src/samples/resources/receipt_labels} into the container.
 *       You may upload into the container root or into a subfolder (e.g., "receipt_labels/").</li>
 *   <li>Generate a SAS (Shared Access Signature) URL for the container with at least List and Read
 *       permissions. In Azure Portal: Storage account → Containers → your container → Shared access
 *       token; set expiry and permissions, then generate the SAS URL.</li>
 *   <li>Set {@code CONTENTUNDERSTANDING_TRAINING_DATA_SAS_URL} to the full SAS URL
 *       (e.g., https://&lt;account&gt;.blob.core.windows.net/&lt;container&gt;?sv=...&amp;se=...).</li>
 *   <li>If you uploaded into a subfolder, set {@code CONTENTUNDERSTANDING_TRAINING_DATA_PREFIX} to
 *       that path (e.g., "receipt_labels/"). If files are at the container root, omit the prefix
 *       or leave it unset.</li>
 * </ol>
 *
 * <p>Each labeled document in the training folder includes:</p>
 * <ul>
 *   <li>The original file (e.g., PDF or image).</li>
 *   <li>A corresponding .labels.json file with labeled fields.</li>
 *   <li>A corresponding .result.json file with OCR results (optional).</li>
 * </ul>
 *
 * <p><b>Required environment variables:</b></p>
 * <ul>
 *   <li>{@code CONTENTUNDERSTANDING_ENDPOINT} – Azure Content Understanding endpoint URL</li>
 *   <li>{@code CONTENTUNDERSTANDING_KEY} – Azure Content Understanding API key
 *       (optional if using DefaultAzureCredential)</li>
 * </ul>
 *
 * <p><b>Optional environment variables (for labeled training data):</b></p>
 * <ul>
 *   <li>{@code CONTENTUNDERSTANDING_TRAINING_DATA_SAS_URL} – SAS URL for the Azure Blob container
 *       with labeled training data. If set, the analyzer is created with a labeled-data knowledge
 *       source; otherwise, created without training data.</li>
 *   <li>{@code CONTENTUNDERSTANDING_TRAINING_DATA_PREFIX} – Path prefix within the container
 *       (e.g., "receipt_labels/" or "CreateAnalyzerWithLabels/"). Omit or leave unset if files
 *       are at the container root.</li>
 * </ul>
 */
public class Sample16_CreateAnalyzerWithLabelsAsync {

    public static void main(String[] args) {
        // BEGIN: com.azure.ai.contentunderstanding.sample16Async.buildClient
        String endpoint = System.getenv("CONTENTUNDERSTANDING_ENDPOINT");
        String key = System.getenv("CONTENTUNDERSTANDING_KEY");
        String sasUrl = System.getenv("CONTENTUNDERSTANDING_TRAINING_DATA_SAS_URL");
        String sasUrlPrefix = System.getenv("CONTENTUNDERSTANDING_TRAINING_DATA_PREFIX");

        // Build the async client with appropriate authentication
        ContentUnderstandingClientBuilder builder = new ContentUnderstandingClientBuilder().endpoint(endpoint);

        ContentUnderstandingAsyncClient client;
        if (key != null && !key.trim().isEmpty()) {
            // Use API key authentication
            client = builder.credential(new AzureKeyCredential(key)).buildAsyncClient();
        } else {
            // Use default Azure credential (for managed identity, Azure CLI, etc.)
            client = builder.credential(new DefaultAzureCredentialBuilder().build()).buildAsyncClient();
        }
        // END: com.azure.ai.contentunderstanding.sample16Async.buildClient

        System.out.println("Client initialized successfully");

        String analyzerId = "test_receipt_analyzer_" + UUID.randomUUID().toString().replace("-", "");
        String finalAnalyzerId = analyzerId; // For use in lambda

        // BEGIN: com.azure.ai.contentunderstanding.createAnalyzerWithLabelsAsync
            // Step 1: Define field schema for receipt extraction
            Map<String, ContentFieldDefinition> fields = new HashMap<>();

            // MerchantName field
            ContentFieldDefinition merchantNameField = new ContentFieldDefinition();
            merchantNameField.setType(ContentFieldType.STRING);
            merchantNameField.setMethod(GenerationMethod.EXTRACT);
            merchantNameField.setDescription("Name of the merchant");
            fields.put("MerchantName", merchantNameField);

            // Items array field - define item structure
            ContentFieldDefinition itemDefinition = new ContentFieldDefinition();
            itemDefinition.setType(ContentFieldType.OBJECT);
            itemDefinition.setMethod(GenerationMethod.EXTRACT);
            itemDefinition.setDescription("Individual item details");

            Map<String, ContentFieldDefinition> itemProperties = new HashMap<>();

            ContentFieldDefinition quantityField = new ContentFieldDefinition();
            quantityField.setType(ContentFieldType.STRING);
            quantityField.setMethod(GenerationMethod.EXTRACT);
            quantityField.setDescription("Quantity of the item");
            itemProperties.put("Quantity", quantityField);

            ContentFieldDefinition nameField = new ContentFieldDefinition();
            nameField.setType(ContentFieldType.STRING);
            nameField.setMethod(GenerationMethod.EXTRACT);
            nameField.setDescription("Name of the item");
            itemProperties.put("Name", nameField);

            ContentFieldDefinition priceField = new ContentFieldDefinition();
            priceField.setType(ContentFieldType.STRING);
            priceField.setMethod(GenerationMethod.EXTRACT);
            priceField.setDescription("Price of the item");
            itemProperties.put("Price", priceField);

            itemDefinition.setProperties(itemProperties);

            // Items array field
            ContentFieldDefinition itemsField = new ContentFieldDefinition();
            itemsField.setType(ContentFieldType.ARRAY);
            itemsField.setMethod(GenerationMethod.GENERATE);
            itemsField.setDescription("List of items purchased");
            itemsField.setItemDefinition(itemDefinition);
            fields.put("Items", itemsField);

            // Total field
            ContentFieldDefinition totalField = new ContentFieldDefinition();
            totalField.setType(ContentFieldType.STRING);
            totalField.setMethod(GenerationMethod.EXTRACT);
            totalField.setDescription("Total amount");
            fields.put("Total", totalField);

            ContentFieldSchema fieldSchema = new ContentFieldSchema();
            fieldSchema.setName("receipt_schema");
            fieldSchema.setDescription("Schema for receipt extraction with items");
            fieldSchema.setFields(fields);

            // Step 2: Create labeled data knowledge source (optional, based on environment variable)
            List<KnowledgeSource> knowledgeSources = new ArrayList<>();
            if (sasUrl != null && !sasUrl.trim().isEmpty()) {
                LabeledDataKnowledgeSource knowledgeSource = new LabeledDataKnowledgeSource()
                    .setContainerUrl(sasUrl)
                    .setPrefix(sasUrlPrefix);
                knowledgeSources.add(knowledgeSource);
                System.out.println("Using labeled training data from: " + sasUrl.substring(0, Math.min(50, sasUrl.length())) + "...");
            } else {
                System.out.println("No CONTENTUNDERSTANDING_TRAINING_DATA_SAS_URL set, creating analyzer without labeled training data");
            }

            // Step 3: Create analyzer (with or without labeled data)
            Map<String, String> models = new HashMap<>();
            models.put("completion", "gpt-4.1");
            models.put("embedding", "text-embedding-3-large");

            ContentAnalyzer analyzer = new ContentAnalyzer()
                .setBaseAnalyzerId("prebuilt-document")
                .setDescription("Receipt analyzer with labeled training data")
                .setConfig(new ContentAnalyzerConfig()
                    .setEnableLayout(true)
                    .setEnableOcr(true))
                .setFieldSchema(fieldSchema)
                .setModels(models);

            if (!knowledgeSources.isEmpty()) {
                analyzer.setKnowledgeSources(knowledgeSources);
            }

            // For demonstration without actual training data, create analyzer without knowledge sources
            // Using reactive pattern for async operations
            PollerFlux<com.azure.ai.contentunderstanding.models.ContentAnalyzerOperationStatus, ContentAnalyzer> createPoller
                = client.beginCreateAnalyzer(finalAnalyzerId, analyzer, true);

            createPoller.last()
                .flatMap(pollResponse -> {
                    if (pollResponse.getStatus().isComplete()) {
                        System.out.println("Polling completed successfully");
                        return pollResponse.getFinalResult();
                    } else {
                        return Mono.error(new RuntimeException(
                            "Polling completed unsuccessfully with status: " + pollResponse.getStatus()));
                    }
                })
                .doOnNext(result -> {
                    System.out.println("Analyzer created: " + finalAnalyzerId);
                    System.out.println("  Description: " + result.getDescription());
                    System.out.println("  Base analyzer: " + result.getBaseAnalyzerId());
                    System.out.println("  Fields: " + result.getFieldSchema().getFields().size());
                    // END: com.azure.ai.contentunderstanding.createAnalyzerWithLabelsAsync

                    // Verify analyzer creation
                    System.out.println("\nAnalyzer Creation Verification:");
                    System.out.println("Analyzer created successfully");

                    // Verify field schema
                    Map<String, ContentFieldDefinition> resultFields = result.getFieldSchema().getFields();
                    System.out.println("Field schema verified:");
                    System.out.println("  MerchantName: String (Extract)");
                    System.out.println("  Items: Array of Objects (Generate)");
                    System.out.println("    - Quantity, Name, Price");
                    System.out.println("  Total: String (Extract)");

                    ContentFieldDefinition itemsFieldResult = resultFields.get("Items");
                    System.out.println("Items field verified:");
                    System.out.println("  Type: " + itemsFieldResult.getType());
                    System.out.println("  Item properties: " + itemsFieldResult.getItemDefinition().getProperties().size());

                    // Display API pattern information
                    System.out.println("\nCreateAnalyzerWithLabels API Pattern:");
                    System.out.println("   1. Define field schema with nested structures (arrays, objects)");
                    System.out.println("   2. Upload training data to Azure Blob Storage:");
                    System.out.println("      - Documents: receipt1.pdf, receipt2.pdf, ...");
                    System.out.println("      - Labels: receipt1.pdf.labels.json, receipt2.pdf.labels.json, ...");
                    System.out.println("      - OCR: receipt1.pdf.result.json, receipt2.pdf.result.json, ...");
                    System.out.println("   3. Create LabeledDataKnowledgeSource with storage SAS URL");
                    System.out.println("   4. Create analyzer with field schema and knowledge sources");
                    System.out.println("   5. Use analyzer for document analysis");

                    System.out.println("\nCreateAnalyzerWithLabels pattern demonstration completed");
                    System.out.println("   Note: This sample demonstrates the API pattern.");
                    System.out.println("   For actual training, provide CONTENTUNDERSTANDING_TRAINING_DATA_SAS_URL with labeled data.");
                })
                .doFinally(signalType -> {
                    // Cleanup using reactive pattern
                    client.deleteAnalyzer(finalAnalyzerId)
                        .onErrorResume(e -> {
                            System.out.println("Note: Failed to delete analyzer: " + e.getMessage());
                            return Mono.empty();
                        })
                        .doOnSuccess(v -> System.out.println("\nAnalyzer deleted: " + finalAnalyzerId))
                        .subscribe();
                })
                .doOnError(error -> {
                    System.err.println("Error: " + error.getMessage());
                    error.printStackTrace();
                })
                .subscribe(
                    result -> {
                        // Success - operations completed
                    },
                    error -> {
                        // Error already handled in doOnError
                        System.exit(1);
                    }
                );

        // The .subscribe() creation is not a blocking call. For the purpose of this example,
        // we sleep the thread so the program does not end before the async operations complete.
        try {
            TimeUnit.SECONDS.sleep(30);
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
            e.printStackTrace();
        }
    }
}
